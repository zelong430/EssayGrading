{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Input,Activation,Conv1D,MaxPooling1D,Flatten,Dense,Embedding,LSTM,Merge, Dropout, TimeDistributedDense\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.optimizers import SGD\n",
    "import evaluate\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 1200\n",
    "MAX_NB_WORDS = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences_train = tokenizer.texts_to_sequences(texts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38025 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of data tensor:', (10314, 1200))\n",
      "('Shape of label tensor:', (10314,))\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels_train))\n",
    "print('Shape of data tensor:', data_train.shape)\n",
    "print('Shape of label tensor:', labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(0.8 * data.shape[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(\"glove/glove.6B.300d.txt\", \"r\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(61, activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x15fbde5d0>,\n",
       " <keras.layers.embeddings.Embedding at 0x17f2bba10>,\n",
       " <keras.layers.convolutional.Convolution1D at 0x1512e23d0>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x15fbde850>,\n",
       " <keras.layers.convolutional.Convolution1D at 0x15fc41a10>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x15fc41e50>,\n",
       " <keras.layers.convolutional.Convolution1D at 0x15fc635d0>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x15fc96d10>,\n",
       " <keras.layers.core.Flatten at 0x15fe06b10>,\n",
       " <keras.layers.core.Dense at 0x15fe23d50>,\n",
       " <keras.layers.core.Dense at 0x15fe4ee10>]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2063 samples, validate on 8251 samples\n",
      "Epoch 1/2\n",
      "2063/2063 [==============================] - 109s - loss: 3.7060 - acc: 0.1677 - val_loss: 3.1452 - val_acc: 0.1128\n",
      "Epoch 2/2\n",
      "2063/2063 [==============================] - 104s - loss: 2.7153 - acc: 0.2113 - val_loss: 2.5326 - val_acc: 0.2165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137910490>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# happy learning!\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from evaluate import set_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Bidirectional_lstm_cls_train.csv', names = ['essay_set','essay_id','prediction','actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10284</th>\n",
       "      <td>8</td>\n",
       "      <td>21581</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>8</td>\n",
       "      <td>21584</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10286</th>\n",
       "      <td>8</td>\n",
       "      <td>21586</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10287</th>\n",
       "      <td>8</td>\n",
       "      <td>21587</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10288</th>\n",
       "      <td>8</td>\n",
       "      <td>21589</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10289</th>\n",
       "      <td>8</td>\n",
       "      <td>21592</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10290</th>\n",
       "      <td>8</td>\n",
       "      <td>21595</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10291</th>\n",
       "      <td>8</td>\n",
       "      <td>21596</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10292</th>\n",
       "      <td>8</td>\n",
       "      <td>21598</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10293</th>\n",
       "      <td>8</td>\n",
       "      <td>21599</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>8</td>\n",
       "      <td>21601</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10295</th>\n",
       "      <td>8</td>\n",
       "      <td>21603</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>8</td>\n",
       "      <td>21604</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>8</td>\n",
       "      <td>21605</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>8</td>\n",
       "      <td>21606</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>8</td>\n",
       "      <td>21608</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10300</th>\n",
       "      <td>8</td>\n",
       "      <td>21610</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10301</th>\n",
       "      <td>8</td>\n",
       "      <td>21611</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>8</td>\n",
       "      <td>21613</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10303</th>\n",
       "      <td>8</td>\n",
       "      <td>21617</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>8</td>\n",
       "      <td>21618</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>8</td>\n",
       "      <td>21619</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306</th>\n",
       "      <td>8</td>\n",
       "      <td>21620</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10307</th>\n",
       "      <td>8</td>\n",
       "      <td>21621</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10308</th>\n",
       "      <td>8</td>\n",
       "      <td>21623</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10309</th>\n",
       "      <td>8</td>\n",
       "      <td>21626</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10310</th>\n",
       "      <td>8</td>\n",
       "      <td>21628</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10311</th>\n",
       "      <td>8</td>\n",
       "      <td>21629</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10312</th>\n",
       "      <td>8</td>\n",
       "      <td>21630</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10313</th>\n",
       "      <td>8</td>\n",
       "      <td>21633</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10314 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_set  essay_id  prediction  actual\n",
       "0              1         1           8       8\n",
       "1              1         2           8       9\n",
       "2              1         3           8       7\n",
       "3              1         5          10       8\n",
       "4              1         6           8       8\n",
       "5              1         7          10      10\n",
       "6              1         8          10      10\n",
       "7              1         9          10       9\n",
       "8              1        11           8       8\n",
       "9              1        12           8       8\n",
       "10             1        13           8       7\n",
       "11             1        14           8       6\n",
       "12             1        15           8       6\n",
       "13             1        18           8       8\n",
       "14             1        19           1       4\n",
       "15             1        20           8       6\n",
       "16             1        21           8       8\n",
       "17             1        22           8       3\n",
       "18             1        23          10      10\n",
       "19             1        24          10      11\n",
       "20             1        25           8       8\n",
       "21             1        27           3       4\n",
       "22             1        28           8       9\n",
       "23             1        29           8       9\n",
       "24             1        30           8       8\n",
       "25             1        31          10      10\n",
       "26             1        32          10      10\n",
       "27             1        33           8       6\n",
       "28             1        34           8       8\n",
       "29             1        35          10       9\n",
       "...          ...       ...         ...     ...\n",
       "10284          8     21581          40      36\n",
       "10285          8     21584          10      30\n",
       "10286          8     21586          40      39\n",
       "10287          8     21587          16      30\n",
       "10288          8     21589          40      30\n",
       "10289          8     21592          40      40\n",
       "10290          8     21595          16      36\n",
       "10291          8     21596          16      31\n",
       "10292          8     21598          16      30\n",
       "10293          8     21599          40      47\n",
       "10294          8     21601          40      40\n",
       "10295          8     21603          40      35\n",
       "10296          8     21604          40      33\n",
       "10297          8     21605          16      36\n",
       "10298          8     21606          40      36\n",
       "10299          8     21608          40      40\n",
       "10300          8     21610          40      40\n",
       "10301          8     21611          40      42\n",
       "10302          8     21613          40      40\n",
       "10303          8     21617          40      36\n",
       "10304          8     21618          40      40\n",
       "10305          8     21619           1      10\n",
       "10306          8     21620          40      33\n",
       "10307          8     21621          40      44\n",
       "10308          8     21623          40      35\n",
       "10309          8     21626          40      35\n",
       "10310          8     21628          40      32\n",
       "10311          8     21629          40      40\n",
       "10312          8     21630          40      40\n",
       "10313          8     21633          40      40\n",
       "\n",
       "[10314 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent = []\n",
    "for i in range(1,9):\n",
    "    temp = data[data[\"essay_set\"] == i]\n",
    "    num_sm = temp[ np.logical_and(temp['prediction'] < set_range[i][1], temp['prediction'] > set_range[i][0])]\n",
    "    percent.append( len(num_sm)/float(len(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgUAAAFkCAYAAACw3EhvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAF4tJREFUeJzt3X2QZXV95/H3hydnBxU2mWRmWJkCSjOO5S5Ki5EykFgo\nBC2IpshiAyWCkkWwSBF2jZbOEqESYpIBHwIBVw0QtANa2V3IJsEFyWYFkTAT2DIOY1YhLQojDcmw\nAQYI890/zm/CTGd6pu+lb99+eL+qbkH/+px7f7e6p+/7PNx7UlVIkiTtNewJSJKkucEokCRJgFEg\nSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJElAH1GQ5OgkNyX5QZJtSU6axjo/\nl2R9kq1JvpPkjP6mK0mSBqWfPQX7A/cC5wJ7vHBCkkOAPwFuAw4HPgV8Lsnb+nhsSZI0IHkxF0RK\nsg14Z1XdtJtlPgGcUFX/boexMeCAqnp73w8uSZJm1GycU/Am4NZJY7cAR83CY0uSpGnaZxYeYwWw\nedLYZuDlSV5SVc9MXiHJjwPHAw8CWwc+Q0mSFo4lwCHALVX1WC8rzkYU9ON44IvDnoQkSfPYacCX\nellhNqLgEWD5pLHlwBO72kvQPAhwySWXcOihhw5wajPvwAMPZOXKldNe/gMf+ADnn3/+AGc0GL0+\nzwsuuIDLL798gDOaGxbD89y4cSOnn346cAkwv/59wgPAWq6//nrWrFmz2yUffvhhTjzxJKq2zc7U\nZth++y3hj//4K9P6d7oYfm9hPv/uTv/3FnZ8nt1raS9mIwq+AZwwaey4Nj6VrQBr164d1JwGZsmS\npWzatJFVq1btcdnx8XHuuWf99h/evNLL8wQ44IADOOKIIwY8q+FbLM+z83Zgvj3XDcBa1qxZs8ef\n04YNG1oQXA/s+Q/x3LKRZ589nZUrV07r93G//fabhTkNxrJly6b9d+gF8+13d/q/t5P0fPi95yhI\nsj/wSiBt6LAkhwOPV9X3k1wKHFRV2z+L4CrgvPYuhC8AxwIn0/1U9uCS6S02Z2xk69bTmZiYmNYv\n6cTEBNu2Pc/8+6PT2/OU5rc1zK8XkN6Mj4/zta/dzsjIyLCn0pdeN1C0e/3sKXgDcDvdZxQUsK6N\nXwucRXdi4cHbF66qB5O8A7gcOB94CHhfVU1+R8IuHMpC/sf4goX9R0fS3DV/N07ADZSZ13MUVNX/\nYjdvZayqM3cx9pfA/MxQSVoU3DiR1z7QLBkdHR32FGbFYnmekhYmo0CzYrG8WC6W5ylpYTIKJEkS\nYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZIa\no0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJEmAUSBJkhqjQJIkAUaBJElqjAJJkgQY\nBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBMA+w56AtJCMj48zMTEx7Gn0\nZdmyZaxatWrY05A0REaBNEPGx8dZvXoNW7c+Neyp9GXJkqVs2rTRMJAWMaNAmiETExMtCK4H1gx7\nOj3ayNatpzMxMWEUSIuYUSDNuDXAEcOehCT1zBMNJUkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEk\nSWqMAkmSBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJavqKgiTnJXkgydNJ7kpy\n5B6WPy3JvUmeTPLDJJ9P8mP9TVmSJA1Cz1GQ5BRgHXAR8HrgPuCWJMumWP7NwLXAfwFeA5wMvBH4\nbJ9zliRJA9DPnoILgKur6rqquh84B3gKOGuK5d8EPFBVV1TV31XVncDVdGEgSZLmiJ6iIMm+wAhw\n2/axqirgVuCoKVb7BnBwkhPafSwHfgn4H/1MWJIkDUavewqWAXsDmyeNbwZW7GqFtmfgdOCGJM8C\nDwN/D3ywx8eWJEkDtM+gHyDJa4BPAb8OfBVYCfwu3SGE9+9+7XXADZPGRttNkqTFbWxsjLGxsZ3G\ntmzZ0vf99RoFE8DzwPJJ48uBR6ZY58PAHVV1Wfv6W0nOBf53ko9W1eS9Dju4EDitxylqLhofH2di\nYmLY0+jZsmXLWLVq1bCnIUm7NDo6yujozhvKGzZsYGRkpK/76ykKquq5JOuBY4GbAJKkff3pKVZb\nCjw7aWwbUEB6mq3mpfHxcVavXsPWrU8Neyo9W7JkKZs2bTQMJC0K/Rw+uAy4psXB3XTvRlgKXAOQ\n5FLgoKo6oy1/M/DZJOcAtwAHAZcD36yqqfYuaAGZmJhoQXA9sGbY0+nBRrZuPZ2JiQmjQNKi0HMU\nVNWN7TMJLqY7bHAvcHxVPdoWWQEcvMPy1yZ5KXAe3bkE/0D37oUPv8i5a95ZAxwx7ElIkqbQ14mG\nVXUlcOUU3ztzF2NXAFf081iSJGl2eO0DSZIEGAWSJKkxCiRJEmAUSJKkxiiQJEmAUSBJkhqjQJIk\nAUaBJElqjAJJkgQYBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBBgFkiSp\nMQokSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJEmA\nUSBJkhqjQJIkAUaBJElqjAJJkgQYBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqM\nAkmSBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEtBn\nFCQ5L8kDSZ5OcleSI/ew/H5JfiPJg0m2Jvlekvf2NWNJkjQQ+/S6QpJTgHXALwN3AxcAtyT5qaqa\nmGK1LwM/AZwJfBdYiXspJEmaU3qOAroIuLqqrgNIcg7wDuAs4LcnL5zk54GjgcOq6h/a8Hh/05Uk\nSYPS09Z6kn2BEeC27WNVVcCtwFFTrHYicA/wa0keSrIpye8kWdLnnCVJ0gD0uqdgGbA3sHnS+GZg\n9RTrHEa3p2Ar8M52H78P/Bjwvh4fX5IkDUg/hw96tRewDTi1qv4RIMmvAl9Ocm5VPTP1quuAGyaN\njbabJEmL29jYGGNjYzuNbdmype/76zUKJoDngeWTxpcDj0yxzsPAD7YHQbMRCPAKuhMPp3AhcFqP\nU5QkaXEYHR1ldHTnDeUNGzYwMjLS1/31dE5BVT0HrAeO3T6WJO3rO6dY7Q7goCRLdxhbTbf34KGe\nZitJkgamn7cFXgacneQ9SV4NXAUsBa4BSHJpkmt3WP5LwGPAHyRZk+QYuncpfH73hw4kSdJs6vmc\ngqq6Mcky4GK6wwb3AsdX1aNtkRXAwTss/2SStwGfAf6KLhBuANa+yLlLkqQZ1NeJhlV1JXDlFN87\ncxdj3wGO7+exJEnS7PBTBSVJEmAUSJKkxiiQJEmAUSBJkhqjQJIkAUaBJElqjAJJkgQYBZIkqTEK\nJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBBgFkiSpMQokSRJgFEiSpMYokCRJgFEg\nSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJEmAUSBJkhqjQJIkAUaBJElqjAJJ\nkgQYBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBBgFkiSpMQokSRJgFEiS\npMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJElAn1GQ5LwkDyR5\nOsldSY6c5npvTvJckg39PK4kSRqcnqMgySnAOuAi4PXAfcAtSZbtYb0DgGuBW/uYpyRJGrB+9hRc\nAFxdVddV1f3AOcBTwFl7WO8q4IvAXX08piRJGrCeoiDJvsAIcNv2saoquq3/o3az3pnAocDH+5um\nJEkatH16XH4ZsDewedL4ZmD1rlZI8irgN4GfqaptSXqepCRJGrxeo6AnSfaiO2RwUVV9d/vw9O9h\nHXDDpLHRdpMkaXEbGxtjbGxsp7EtW7b0fX+9RsEE8DywfNL4cuCRXSz/MuANwOuSXNHG9gKS5Fng\nuKr6i6kf7kLgtB6nKEnS4jA6Osro6M4byhs2bGBkZKSv++vpnIKqeg5YDxy7fSzd8YBjgTt3scoT\nwGuB1wGHt9tVwP3t/7/Z16wlSdKM6+fwwWXANUnWA3fTvRthKXANQJJLgYOq6ox2EuK3d1w5yY+A\nrVW18cVMXJIkzayeo6CqbmyfSXAx3WGDe4Hjq+rRtsgK4OCZm6IkSZoNfZ1oWFVXAldO8b0z97Du\nx/GtiZIkzTle+0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJEmAUSBJkhqjQJIkAUaB\nJElqjAJJkgQYBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBBgFkiSpMQok\nSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKkxiiQJEmAUSBJ\nkhqjQJIkAUaBJElqjAJJkgQYBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmS\nBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIE9BkFSc5L8kCSp5PcleTI\n3Sz7riRfTfKjJFuS3JnkuP6nLEmSBqHnKEhyCrAOuAh4PXAfcEuSZVOscgzwVeAE4AjgduDmJIf3\nNWNJkjQQ/ewpuAC4uqquq6r7gXOAp4CzdrVwVV1QVb9bVeur6rtV9VHgb4ET+561JEmacT1FQZJ9\ngRHgtu1jVVXArcBR07yPAC8DHu/lsSVJ0mD1uqdgGbA3sHnS+GZgxTTv4z8B+wM39vjYkiRpgPaZ\nzQdLciqwFjipqib2vMY64IZJY6PtJknS4jY2NsbY2NhOY1u2bOn7/nqNggngeWD5pPHlwCO7WzHJ\nu4HPAidX1e3Te7gLgdN6nKIkSYvD6Ogoo6M7byhv2LCBkZGRvu6vp8MHVfUcsB44dvtYO0fgWODO\nqdZLMgp8Hnh3Vf15XzOVJEkD1c/hg8uAa5KsB+6mezfCUuAagCSXAgdV1Rnt61Pb984H/irJ9r0M\nT1fVEy9q9pIkacb0HAVVdWP7TIKL6Q4b3AscX1WPtkVWAAfvsMrZdCcnXtFu213LFG9jlCRJs6+v\nEw2r6krgyim+d+akr9/Sz2NIkqTZ5bUPJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmS\nBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIEGAWSJKkxCiRJEmAUSJKk\nxiiQJEmAUSBJkhqjQJIkAUaBJElqjAJJkgQYBZIkqTEKJEkSYBRIkqTGKJAkSYBRIEmSGqNAkiQB\nRoEkSWqMAkmSBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZIao0CSJAFGgSRJaowCSZIEGAWSJKkx\nCiRJEmAUSJKkxiiQJEmAUSBJkhqjQJIkAUaBJElqjAJJkgQYBZIkqTEKJEkSYBRIkqTGKJAkSUCf\nUZDkvCQPJHk6yV1JjtzD8j+XZH2SrUm+k+SM/qYrSZIGpecoSHIKsA64CHg9cB9wS5JlUyx/CPAn\nwG3A4cCngM8leVt/U5YkSYPQz56CC4Crq+q6qrofOAd4CjhriuU/AHyvqj5UVZuq6grgK+1+JEnS\nHNFTFCTZFxih2+oHoKoKuBU4aorV3tS+v6NbdrO8JEkagn16XH4ZsDewedL4ZmD1FOusmGL5lyd5\nSVU9s4t1lnT/uaPH6Q3bAwBs3LhxWku/sNyfAtNbZ27wee7K/H2e0Mtz9XnOBz7PXZm/z7Xf57n9\ntXT60m3oT3PhZCXwA+CoqvrmDuOfAI6pqn+x9Z9kE/CFqvrEDmMn0J1nsHRXUZDkVOCLvTwRSZK0\nk9Oq6ku9rNDrnoIJ4Hlg+aTx5cAjU6zzyBTLPzHFXgLoDi+cBjwIbO1xjpIkLWZLgEPoXkt70lMU\nVNVzSdYDxwI3ASRJ+/rTU6z2DeCESWPHtfGpHucxoKe6kSRJ/+zOflbq590HlwFnJ3lPklcDVwFL\ngWsAklya5Nodlr8KOCzJJ5KsTnIucHK7H0mSNEf0eviAqrqxfSbBxXSHAe4Fjq+qR9siK4CDd1j+\nwSTvAC4HzgceAt5XVZPfkSBJkoaopxMNJUnSwuW1DyRJEmAUSJKkZk5FQZKjk9yU5AdJtiU5adhz\nmmlJPpLk7iRPJNmc5L8m+alhz2sQkpyT5L4kW9rtziQ/P+x5DVKSD7ff3QV3Im2Si9pz2/H27WHP\naxCSHJTkD5NMJHmq/R4fMex5zaR2UbvJP89tST4z7LnNpCR7Jbkkyffaz/L/JvnYsOc1CElemuST\nSR5sz/XrSd7Qy33MqSgA9qc7cfFcYKGe7HA08Bngp4G3AvsCX03yr4Y6q8H4PvBrwBF0H4/9NeC/\nJ1kz1FkNSLta6C/TXSRsofoW3QnGK9rtZ4Y7nZmX5EC6j1N9BjgeWANcCPz9MOc1AG/ghZ/jCuBt\ndH93bxzmpAbgw8B/oHtdeTXwIeBDST441FkNxufpPiLgNOC1wP8Ebm0fPDgtc/ZEwyTbgHdW1U3D\nnssgtXdy/IjuEyG/Puz5DFqSx4D/WFV/MOy5zKQkLwXW010AbC3w11X1q8Od1cxKchHwC1W1oLaY\nJ0vyW3Sf2vqzw57LbErySeDtVbWg9lwmuRl4pKrO3mHsK8BTVfWe4c1sZiVZAvw/4MSq+vMdxu8B\n/rSq/vN07meu7SlYjA6kq/PHhz2RQWq78N5N95kWU35w1Tx2BXBzVX1t2BMZsFe1w3vfTXJ9koP3\nvMq8cyJwT5Ib2yG+DUneP+xJDVK72N1pdFuaC82dwLFJXgWQ5HDgzXQXQFhI9qG7NtHkTwp+mh72\n6PX8OQWaOe3TID8JfL2qFuqx2dfSRcD2in1Xu+T2gtFi53V0u2MXsruA9wKbgJXArwN/meS1VfXk\nEOc10w6j2+OzDvgN4I3Ap5M8U1V/ONSZDc67gAOAa/e04Dz0W8DLgfuTPE+3MfzRqvqj4U5rZlXV\nPyb5BrA2yf10Fx48le6KxH873fsxCobrSuA1dNW6UN0PHE73B+dk4LokxyyUMEjyCrqwe2tVPTfs\n+QxSVe34OerfSnI38HfAvwcW0uGgvYC7q2pt+/q+FrfnAAs1Cs4C/qyqprqGzXx2Ct2L47uBb9MF\n/KeS/HABRt7pwBfoLlz4T8AGuksGjEz3DoyCIUnye8DbgaOr6uFhz2dQquqfgO+1L/86yRuBX6Hb\nElsIRoCfADa0PT/Q7cI7pp3I9JKaqyfuvEhVtSXJd4BXDnsuM+xh/uV1dTcCvziEuQxcklV0Jz2/\nc9hzGZDfBi6tqi+3r/8mySHAR1hgkVdVDwBvaSeuv7yqNif5I174G7xHnlMwBC0IfgF4S1WND3s+\ns2wv4CXDnsQMuhX4t3RbH4e32z3A9cDhCzUI4J9Prnwl3YvoQnIHsHrS2Gq6vSIL0Vl0u5oX2jH2\n7ZbSXd13R9tYwK9/VfV0C4J/TfcOmv823XXn1J6CJPvT/ZHZvsV1WDsp5PGq+v7wZjZzklwJjAIn\nAU8m2X5Z6S1VtaAuE53kN4E/A8aBl9GdyPSzdFfJXBDasfSdzgdJ8iTwWFVN3tqc15L8DnAz3Yvj\nvwE+DjwHjA1zXgNwOXBHko/QvT3vp4H3A2fvdq15qO3dei9wTVVtG/J0BuVm4GNJHgL+hu4t0hcA\nnxvqrAYgyXF0r5+bgFfR7SX5Nu2ChdMxp6KA7kSt2+nOxi+6E32gO/nlrGFNaoadQ/fc/mLS+JnA\ndbM+m8H6Sbqf3UpgC/B/gOMWwRn6C3XvwCvojk/+OPAo8HXgTe1S5wtGVd2T5F10J6itBR4AfmWh\nnZjWvJXuAnYL6ZyQyT4IXEL3DqGfBH4I/H4bW2gOAC6li/bHga8AH6uqyXtKpjRnP6dAkiTNrgV7\nTEWSJPXGKJAkSYBRIEmSGqNAkiQBRoEkSWqMAkmSBBgFkiSpMQokSRJgFEiSpMYokCRJgFEgSZKa\n/w+PBlkYZk6AsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1854a6590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1,9),percent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 'i' in stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(text, keep_period = False):\n",
    "    text = text.lower()\n",
    "    NER_pat = re.compile(\"(@[a-z]+)[1-9]+\")\n",
    "    text = NER_pat.sub('\\\\1', text)\n",
    "\n",
    "    NUM_pat = re.compile(\"(\\d+)\\S*\")\n",
    "    text = NUM_pat.sub('@number', text)\n",
    "\n",
    "    if keep_period:\n",
    "        text = re.sub('[^a-zA-Z0-9.@]', ' ', text)\n",
    "    else:\n",
    "        text = re.sub('[^a-zA-Z0-9@]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed_data/train.tsv',delimiter='\\t')\n",
    "val = pd.read_csv('processed_data/val.tsv',delimiter='\\t')\n",
    "test = pd.read_csv('processed_data/test.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[train[\"essay_set\"] != 8]\n",
    "test = test[test[\"essay_set\"] != 8]\n",
    "train = train[train[\"essay_set\"] != 7]\n",
    "test = test[test[\"essay_set\"] != 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_train = train[\"essay\"].values\n",
    "texts_train = [clean_data(i).replace('@', '') for i in texts_train]\n",
    "\n",
    "\n",
    "texts_val = val[\"essay\"].values\n",
    "texts_val = [clean_data(i).replace('@', '') for i in texts_val]\n",
    "\n",
    "texts_test = test[\"essay\"].values\n",
    "texts_test = [clean_data(i).replace('@', '') for i in texts_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_train = train[\"domain1_score\"].values\n",
    "labels_val = val[\"domain1_score\"].values\n",
    "labels_test = test[\"domain1_score\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class w2v_Model(object):\n",
    "    def __init__(self, path,EMBEDDING_DIM):\n",
    "        self.path = path\n",
    "        self.vocab = {}\n",
    "        self.EMBEDDING_DIM = EMBEDDING_DIM\n",
    "        with open(self.path, 'r') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                self.vocab[word] = coefs\n",
    "\n",
    "        print('Found %s word vectors.' % len(self.vocab))\n",
    "\n",
    "    def __getitem__(self, word):\n",
    "        '''\n",
    "        Return a word vector or subset of word vectors depending on the key.\n",
    "        If `key` is a word string, returns the word vector for that word if present,\n",
    "        else throws and error. If `key` is a list of word strings, returns a matrix X\n",
    "        where\n",
    "        \n",
    "            X[i] = word_vector(key[i])\n",
    "\n",
    "        else throws an error if any of the word strings does not have a vector.\n",
    "\n",
    "        Example:\n",
    "        m = Model('vectors.txt'); m.load()\n",
    "        m['hello'] # returns a single vector of shape (300,)\n",
    "        m[['hello', 'world']] # returns a matrix with shape (2, 300)\n",
    "        '''\n",
    "        \n",
    "        if isinstance(word, str):\n",
    "            return self.__safe_get__(word)\n",
    "        elif isinstance(word, list):\n",
    "            indices = map(lambda w: self.__safe_get__(w), word)\n",
    "            return np.array(indices)\n",
    "        \n",
    "    def __safe_get__(self, word):\n",
    "        if word in self.vocab:\n",
    "            return self.vocab[word]\n",
    "        else:\n",
    "            return np.zeros(self.EMBEDDING_DIM)\n",
    "    \n",
    "    def __contains__(self, word):\n",
    "        return word in self.vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "w2v = w2v_Model('glove/glove.6B.300d.txt',300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regress_kappa(y_true, y_pred, target = train):\n",
    "    #y_pred = y_pred[:,0]\n",
    "    \n",
    "    result_y = np.zeros((len(y_pred),3))\n",
    "    result_y[:, 0 ] = target[\"essay_set\"].values\n",
    "    result_y[:,1] = target[\"essay_id\"].values\n",
    "    result_y[:,2] = np.round(y_pred[:,0])\n",
    "    result_y = result_y.astype('int64')\n",
    "    \n",
    "    true_y = np.zeros((len(y_true),3))\n",
    "    true_y[:, 0 ] = target[\"essay_set\"].values\n",
    "    true_y[:,1] = target[\"essay_id\"].values\n",
    "    true_y[:,2] = y_true \n",
    "    true_y = true_y.astype('int64')\n",
    "    \n",
    "    return evaluate.evaluate(result_y, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.array(map(lambda essay: w2v[essay.split()].mean(axis = 0), texts_train))\n",
    "train_y = labels_train.astype('float32')\n",
    "test_x = np.array(map(lambda essay: w2v[essay.split()].mean(axis = 0), texts_test))\n",
    "test_y = labels_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.hstack((train_x, to_categorical(train[\"essay_set\"].values)))\n",
    "test_x = np.hstack((test_x, to_categorical(test[\"essay_set\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10314/10314 [==============================] - 2s - loss: 45.0495 - mean_absolute_error: 3.8935     \n",
      "Epoch 2/200\n",
      "10314/10314 [==============================] - 2s - loss: 17.4783 - mean_absolute_error: 2.3172     \n",
      "Epoch 3/200\n",
      "10314/10314 [==============================] - 2s - loss: 13.3104 - mean_absolute_error: 2.0403     \n",
      "Epoch 4/200\n",
      "10314/10314 [==============================] - 1s - loss: 10.8449 - mean_absolute_error: 1.8079     \n",
      "Epoch 5/200\n",
      "10314/10314 [==============================] - 1s - loss: 9.3287 - mean_absolute_error: 1.6905     \n",
      "Epoch 6/200\n",
      "10314/10314 [==============================] - 1s - loss: 7.8922 - mean_absolute_error: 1.5320     \n",
      "Epoch 7/200\n",
      "10314/10314 [==============================] - 1s - loss: 7.2788 - mean_absolute_error: 1.4957     \n",
      "Epoch 8/200\n",
      "10314/10314 [==============================] - 1s - loss: 6.7999 - mean_absolute_error: 1.4466     \n",
      "Epoch 9/200\n",
      "10314/10314 [==============================] - 1s - loss: 6.9033 - mean_absolute_error: 1.4458     \n",
      "Epoch 10/200\n",
      "10314/10314 [==============================] - 1s - loss: 6.1368 - mean_absolute_error: 1.3835     \n",
      "Epoch 11/200\n",
      "10314/10314 [==============================] - 1s - loss: 5.6823 - mean_absolute_error: 1.3426     \n",
      "Epoch 12/200\n",
      "10314/10314 [==============================] - 1s - loss: 5.3867 - mean_absolute_error: 1.2939     \n",
      "Epoch 13/200\n",
      "10314/10314 [==============================] - 1s - loss: 5.2001 - mean_absolute_error: 1.2857     \n",
      "Epoch 14/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.6064 - mean_absolute_error: 1.2341     \n",
      "Epoch 15/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.9514 - mean_absolute_error: 1.2554     \n",
      "Epoch 16/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.6405 - mean_absolute_error: 1.2269     \n",
      "Epoch 17/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.3733 - mean_absolute_error: 1.1926     \n",
      "Epoch 18/200\n",
      "10314/10314 [==============================] - 1s - loss: 5.0876 - mean_absolute_error: 1.2696     \n",
      "Epoch 19/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.0774 - mean_absolute_error: 1.1648     \n",
      "Epoch 20/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.3378 - mean_absolute_error: 1.1968     \n",
      "Epoch 21/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.0153 - mean_absolute_error: 1.1582     \n",
      "Epoch 22/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.1611 - mean_absolute_error: 1.1682     \n",
      "Epoch 23/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.4874 - mean_absolute_error: 1.1969     \n",
      "Epoch 24/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.2430 - mean_absolute_error: 1.1838     \n",
      "Epoch 25/200\n",
      "10314/10314 [==============================] - 1s - loss: 4.1130 - mean_absolute_error: 1.1738     \n",
      "Epoch 26/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.7296 - mean_absolute_error: 1.1298     \n",
      "Epoch 27/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.3983 - mean_absolute_error: 1.0792     \n",
      "Epoch 28/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.8220 - mean_absolute_error: 1.1455     \n",
      "Epoch 29/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.3374 - mean_absolute_error: 1.0825     \n",
      "Epoch 30/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.3330 - mean_absolute_error: 1.0698     \n",
      "Epoch 31/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.3355 - mean_absolute_error: 1.0657     \n",
      "Epoch 32/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.2039 - mean_absolute_error: 1.0401     \n",
      "Epoch 33/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.3804 - mean_absolute_error: 1.0731     \n",
      "Epoch 34/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.6076 - mean_absolute_error: 1.0936     \n",
      "Epoch 35/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.5738 - mean_absolute_error: 1.0968     \n",
      "Epoch 36/200\n",
      "10314/10314 [==============================] - 1s - loss: 3.4536 - mean_absolute_error: 1.0728     \n",
      "Epoch 37/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.8879 - mean_absolute_error: 1.0129     \n",
      "Epoch 38/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.8979 - mean_absolute_error: 1.0099     \n",
      "Epoch 39/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.7648 - mean_absolute_error: 1.0062     \n",
      "Epoch 40/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.8945 - mean_absolute_error: 1.0215     \n",
      "Epoch 41/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.8876 - mean_absolute_error: 1.0117     \n",
      "Epoch 42/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.7627 - mean_absolute_error: 0.9908     \n",
      "Epoch 43/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.8517 - mean_absolute_error: 1.0108     \n",
      "Epoch 44/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.7143 - mean_absolute_error: 0.9987     \n",
      "Epoch 45/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.7202 - mean_absolute_error: 0.9929     \n",
      "Epoch 46/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.5987 - mean_absolute_error: 0.9668     \n",
      "Epoch 47/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.4705 - mean_absolute_error: 0.9460     \n",
      "Epoch 48/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.7097 - mean_absolute_error: 0.9837     \n",
      "Epoch 49/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.5303 - mean_absolute_error: 0.9645     \n",
      "Epoch 50/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.6288 - mean_absolute_error: 0.9722     \n",
      "Epoch 51/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.9516 - mean_absolute_error: 1.0211     \n",
      "Epoch 52/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.5121 - mean_absolute_error: 0.9486     \n",
      "Epoch 53/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.4511 - mean_absolute_error: 0.9495     \n",
      "Epoch 54/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.2786 - mean_absolute_error: 0.9236     \n",
      "Epoch 55/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1212 - mean_absolute_error: 0.8988     \n",
      "Epoch 56/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1211 - mean_absolute_error: 0.9017     \n",
      "Epoch 57/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1838 - mean_absolute_error: 0.9153     \n",
      "Epoch 58/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1568 - mean_absolute_error: 0.9021     \n",
      "Epoch 59/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.0569 - mean_absolute_error: 0.8929     \n",
      "Epoch 60/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9411 - mean_absolute_error: 0.8709     \n",
      "Epoch 61/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1196 - mean_absolute_error: 0.8977     \n",
      "Epoch 62/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1703 - mean_absolute_error: 0.9122     \n",
      "Epoch 63/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1256 - mean_absolute_error: 0.8959     \n",
      "Epoch 64/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9234 - mean_absolute_error: 0.8664     \n",
      "Epoch 65/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.0312 - mean_absolute_error: 0.8843     \n",
      "Epoch 66/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8154 - mean_absolute_error: 0.8490     \n",
      "Epoch 67/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8914 - mean_absolute_error: 0.8594     \n",
      "Epoch 68/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9181 - mean_absolute_error: 0.8667     \n",
      "Epoch 69/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6662 - mean_absolute_error: 0.8243     \n",
      "Epoch 70/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9853 - mean_absolute_error: 0.8812     \n",
      "Epoch 71/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7414 - mean_absolute_error: 0.8350     \n",
      "Epoch 72/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7650 - mean_absolute_error: 0.8471     \n",
      "Epoch 73/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6184 - mean_absolute_error: 0.8138     \n",
      "Epoch 74/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6814 - mean_absolute_error: 0.8225     \n",
      "Epoch 75/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6272 - mean_absolute_error: 0.8160     \n",
      "Epoch 76/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6452 - mean_absolute_error: 0.8148     \n",
      "Epoch 77/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6068 - mean_absolute_error: 0.8048     \n",
      "Epoch 78/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7320 - mean_absolute_error: 0.8303     \n",
      "Epoch 79/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7299 - mean_absolute_error: 0.8391     \n",
      "Epoch 80/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7093 - mean_absolute_error: 0.8279     \n",
      "Epoch 81/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6830 - mean_absolute_error: 0.8208     \n",
      "Epoch 82/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5841 - mean_absolute_error: 0.7958     \n",
      "Epoch 83/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4756 - mean_absolute_error: 0.7851     \n",
      "Epoch 84/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3873 - mean_absolute_error: 0.7610     \n",
      "Epoch 85/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4544 - mean_absolute_error: 0.7790     \n",
      "Epoch 86/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5294 - mean_absolute_error: 0.7962     \n",
      "Epoch 87/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3219 - mean_absolute_error: 0.7481     \n",
      "Epoch 88/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4570 - mean_absolute_error: 0.7824     \n",
      "Epoch 89/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.2922 - mean_absolute_error: 0.7429     \n",
      "Epoch 90/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.2591 - mean_absolute_error: 0.7364     \n",
      "Epoch 91/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4879 - mean_absolute_error: 0.7875     \n",
      "Epoch 92/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.2041 - mean_absolute_error: 0.7264     \n",
      "Epoch 93/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.2439 - mean_absolute_error: 0.7320     \n",
      "Epoch 94/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3474 - mean_absolute_error: 0.7546     \n",
      "Epoch 95/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.1792 - mean_absolute_error: 0.7167     \n",
      "Epoch 96/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3443 - mean_absolute_error: 0.7462     \n",
      "Epoch 97/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7905 - mean_absolute_error: 0.8361     \n",
      "Epoch 98/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3359 - mean_absolute_error: 0.7562     \n",
      "Epoch 99/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.1632 - mean_absolute_error: 0.7103     \n",
      "Epoch 100/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3079 - mean_absolute_error: 0.7391     \n",
      "Epoch 101/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.0427 - mean_absolute_error: 0.6965     \n",
      "Epoch 102/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.0645 - mean_absolute_error: 0.6894     \n",
      "Epoch 103/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9736 - mean_absolute_error: 0.6711     \n",
      "Epoch 104/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.0589 - mean_absolute_error: 0.6872     \n",
      "Epoch 105/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.1169 - mean_absolute_error: 0.7024     \n",
      "Epoch 106/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4884 - mean_absolute_error: 0.7588     \n",
      "Epoch 107/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.0678 - mean_absolute_error: 0.6847     \n",
      "Epoch 108/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.0424 - mean_absolute_error: 0.6776     \n",
      "Epoch 109/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6752 - mean_absolute_error: 0.8036     \n",
      "Epoch 110/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.1662 - mean_absolute_error: 0.7110     \n",
      "Epoch 111/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9649 - mean_absolute_error: 0.6633     \n",
      "Epoch 112/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9728 - mean_absolute_error: 0.6662     \n",
      "Epoch 113/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9622 - mean_absolute_error: 0.6564     \n",
      "Epoch 114/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3919 - mean_absolute_error: 0.7599     \n",
      "Epoch 115/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9807 - mean_absolute_error: 0.6632     \n",
      "Epoch 116/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9585 - mean_absolute_error: 0.6584     \n",
      "Epoch 117/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.8296 - mean_absolute_error: 0.6244     \n",
      "Epoch 118/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.8244 - mean_absolute_error: 0.6274     \n",
      "Epoch 119/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9457 - mean_absolute_error: 0.6589     \n",
      "Epoch 120/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.8928 - mean_absolute_error: 0.6412     \n",
      "Epoch 121/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9464 - mean_absolute_error: 0.6514     \n",
      "Epoch 122/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9664 - mean_absolute_error: 0.6594     \n",
      "Epoch 123/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9988 - mean_absolute_error: 0.6660     \n",
      "Epoch 124/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7629 - mean_absolute_error: 0.7891     \n",
      "Epoch 125/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9791 - mean_absolute_error: 0.6626     \n",
      "Epoch 126/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7943 - mean_absolute_error: 0.6139     \n",
      "Epoch 127/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7128 - mean_absolute_error: 0.5906     \n",
      "Epoch 128/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7010 - mean_absolute_error: 0.5840     \n",
      "Epoch 129/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7100 - mean_absolute_error: 0.5879     \n",
      "Epoch 130/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6799 - mean_absolute_error: 0.5745     \n",
      "Epoch 131/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9445 - mean_absolute_error: 0.6514     \n",
      "Epoch 132/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.8470 - mean_absolute_error: 0.6222     \n",
      "Epoch 133/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7067 - mean_absolute_error: 0.5838     \n",
      "Epoch 134/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6591 - mean_absolute_error: 0.5695     \n",
      "Epoch 135/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6208 - mean_absolute_error: 0.5557     \n",
      "Epoch 136/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9533 - mean_absolute_error: 0.6466     \n",
      "Epoch 137/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.0079 - mean_absolute_error: 0.6638     \n",
      "Epoch 138/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7760 - mean_absolute_error: 0.6023     \n",
      "Epoch 139/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6659 - mean_absolute_error: 0.5698     \n",
      "Epoch 140/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7604 - mean_absolute_error: 0.5919     \n",
      "Epoch 141/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7295 - mean_absolute_error: 0.5850     \n",
      "Epoch 142/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6581 - mean_absolute_error: 0.5572     \n",
      "Epoch 143/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.1840 - mean_absolute_error: 0.7013     \n",
      "Epoch 144/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7316 - mean_absolute_error: 0.5895     \n",
      "Epoch 145/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.8842 - mean_absolute_error: 0.6262     \n",
      "Epoch 146/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6502 - mean_absolute_error: 0.5620     \n",
      "Epoch 147/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5912 - mean_absolute_error: 0.5403     \n",
      "Epoch 148/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7080 - mean_absolute_error: 0.5764     \n",
      "Epoch 149/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5984 - mean_absolute_error: 0.5436     \n",
      "Epoch 150/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5590 - mean_absolute_error: 0.5294     \n",
      "Epoch 151/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5288 - mean_absolute_error: 0.5215     \n",
      "Epoch 152/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6002 - mean_absolute_error: 0.5417     \n",
      "Epoch 153/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7205 - mean_absolute_error: 0.5743     \n",
      "Epoch 154/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6682 - mean_absolute_error: 0.5568     \n",
      "Epoch 155/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6584 - mean_absolute_error: 0.5605     \n",
      "Epoch 156/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6781 - mean_absolute_error: 0.5660     \n",
      "Epoch 157/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6740 - mean_absolute_error: 0.5630     \n",
      "Epoch 158/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5778 - mean_absolute_error: 0.5328     \n",
      "Epoch 159/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4834 - mean_absolute_error: 0.4986     \n",
      "Epoch 160/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4967 - mean_absolute_error: 0.5025     \n",
      "Epoch 161/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5378 - mean_absolute_error: 0.5151     \n",
      "Epoch 162/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5980 - mean_absolute_error: 0.5353     \n",
      "Epoch 163/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3342 - mean_absolute_error: 0.7119     \n",
      "Epoch 164/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7713 - mean_absolute_error: 0.8031     \n",
      "Epoch 165/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.9288 - mean_absolute_error: 0.6369     \n",
      "Epoch 166/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5732 - mean_absolute_error: 0.5301     \n",
      "Epoch 167/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4624 - mean_absolute_error: 0.4885     \n",
      "Epoch 168/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4166 - mean_absolute_error: 0.4676     \n",
      "Epoch 169/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4819 - mean_absolute_error: 0.4907     \n",
      "Epoch 170/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4463 - mean_absolute_error: 0.4767     \n",
      "Epoch 171/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.3640 - mean_absolute_error: 0.4422     \n",
      "Epoch 172/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4568 - mean_absolute_error: 0.4784     \n",
      "Epoch 173/200\n",
      "10314/10314 [==============================] - 2s - loss: 0.4474 - mean_absolute_error: 0.4750     \n",
      "Epoch 174/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5926 - mean_absolute_error: 0.5268     \n",
      "Epoch 175/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3940 - mean_absolute_error: 0.7196     \n",
      "Epoch 176/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.6749 - mean_absolute_error: 0.5503     \n",
      "Epoch 177/200\n",
      "10314/10314 [==============================] - 2s - loss: 0.4471 - mean_absolute_error: 0.4778     \n",
      "Epoch 178/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.3710 - mean_absolute_error: 0.4443     \n",
      "Epoch 179/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.5204 - mean_absolute_error: 0.4873     \n",
      "Epoch 180/200\n",
      "10314/10314 [==============================] - 2s - loss: 0.3757 - mean_absolute_error: 0.4456     \n",
      "Epoch 181/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.3589 - mean_absolute_error: 0.4359     \n",
      "Epoch 182/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4562 - mean_absolute_error: 0.4752     \n",
      "Epoch 183/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.3887 - mean_absolute_error: 0.4502     \n",
      "Epoch 184/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.3676 - mean_absolute_error: 0.4388     \n",
      "Epoch 185/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.4339 - mean_absolute_error: 0.4643     \n",
      "Epoch 186/200\n",
      "10314/10314 [==============================] - 1s - loss: 0.7136 - mean_absolute_error: 0.5598     \n",
      "Epoch 187/200\n",
      " 2560/10314 [======>.......................] - ETA: 1s - loss: 0.6684 - mean_absolute_error: 0.5628"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ace4923d2b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=300, init='normal', activation='relu'))\n",
    "model.add(Dense(300, init='normal', activation='relu'))\n",
    "model.add(Dense(300, init='normal', activation='relu'))\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', metrics = ['mean_absolute_error'], optimizer='adam')\n",
    "model.fit(train_x, train_y, batch_size = 64, nb_epoch = 200 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5         True\n",
       "6         True\n",
       "7        False\n",
       "8        False\n",
       "9         True\n",
       "10        True\n",
       "11        True\n",
       "12        True\n",
       "13        True\n",
       "14        True\n",
       "15       False\n",
       "16       False\n",
       "17        True\n",
       "18        True\n",
       "19        True\n",
       "20       False\n",
       "21        True\n",
       "22        True\n",
       "23        True\n",
       "24        True\n",
       "25        True\n",
       "26        True\n",
       "27       False\n",
       "28        True\n",
       "29        True\n",
       "         ...  \n",
       "10284    False\n",
       "10285    False\n",
       "10286    False\n",
       "10287     True\n",
       "10288     True\n",
       "10289    False\n",
       "10290     True\n",
       "10291    False\n",
       "10292    False\n",
       "10293    False\n",
       "10294    False\n",
       "10295     True\n",
       "10296     True\n",
       "10297    False\n",
       "10298    False\n",
       "10299    False\n",
       "10300     True\n",
       "10301     True\n",
       "10302     True\n",
       "10303     True\n",
       "10304     True\n",
       "10305     True\n",
       "10306     True\n",
       "10307    False\n",
       "10308     True\n",
       "10309     True\n",
       "10310    False\n",
       "10311    False\n",
       "10312    False\n",
       "10313     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['prediction'] - train['score'] < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2 I feel that computers do ta...</td>\n",
       "      <td>8</td>\n",
       "      <td>8.077567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>My three detaileds for this news paper article...</td>\n",
       "      <td>6</td>\n",
       "      <td>5.994410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local Newspaper @CAPS1 a take all your co...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.963473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 you ever see a ch...</td>\n",
       "      <td>10</td>\n",
       "      <td>9.945508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I've heard that not many...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.853074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 people throughout...</td>\n",
       "      <td>9</td>\n",
       "      <td>9.205441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper People, I think that computers ...</td>\n",
       "      <td>8</td>\n",
       "      <td>8.189183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>I agree that computers deffinately are an adva...</td>\n",
       "      <td>10</td>\n",
       "      <td>9.997777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, @CAPS1 is a rumor going aroun...</td>\n",
       "      <td>8</td>\n",
       "      <td>7.900826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I think computers have a p...</td>\n",
       "      <td>9</td>\n",
       "      <td>8.946049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, Have you ever wondered wha...</td>\n",
       "      <td>10</td>\n",
       "      <td>10.025285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local Newspaper A lot more people uses co...</td>\n",
       "      <td>10</td>\n",
       "      <td>9.760250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, my name is @PERSON1 I am...</td>\n",
       "      <td>7</td>\n",
       "      <td>6.807297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>The effect of people using computers isn't any...</td>\n",
       "      <td>6</td>\n",
       "      <td>6.082152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think that computers h...</td>\n",
       "      <td>8</td>\n",
       "      <td>8.029210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear news paper I think computers good for you...</td>\n",
       "      <td>7</td>\n",
       "      <td>7.271690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper, People are spending way too mu...</td>\n",
       "      <td>9</td>\n",
       "      <td>9.223738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper @CAPS1, I am writing to y...</td>\n",
       "      <td>9</td>\n",
       "      <td>8.770526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 name is @PERSON1 and I do ...</td>\n",
       "      <td>8</td>\n",
       "      <td>7.790724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper, @CAPS1 computers become more a...</td>\n",
       "      <td>8</td>\n",
       "      <td>8.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper people, I'm here to tell you th...</td>\n",
       "      <td>8</td>\n",
       "      <td>8.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, Have you ever been runni...</td>\n",
       "      <td>9</td>\n",
       "      <td>8.779888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, @CAPS1 your computer ever cra...</td>\n",
       "      <td>10</td>\n",
       "      <td>9.802985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @PERSON1, @CAPS1 these days are telling k...</td>\n",
       "      <td>9</td>\n",
       "      <td>9.014125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper people, @CAPS1! Isn't computers...</td>\n",
       "      <td>9</td>\n",
       "      <td>8.759309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you think computers are helpful? Well you s...</td>\n",
       "      <td>8</td>\n",
       "      <td>8.071255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>@ORGANIZATION1, In my opinion computers can be...</td>\n",
       "      <td>9</td>\n",
       "      <td>9.117596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1 @CAPS1 @CAPS2, Computers a...</td>\n",
       "      <td>10</td>\n",
       "      <td>10.092565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, I understand that the ide...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.873014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers are the way of the future. I believe...</td>\n",
       "      <td>10</td>\n",
       "      <td>9.713973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139</th>\n",
       "      <td>21336</td>\n",
       "      <td>8</td>\n",
       "      <td>When I had turned fifteen I was so anxious to...</td>\n",
       "      <td>36</td>\n",
       "      <td>35.940510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10141</th>\n",
       "      <td>21340</td>\n",
       "      <td>8</td>\n",
       "      <td>There have been many times in my life in whic...</td>\n",
       "      <td>37</td>\n",
       "      <td>36.909229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10169</th>\n",
       "      <td>21393</td>\n",
       "      <td>8</td>\n",
       "      <td>Imagine this, flying past trees on a @CAPS1 @...</td>\n",
       "      <td>30</td>\n",
       "      <td>30.015518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>21407</td>\n",
       "      <td>8</td>\n",
       "      <td>The @CAPS1 of @CAPS2 @CAPS3 I think of laughte...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.048862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>21409</td>\n",
       "      <td>8</td>\n",
       "      <td>Growing up with both of my parents and having...</td>\n",
       "      <td>44</td>\n",
       "      <td>44.002602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>21429</td>\n",
       "      <td>8</td>\n",
       "      <td>The @CAPS1-inspirational, @CAPS2 @CAPS3 of @CA...</td>\n",
       "      <td>55</td>\n",
       "      <td>54.845619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>21443</td>\n",
       "      <td>8</td>\n",
       "      <td>Every time I walk down the hall and I see a c...</td>\n",
       "      <td>34</td>\n",
       "      <td>33.746384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>21457</td>\n",
       "      <td>8</td>\n",
       "      <td>Like all great things in life, laughter is the...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.122013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>21458</td>\n",
       "      <td>8</td>\n",
       "      <td>In any relationship, things like physical cont...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.159382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10213</th>\n",
       "      <td>21460</td>\n",
       "      <td>8</td>\n",
       "      <td>I am going to tell you a story about when I w...</td>\n",
       "      <td>32</td>\n",
       "      <td>31.735367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10214</th>\n",
       "      <td>21462</td>\n",
       "      <td>8</td>\n",
       "      <td>There was a memory of mine that was full of l...</td>\n",
       "      <td>35</td>\n",
       "      <td>35.229076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>21463</td>\n",
       "      <td>8</td>\n",
       "      <td>@NUM1)I heard one true story about one normal ...</td>\n",
       "      <td>25</td>\n",
       "      <td>24.779554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10216</th>\n",
       "      <td>21467</td>\n",
       "      <td>8</td>\n",
       "      <td>It was my first year of @CAPS1. high school a...</td>\n",
       "      <td>45</td>\n",
       "      <td>45.224411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10220</th>\n",
       "      <td>21472</td>\n",
       "      <td>8</td>\n",
       "      <td>I have lived in @CAPS1 @CAPS2 almost my whole ...</td>\n",
       "      <td>33</td>\n",
       "      <td>32.995304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10223</th>\n",
       "      <td>21476</td>\n",
       "      <td>8</td>\n",
       "      <td>One time I was sick, and I told my mom \"I need...</td>\n",
       "      <td>28</td>\n",
       "      <td>28.158489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10224</th>\n",
       "      <td>21477</td>\n",
       "      <td>8</td>\n",
       "      <td>It was a cold @DATE1 @TIME1 when I decided to ...</td>\n",
       "      <td>28</td>\n",
       "      <td>27.923248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10227</th>\n",
       "      <td>21481</td>\n",
       "      <td>8</td>\n",
       "      <td>Have @CAPS3 ever had that one moment with some...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.220791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>21483</td>\n",
       "      <td>8</td>\n",
       "      <td>My grandfather always used to say, \"life is l...</td>\n",
       "      <td>41</td>\n",
       "      <td>40.742325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>21491</td>\n",
       "      <td>8</td>\n",
       "      <td>Life is a serious matter that should be taken...</td>\n",
       "      <td>30</td>\n",
       "      <td>30.064093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>21501</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter \"Laughter is the shortest distance...</td>\n",
       "      <td>28</td>\n",
       "      <td>27.757385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10242</th>\n",
       "      <td>21507</td>\n",
       "      <td>8</td>\n",
       "      <td>To me laughter shows the importance of life. ...</td>\n",
       "      <td>36</td>\n",
       "      <td>35.993797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10254</th>\n",
       "      <td>21531</td>\n",
       "      <td>8</td>\n",
       "      <td>@LOCATION3 has always been my place of choi...</td>\n",
       "      <td>50</td>\n",
       "      <td>49.751511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>21552</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is the best medicine for a friend in...</td>\n",
       "      <td>33</td>\n",
       "      <td>32.997883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10282</th>\n",
       "      <td>21578</td>\n",
       "      <td>8</td>\n",
       "      <td>A couple years ago when I was in middle schoo...</td>\n",
       "      <td>32</td>\n",
       "      <td>32.014767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>21579</td>\n",
       "      <td>8</td>\n",
       "      <td>One day when i was going to school with my fri...</td>\n",
       "      <td>27</td>\n",
       "      <td>27.142241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10287</th>\n",
       "      <td>21587</td>\n",
       "      <td>8</td>\n",
       "      <td>I think laughter is one of the most important ...</td>\n",
       "      <td>30</td>\n",
       "      <td>30.184860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>21604</td>\n",
       "      <td>8</td>\n",
       "      <td>Some say that laugh is the common language bet...</td>\n",
       "      <td>33</td>\n",
       "      <td>32.980846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>21613</td>\n",
       "      <td>8</td>\n",
       "      <td>Before my best friend moved away, we would st...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.227760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10305</th>\n",
       "      <td>21619</td>\n",
       "      <td>8</td>\n",
       "      <td>I dont like computers</td>\n",
       "      <td>10</td>\n",
       "      <td>9.757031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10313</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>40.137924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4455 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "9            12          1  Dear @CAPS1 @CAPS2 I feel that computers do ta...   \n",
       "11           14          1  My three detaileds for this news paper article...   \n",
       "17           22          1  Dear local Newspaper @CAPS1 a take all your co...   \n",
       "18           23          1  Dear local newspaper, @CAPS1 you ever see a ch...   \n",
       "19           24          1  Dear local newspaper, I've heard that not many...   \n",
       "23           29          1  Dear local newspaper, @CAPS1 people throughout...   \n",
       "24           30          1  Dear Newspaper People, I think that computers ...   \n",
       "25           31          1  I agree that computers deffinately are an adva...   \n",
       "28           34          1  Dear @LOCATION1, @CAPS1 is a rumor going aroun...   \n",
       "29           35          1  Dear @CAPS1 @CAPS2, I think computers have a p...   \n",
       "30           36          1  Dear @CAPS1 @CAPS2, Have you ever wondered wha...   \n",
       "32           39          1  Dear local Newspaper A lot more people uses co...   \n",
       "33           40          1  Dear local newspaper, my name is @PERSON1 I am...   \n",
       "36           43          1  The effect of people using computers isn't any...   \n",
       "51           63          1  Dear local newspaper, I think that computers h...   \n",
       "52           64          1  Dear news paper I think computers good for you...   \n",
       "53           65          1  Dear Newspaper, People are spending way too mu...   \n",
       "55           68          1  Dear Local Newspaper @CAPS1, I am writing to y...   \n",
       "64           80          1  Dear @CAPS1, @CAPS2 name is @PERSON1 and I do ...   \n",
       "69           86          1  Dear Newspaper, @CAPS1 computers become more a...   \n",
       "75           94          1  Dear Newspaper people, I'm here to tell you th...   \n",
       "81          103          1  Dear Local Newspaper, Have you ever been runni...   \n",
       "85          107          1  Dear @LOCATION1, @CAPS1 your computer ever cra...   \n",
       "88          112          1  Dear @PERSON1, @CAPS1 these days are telling k...   \n",
       "91          115          1  Dear Newspaper people, @CAPS1! Isn't computers...   \n",
       "96          121          1  Do you think computers are helpful? Well you s...   \n",
       "101         128          1  @ORGANIZATION1, In my opinion computers can be...   \n",
       "104         131          1  Dear @ORGANIZATION1 @CAPS1 @CAPS2, Computers a...   \n",
       "105         132          1  Dear @ORGANIZATION1, I understand that the ide...   \n",
       "106         134          1  Computers are the way of the future. I believe...   \n",
       "...         ...        ...                                                ...   \n",
       "10139     21336          8   When I had turned fifteen I was so anxious to...   \n",
       "10141     21340          8   There have been many times in my life in whic...   \n",
       "10169     21393          8   Imagine this, flying past trees on a @CAPS1 @...   \n",
       "10176     21407          8  The @CAPS1 of @CAPS2 @CAPS3 I think of laughte...   \n",
       "10178     21409          8   Growing up with both of my parents and having...   \n",
       "10191     21429          8  The @CAPS1-inspirational, @CAPS2 @CAPS3 of @CA...   \n",
       "10200     21443          8   Every time I walk down the hall and I see a c...   \n",
       "10210     21457          8  Like all great things in life, laughter is the...   \n",
       "10211     21458          8  In any relationship, things like physical cont...   \n",
       "10213     21460          8   I am going to tell you a story about when I w...   \n",
       "10214     21462          8   There was a memory of mine that was full of l...   \n",
       "10215     21463          8  @NUM1)I heard one true story about one normal ...   \n",
       "10216     21467          8   It was my first year of @CAPS1. high school a...   \n",
       "10220     21472          8  I have lived in @CAPS1 @CAPS2 almost my whole ...   \n",
       "10223     21476          8  One time I was sick, and I told my mom \"I need...   \n",
       "10224     21477          8  It was a cold @DATE1 @TIME1 when I decided to ...   \n",
       "10227     21481          8  Have @CAPS3 ever had that one moment with some...   \n",
       "10229     21483          8   My grandfather always used to say, \"life is l...   \n",
       "10235     21491          8   Life is a serious matter that should be taken...   \n",
       "10237     21501          8     Laughter \"Laughter is the shortest distance...   \n",
       "10242     21507          8   To me laughter shows the importance of life. ...   \n",
       "10254     21531          8     @LOCATION3 has always been my place of choi...   \n",
       "10266     21552          8   Laughter is the best medicine for a friend in...   \n",
       "10282     21578          8   A couple years ago when I was in middle schoo...   \n",
       "10283     21579          8  One day when i was going to school with my fri...   \n",
       "10287     21587          8  I think laughter is one of the most important ...   \n",
       "10296     21604          8  Some say that laugh is the common language bet...   \n",
       "10302     21613          8   Before my best friend moved away, we would st...   \n",
       "10305     21619          8                              I dont like computers   \n",
       "10313     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       score  prediction  \n",
       "9          8    8.077567  \n",
       "11         6    5.994410  \n",
       "17         3    2.963473  \n",
       "18        10    9.945508  \n",
       "19        11   10.853074  \n",
       "23         9    9.205441  \n",
       "24         8    8.189183  \n",
       "25        10    9.997777  \n",
       "28         8    7.900826  \n",
       "29         9    8.946049  \n",
       "30        10   10.025285  \n",
       "32        10    9.760250  \n",
       "33         7    6.807297  \n",
       "36         6    6.082152  \n",
       "51         8    8.029210  \n",
       "52         7    7.271690  \n",
       "53         9    9.223738  \n",
       "55         9    8.770526  \n",
       "64         8    7.790724  \n",
       "69         8    8.090912  \n",
       "75         8    8.070500  \n",
       "81         9    8.779888  \n",
       "85        10    9.802985  \n",
       "88         9    9.014125  \n",
       "91         9    8.759309  \n",
       "96         8    8.071255  \n",
       "101        9    9.117596  \n",
       "104       10   10.092565  \n",
       "105       11   10.873014  \n",
       "106       10    9.713973  \n",
       "...      ...         ...  \n",
       "10139     36   35.940510  \n",
       "10141     37   36.909229  \n",
       "10169     30   30.015518  \n",
       "10176     40   40.048862  \n",
       "10178     44   44.002602  \n",
       "10191     55   54.845619  \n",
       "10200     34   33.746384  \n",
       "10210     40   40.122013  \n",
       "10211     40   40.159382  \n",
       "10213     32   31.735367  \n",
       "10214     35   35.229076  \n",
       "10215     25   24.779554  \n",
       "10216     45   45.224411  \n",
       "10220     33   32.995304  \n",
       "10223     28   28.158489  \n",
       "10224     28   27.923248  \n",
       "10227     40   40.220791  \n",
       "10229     41   40.742325  \n",
       "10235     30   30.064093  \n",
       "10237     28   27.757385  \n",
       "10242     36   35.993797  \n",
       "10254     50   49.751511  \n",
       "10266     33   32.997883  \n",
       "10282     32   32.014767  \n",
       "10283     27   27.142241  \n",
       "10287     30   30.184860  \n",
       "10296     33   32.980846  \n",
       "10302     40   40.227760  \n",
       "10305     10    9.757031  \n",
       "10313     40   40.137924  \n",
       "\n",
       "[4455 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_y = model.predict(train_x)\n",
    "# train[\"prediction\"] = pred_y\n",
    "# train[train[\"essay_set\"] == 2]\n",
    "# train = train.drop(['rater1_domain1','rater2_domain1'], axis = 1)\n",
    "# train.columns = [u'essay_id', u'essay_set', u'essay',u'score', u'prediction']\n",
    "train[abs(train['prediction'] - train['score'])<0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zelongqiu/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2861</th>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.887145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2863</th>\n",
       "      <td>5981</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2865</th>\n",
       "      <td>5984</td>\n",
       "      <td>3</td>\n",
       "      <td>The cyclist was riding through a tower when he...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>5991</td>\n",
       "      <td>3</td>\n",
       "      <td>The features in the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.065936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>5994</td>\n",
       "      <td>3</td>\n",
       "      <td>Many different characteristics in a setting an...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.088818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>5995</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting of the story affects the cyclist i...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.250882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>5999</td>\n",
       "      <td>3</td>\n",
       "      <td>The cyclist has a couple things if he racing a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.107499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>ï¿½Do Not Exceed Posted Speed Limitï¿½ had a  roug...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.168858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>6001</td>\n",
       "      <td>3</td>\n",
       "      <td>An example of the setting affecting the cyclis...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.109348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>6006</td>\n",
       "      <td>3</td>\n",
       "      <td>The settings of the story were grveling. While...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.037999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>6011</td>\n",
       "      <td>3</td>\n",
       "      <td>In the essay the mshan writes of rough rodes t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>6012</td>\n",
       "      <td>3</td>\n",
       "      <td>Understanding, realitic, mode-all are reasonï¿½s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>6013</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting of the story affected the cyclist ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>6015</td>\n",
       "      <td>3</td>\n",
       "      <td>The features in the story great effect the cyc...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.269923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>6018</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the settings affect in the sto...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.214333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>6019</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effects the cyclist because he is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>6020</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting in the story discouraged the biker...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.101597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>6021</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.936417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>6025</td>\n",
       "      <td>3</td>\n",
       "      <td>Some of the features of the setting affect the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.194024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>6027</td>\n",
       "      <td>3</td>\n",
       "      <td>Ghost towns are not exactly the most inviting ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.011254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>6031</td>\n",
       "      <td>3</td>\n",
       "      <td>The narration of ï¿½Rough Road aheadï¿½ a solo cyc...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.860615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>6032</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting affected the cyclist a lot. One wa...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.918263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>6033</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting in ï¿½Do Not Exceed ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.807156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>6039</td>\n",
       "      <td>3</td>\n",
       "      <td>In the story ï¿½Do not exceed posted speed limit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.039311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>6042</td>\n",
       "      <td>3</td>\n",
       "      <td>The cyclist is mostly affected by his lack of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>6047</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of setting  really effects the cy...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.157363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>6049</td>\n",
       "      <td>3</td>\n",
       "      <td>In the story ï¿½Do Not Exceed Posted Speed Limit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.131902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>6050</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting of this story greatly affects the ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.084410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>6052</td>\n",
       "      <td>3</td>\n",
       "      <td>How the setting of the place effects the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.824444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>7638</td>\n",
       "      <td>3</td>\n",
       "      <td>In the essay ï¿½Rough Road Ahead: Do Not Exceed ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.877946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>7639</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affects the cyclis...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.803593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>7640</td>\n",
       "      <td>3</td>\n",
       "      <td>In the story Rough Road Ahead the author takes...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.903601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>7643</td>\n",
       "      <td>3</td>\n",
       "      <td>The features in the setting greatly affect the...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.062790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>7646</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting in the passage is working against ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.138591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>7647</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affects the cyclis...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.047660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>7648</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>7649</td>\n",
       "      <td>3</td>\n",
       "      <td>In the essay by Joe Kurmaskie many obstacles a...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.966274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>7651</td>\n",
       "      <td>3</td>\n",
       "      <td>The cyclist was affected by many features of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>7652</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting effect the cyclist...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.957326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>7654</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting of this story is outside. Yosemite...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.961528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>7656</td>\n",
       "      <td>3</td>\n",
       "      <td>The stoy of the cyclist features of the settin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.148634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>7663</td>\n",
       "      <td>3</td>\n",
       "      <td>In ï¿½Rough Road Ahead: Do Not Exceed Posted Spe...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.759870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>7664</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting affect the cyclist in many ways. \"...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.712424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>7665</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting of the road affected the cyclist i...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.945764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>7666</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.749728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>7667</td>\n",
       "      <td>3</td>\n",
       "      <td>The features in the setting affect the cyclist...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.912226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>7675</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting exhuberate the cyc...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.009054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>7676</td>\n",
       "      <td>3</td>\n",
       "      <td>Many things in the setting affect the cyclist....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.857907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>7682</td>\n",
       "      <td>3</td>\n",
       "      <td>There are many features of the setting that af...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.215079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>7684</td>\n",
       "      <td>3</td>\n",
       "      <td>In the essay, ï¿½Rough Road A head Do Not Exceed...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.033823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>7687</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effected the performence of the cy...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.796587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>7689</td>\n",
       "      <td>3</td>\n",
       "      <td>The young cycolist began his day confident in ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.244824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>7690</td>\n",
       "      <td>3</td>\n",
       "      <td>In the essay the features of the setting affec...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>7691</td>\n",
       "      <td>3</td>\n",
       "      <td>Weather, places, the will to continue ï¿½ all ar...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.929655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>7693</td>\n",
       "      <td>3</td>\n",
       "      <td>In the story, ï¿½Rough Road Ahead: Do not exceed...</td>\n",
       "      <td>3</td>\n",
       "      <td>2.794207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>7697</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.117623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>7698</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting of the story, are very dry and hum...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.796038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>7707</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.283237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>7708</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting in ï¿½Rough Road Ahe...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.037033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "2861      5979          3  The features of the setting affected the cycli...   \n",
       "2862      5980          3  Everyone travels to unfamiliar places. Sometim...   \n",
       "2863      5981          3  I believe the features of the cyclist affected...   \n",
       "2865      5984          3  The cyclist was riding through a tower when he...   \n",
       "2870      5991          3  The features in the setting affected the cycli...   \n",
       "2871      5994          3  Many different characteristics in a setting an...   \n",
       "2872      5995          3  The setting of the story affects the cyclist i...   \n",
       "2875      5999          3  The cyclist has a couple things if he racing a...   \n",
       "2876      6000          3  ï¿½Do Not Exceed Posted Speed Limitï¿½ had a  roug...   \n",
       "2877      6001          3  An example of the setting affecting the cyclis...   \n",
       "2882      6006          3  The settings of the story were grveling. While...   \n",
       "2886      6011          3  In the essay the mshan writes of rough rodes t...   \n",
       "2887      6012          3  Understanding, realitic, mode-all are reasonï¿½s...   \n",
       "2888      6013          3  The setting of the story affected the cyclist ...   \n",
       "2890      6015          3  The features in the story great effect the cyc...   \n",
       "2892      6018          3  The features of the settings affect in the sto...   \n",
       "2893      6019          3  The setting effects the cyclist because he is ...   \n",
       "2894      6020          3  The setting in the story discouraged the biker...   \n",
       "2895      6021          3  The features of the setting affect the cyclist...   \n",
       "2898      6025          3  Some of the features of the setting affect the...   \n",
       "2900      6027          3  Ghost towns are not exactly the most inviting ...   \n",
       "2904      6031          3  The narration of ï¿½Rough Road aheadï¿½ a solo cyc...   \n",
       "2905      6032          3  The setting affected the cyclist a lot. One wa...   \n",
       "2906      6033          3  The features of the setting in ï¿½Do Not Exceed ...   \n",
       "2912      6039          3  In the story ï¿½Do not exceed posted speed limit...   \n",
       "2913      6042          3  The cyclist is mostly affected by his lack of ...   \n",
       "2917      6047          3  The features of setting  really effects the cy...   \n",
       "2919      6049          3  In the story ï¿½Do Not Exceed Posted Speed Limit...   \n",
       "2920      6050          3  The setting of this story greatly affects the ...   \n",
       "2921      6052          3  How the setting of the place effects the cycli...   \n",
       "...        ...        ...                                                ...   \n",
       "4184      7638          3  In the essay ï¿½Rough Road Ahead: Do Not Exceed ...   \n",
       "4185      7639          3  The features of the setting affects the cyclis...   \n",
       "4186      7640          3  In the story Rough Road Ahead the author takes...   \n",
       "4188      7643          3  The features in the setting greatly affect the...   \n",
       "4190      7646          3  The setting in the passage is working against ...   \n",
       "4191      7647          3  The features of the setting affects the cyclis...   \n",
       "4192      7648          3  The features of the setting affect the cyclist...   \n",
       "4193      7649          3  In the essay by Joe Kurmaskie many obstacles a...   \n",
       "4194      7651          3  The cyclist was affected by many features of t...   \n",
       "4195      7652          3  The features of the setting effect the cyclist...   \n",
       "4197      7654          3  The setting of this story is outside. Yosemite...   \n",
       "4198      7656          3  The stoy of the cyclist features of the settin...   \n",
       "4202      7663          3  In ï¿½Rough Road Ahead: Do Not Exceed Posted Spe...   \n",
       "4203      7664          3  The setting affect the cyclist in many ways. \"...   \n",
       "4204      7665          3  The setting of the road affected the cyclist i...   \n",
       "4205      7666          3  The features of the setting affect the cyclist...   \n",
       "4206      7667          3  The features in the setting affect the cyclist...   \n",
       "4213      7675          3  The features of the setting exhuberate the cyc...   \n",
       "4214      7676          3  Many things in the setting affect the cyclist....   \n",
       "4220      7682          3  There are many features of the setting that af...   \n",
       "4221      7684          3  In the essay, ï¿½Rough Road A head Do Not Exceed...   \n",
       "4224      7687          3  The setting effected the performence of the cy...   \n",
       "4226      7689          3  The young cycolist began his day confident in ...   \n",
       "4227      7690          3  In the essay the features of the setting affec...   \n",
       "4228      7691          3  Weather, places, the will to continue ï¿½ all ar...   \n",
       "4230      7693          3  In the story, ï¿½Rough Road Ahead: Do not exceed...   \n",
       "4233      7697          3  The features of the setting affect the cyclist...   \n",
       "4234      7698          3  The setting of the story, are very dry and hum...   \n",
       "4241      7707          3  The features of the setting affected the cycli...   \n",
       "4242      7708          3  The features of the setting in ï¿½Rough Road Ahe...   \n",
       "\n",
       "      score  prediction  \n",
       "2861      2    1.887145  \n",
       "2862      1    0.979572  \n",
       "2863      1    1.094785  \n",
       "2865      1    0.885688  \n",
       "2870      2    2.065936  \n",
       "2871      2    2.088818  \n",
       "2872      2    2.250882  \n",
       "2875      1    1.107499  \n",
       "2876      2    2.168858  \n",
       "2877      1    1.109348  \n",
       "2882      2    2.037999  \n",
       "2886      1    1.100611  \n",
       "2887      0    0.031893  \n",
       "2888      1    0.895913  \n",
       "2890      2    2.269923  \n",
       "2892      2    2.214333  \n",
       "2893      1    0.836244  \n",
       "2894      2    2.101597  \n",
       "2895      2    1.936417  \n",
       "2898      1    1.194024  \n",
       "2900      3    3.011254  \n",
       "2904      3    2.860615  \n",
       "2905      2    1.918263  \n",
       "2906      3    2.807156  \n",
       "2912      1    1.039311  \n",
       "2913      2    2.172981  \n",
       "2917      1    1.157363  \n",
       "2919      1    1.131902  \n",
       "2920      3    3.084410  \n",
       "2921      2    1.824444  \n",
       "...     ...         ...  \n",
       "4184      2    1.877946  \n",
       "4185      2    1.803593  \n",
       "4186      2    1.903601  \n",
       "4188      2    2.062790  \n",
       "4190      1    1.138591  \n",
       "4191      2    2.047660  \n",
       "4192      0    0.262758  \n",
       "4193      2    1.966274  \n",
       "4194      1    0.926114  \n",
       "4195      2    1.957326  \n",
       "4197      1    0.961528  \n",
       "4198      1    1.148634  \n",
       "4202      3    2.759870  \n",
       "4203      2    1.712424  \n",
       "4204      2    1.945764  \n",
       "4205      2    1.749728  \n",
       "4206      2    1.912226  \n",
       "4213      2    2.009054  \n",
       "4214      2    1.857907  \n",
       "4220      1    1.215079  \n",
       "4221      3    3.033823  \n",
       "4224      3    2.796587  \n",
       "4226      3    3.244824  \n",
       "4227      2    2.001232  \n",
       "4228      2    1.929655  \n",
       "4230      3    2.794207  \n",
       "4233      2    2.117623  \n",
       "4234      2    1.796038  \n",
       "4241      2    2.283237  \n",
       "4242      3    3.037033  \n",
       "\n",
       "[792 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['essay_set'] == 3][abs(train['prediction'] - train['score'])<0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_y = np.zeros((len(pred_y),3))\n",
    "result_y[:, 0 ] = test[\"essay_set\"].values\n",
    "result_y[:,1] = test[\"essay_id\"].values\n",
    "result_y[:,2] = np.round(pred_y[:,0])\n",
    "result_y = result_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_y = np.zeros((len(pred_y),3))\n",
    "true_y[:, 0 ] = test[\"essay_set\"].values\n",
    "true_y[:,1] = test[\"essay_id\"].values\n",
    "true_y[:,2] = labels_test\n",
    "true_y = true_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.65595079  0.60566842  0.42155585  0.68330306  0.62259739  0.67250027\n",
      "  0.64822492  0.6039781 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.61912948702497483"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.evaluate(result_y, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.92041811  0.76767925  0.92922567  0.9326163   0.94218313  0.92450137\n",
      "  0.98358915  0.9679918 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93801721836579621"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress_kappa(labels_train,model.predict(train_x),train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple NN Softmax classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_kappa(y_true, y_pred, target = train):\n",
    "    y_pred = np.argmax(y_pred,axis =1)\n",
    "    y_true = np.argmax(y_true,axis = 1)\n",
    "    \n",
    "    result_y = np.zeros((len(y_pred),3))\n",
    "    result_y[:, 0 ] = target[\"essay_set\"].values\n",
    "    result_y[:,1] = target[\"essay_id\"].values\n",
    "    result_y[:,2] = y_pred\n",
    "    result_y = result_y.astype('int64')\n",
    "    \n",
    "    true_y = np.zeros((len(y_true),3))\n",
    "    true_y[:, 0 ] = target[\"essay_set\"].values\n",
    "    true_y[:,1] = target[\"essay_id\"].values\n",
    "    true_y[:,2] = y_true \n",
    "    true_y = true_y.astype('int64')\n",
    "    \n",
    "    return evaluate.evaluate(result_y, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.array(map(lambda essay: w2v[essay.split()].mean(axis = 0), texts_train))\n",
    "test_x = np.array(map(lambda essay: w2v[essay.split()].mean(axis = 0), texts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.hstack((train_x, to_categorical(train[\"essay_set\"].values)))\n",
    "test_x = np.hstack((test_x, to_categorical(test[\"essay_set\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = to_categorical(labels_train)\n",
    "test_y = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = to_categorical(np.hstack((labels_train, labels_test)))[0:len(labels_train),:]\n",
    "test_y = to_categorical(np.hstack((labels_train, labels_test)))[len(labels_train):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.5369 - acc: 0.2342     \n",
      "Epoch 2/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.7946 - acc: 0.3564     \n",
      "Epoch 3/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.6819 - acc: 0.3788     \n",
      "Epoch 4/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.6137 - acc: 0.3938     \n",
      "Epoch 5/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.5468 - acc: 0.4108     \n",
      "Epoch 6/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.4992 - acc: 0.4252     \n",
      "Epoch 7/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.4600 - acc: 0.4403     \n",
      "Epoch 8/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.4353 - acc: 0.4484     \n",
      "Epoch 9/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.4128 - acc: 0.4498     \n",
      "Epoch 10/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.3929 - acc: 0.4595     \n",
      "Epoch 11/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.3675 - acc: 0.4683     \n",
      "Epoch 12/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.3554 - acc: 0.4710     \n",
      "Epoch 13/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3411 - acc: 0.4698     \n",
      "Epoch 14/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.3236 - acc: 0.4793     \n",
      "Epoch 15/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3129 - acc: 0.4875     \n",
      "Epoch 16/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3132 - acc: 0.4860     \n",
      "Epoch 17/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2838 - acc: 0.4980     \n",
      "Epoch 18/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2736 - acc: 0.4996     \n",
      "Epoch 19/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2596 - acc: 0.5030     \n",
      "Epoch 20/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2468 - acc: 0.5124     \n",
      "Epoch 21/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2370 - acc: 0.5146     \n",
      "Epoch 22/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2364 - acc: 0.5169     \n",
      "Epoch 23/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2221 - acc: 0.5212     \n",
      "Epoch 24/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.2054 - acc: 0.5269     \n",
      "Epoch 25/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1994 - acc: 0.5283     \n",
      "Epoch 26/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1831 - acc: 0.5390     \n",
      "Epoch 27/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1823 - acc: 0.5345     \n",
      "Epoch 28/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1708 - acc: 0.5322     \n",
      "Epoch 29/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1654 - acc: 0.5377     \n",
      "Epoch 30/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1428 - acc: 0.5505     \n",
      "Epoch 31/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1440 - acc: 0.5522     \n",
      "Epoch 32/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1399 - acc: 0.5504     \n",
      "Epoch 33/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1275 - acc: 0.5579     \n",
      "Epoch 34/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1237 - acc: 0.5556     \n",
      "Epoch 35/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1044 - acc: 0.5656     \n",
      "Epoch 36/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.1009 - acc: 0.5675     \n",
      "Epoch 37/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0954 - acc: 0.5680     \n",
      "Epoch 38/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0781 - acc: 0.5776     \n",
      "Epoch 39/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0682 - acc: 0.5835     \n",
      "Epoch 40/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0695 - acc: 0.5808     \n",
      "Epoch 41/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0543 - acc: 0.5860     \n",
      "Epoch 42/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0435 - acc: 0.5879     \n",
      "Epoch 43/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0333 - acc: 0.5935     \n",
      "Epoch 44/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0330 - acc: 0.5979     \n",
      "Epoch 45/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0272 - acc: 0.5976     \n",
      "Epoch 46/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0178 - acc: 0.6035     \n",
      "Epoch 47/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0091 - acc: 0.6073     \n",
      "Epoch 48/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0057 - acc: 0.6072     \n",
      "Epoch 49/200\n",
      "10314/10314 [==============================] - 0s - loss: 1.0003 - acc: 0.6097     \n",
      "Epoch 50/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9786 - acc: 0.6160     \n",
      "Epoch 51/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9698 - acc: 0.6186     \n",
      "Epoch 52/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9539 - acc: 0.6287     \n",
      "Epoch 53/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9715 - acc: 0.6188     \n",
      "Epoch 54/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9511 - acc: 0.6284     \n",
      "Epoch 55/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9468 - acc: 0.6311     \n",
      "Epoch 56/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9342 - acc: 0.6346     \n",
      "Epoch 57/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9292 - acc: 0.6386     \n",
      "Epoch 58/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.9172 - acc: 0.6377     \n",
      "Epoch 59/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8967 - acc: 0.6557     \n",
      "Epoch 60/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8997 - acc: 0.6503     \n",
      "Epoch 61/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8896 - acc: 0.6577     \n",
      "Epoch 62/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8650 - acc: 0.6655     \n",
      "Epoch 63/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8645 - acc: 0.6638     \n",
      "Epoch 64/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8579 - acc: 0.6697     \n",
      "Epoch 65/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8568 - acc: 0.6655     \n",
      "Epoch 66/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8436 - acc: 0.6786     \n",
      "Epoch 67/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8233 - acc: 0.6805     \n",
      "Epoch 68/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8279 - acc: 0.6837     \n",
      "Epoch 69/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8175 - acc: 0.6843     \n",
      "Epoch 70/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8160 - acc: 0.6823     \n",
      "Epoch 71/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.8031 - acc: 0.6903     \n",
      "Epoch 72/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7856 - acc: 0.6971     \n",
      "Epoch 73/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7729 - acc: 0.7014     \n",
      "Epoch 74/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7775 - acc: 0.6959     \n",
      "Epoch 75/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7723 - acc: 0.7093     \n",
      "Epoch 76/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7549 - acc: 0.7134     \n",
      "Epoch 77/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7438 - acc: 0.7185     \n",
      "Epoch 78/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7576 - acc: 0.7107     \n",
      "Epoch 79/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7346 - acc: 0.7164     \n",
      "Epoch 80/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7288 - acc: 0.7191     \n",
      "Epoch 81/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.7133 - acc: 0.7290     \n",
      "Epoch 82/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6926 - acc: 0.7417     \n",
      "Epoch 83/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6849 - acc: 0.7383     \n",
      "Epoch 84/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6878 - acc: 0.7389     \n",
      "Epoch 85/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6851 - acc: 0.7378     \n",
      "Epoch 86/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6627 - acc: 0.7506     \n",
      "Epoch 87/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6542 - acc: 0.7548     \n",
      "Epoch 88/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6496 - acc: 0.7504     \n",
      "Epoch 89/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6467 - acc: 0.7559     \n",
      "Epoch 90/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6407 - acc: 0.7566     \n",
      "Epoch 91/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6158 - acc: 0.7677     \n",
      "Epoch 92/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6208 - acc: 0.7637     \n",
      "Epoch 93/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6121 - acc: 0.7697     \n",
      "Epoch 94/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.6212 - acc: 0.7648     \n",
      "Epoch 95/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5821 - acc: 0.7811     \n",
      "Epoch 96/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5834 - acc: 0.7794     \n",
      "Epoch 97/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5637 - acc: 0.7922     \n",
      "Epoch 98/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5623 - acc: 0.7929     \n",
      "Epoch 99/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5781 - acc: 0.7785     \n",
      "Epoch 100/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5753 - acc: 0.7808     \n",
      "Epoch 101/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5632 - acc: 0.7887     \n",
      "Epoch 102/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5331 - acc: 0.8011     \n",
      "Epoch 103/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5319 - acc: 0.8010     \n",
      "Epoch 104/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5457 - acc: 0.7964     \n",
      "Epoch 105/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5286 - acc: 0.8044     \n",
      "Epoch 106/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5302 - acc: 0.8020     \n",
      "Epoch 107/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5035 - acc: 0.8139     \n",
      "Epoch 108/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.5203 - acc: 0.8056     \n",
      "Epoch 109/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4677 - acc: 0.8279     \n",
      "Epoch 110/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4738 - acc: 0.8260     \n",
      "Epoch 111/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4984 - acc: 0.8083     \n",
      "Epoch 112/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4641 - acc: 0.8272     \n",
      "Epoch 113/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4503 - acc: 0.8358     \n",
      "Epoch 114/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4855 - acc: 0.8141     \n",
      "Epoch 115/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4745 - acc: 0.8236     \n",
      "Epoch 116/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4488 - acc: 0.8365     \n",
      "Epoch 117/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4437 - acc: 0.8353     \n",
      "Epoch 118/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4237 - acc: 0.8452     \n",
      "Epoch 119/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3977 - acc: 0.8556     \n",
      "Epoch 120/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4360 - acc: 0.8381     \n",
      "Epoch 121/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4106 - acc: 0.8500     \n",
      "Epoch 122/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3904 - acc: 0.8559     \n",
      "Epoch 123/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4503 - acc: 0.8341     \n",
      "Epoch 124/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.4151 - acc: 0.8463     \n",
      "Epoch 125/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3754 - acc: 0.8622     \n",
      "Epoch 126/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3977 - acc: 0.8516     \n",
      "Epoch 127/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3710 - acc: 0.8609     \n",
      "Epoch 128/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3994 - acc: 0.8512     \n",
      "Epoch 129/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3745 - acc: 0.8617     \n",
      "Epoch 130/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3803 - acc: 0.8580     \n",
      "Epoch 131/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3534 - acc: 0.8684     \n",
      "Epoch 132/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3337 - acc: 0.8806     \n",
      "Epoch 133/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3319 - acc: 0.8805     \n",
      "Epoch 134/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3563 - acc: 0.8687     \n",
      "Epoch 135/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3307 - acc: 0.8804     \n",
      "Epoch 136/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3496 - acc: 0.8732     \n",
      "Epoch 137/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3992 - acc: 0.8481     \n",
      "Epoch 138/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3145 - acc: 0.8841     \n",
      "Epoch 139/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2950 - acc: 0.8933     \n",
      "Epoch 140/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3135 - acc: 0.8849     \n",
      "Epoch 141/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3076 - acc: 0.8894     \n",
      "Epoch 142/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2811 - acc: 0.8985     \n",
      "Epoch 143/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3029 - acc: 0.8870     \n",
      "Epoch 144/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2782 - acc: 0.9010     \n",
      "Epoch 145/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3286 - acc: 0.8785     \n",
      "Epoch 146/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3159 - acc: 0.8857     \n",
      "Epoch 147/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3138 - acc: 0.8834     \n",
      "Epoch 148/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2609 - acc: 0.9060     \n",
      "Epoch 149/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2703 - acc: 0.9017     \n",
      "Epoch 150/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3308 - acc: 0.8791     \n",
      "Epoch 151/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2651 - acc: 0.9036     \n",
      "Epoch 152/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2425 - acc: 0.9127     \n",
      "Epoch 153/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2701 - acc: 0.8988     \n",
      "Epoch 154/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2666 - acc: 0.9054     \n",
      "Epoch 155/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2940 - acc: 0.8923     \n",
      "Epoch 156/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2605 - acc: 0.9084     \n",
      "Epoch 157/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2538 - acc: 0.9074     \n",
      "Epoch 158/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2187 - acc: 0.9215     \n",
      "Epoch 159/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2278 - acc: 0.9186     \n",
      "Epoch 160/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3202 - acc: 0.8818     \n",
      "Epoch 161/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2469 - acc: 0.9100     \n",
      "Epoch 162/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2207 - acc: 0.9217     \n",
      "Epoch 163/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2318 - acc: 0.9154     \n",
      "Epoch 164/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1969 - acc: 0.9302     \n",
      "Epoch 165/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2348 - acc: 0.9130     \n",
      "Epoch 166/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2444 - acc: 0.9120     \n",
      "Epoch 167/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1825 - acc: 0.9362     \n",
      "Epoch 168/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2038 - acc: 0.9310     \n",
      "Epoch 169/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2063 - acc: 0.9285     \n",
      "Epoch 170/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1837 - acc: 0.9361     \n",
      "Epoch 171/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2007 - acc: 0.9270     \n",
      "Epoch 172/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2128 - acc: 0.9251     \n",
      "Epoch 173/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2757 - acc: 0.8986     \n",
      "Epoch 174/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1765 - acc: 0.9378     \n",
      "Epoch 175/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1703 - acc: 0.9392     \n",
      "Epoch 176/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2035 - acc: 0.9303     \n",
      "Epoch 177/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.3944 - acc: 0.8687     \n",
      "Epoch 178/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1661 - acc: 0.9462     \n",
      "Epoch 179/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1453 - acc: 0.9518     \n",
      "Epoch 180/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1396 - acc: 0.9550     \n",
      "Epoch 181/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1327 - acc: 0.9561     \n",
      "Epoch 182/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1778 - acc: 0.9370     \n",
      "Epoch 183/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1710 - acc: 0.9398     \n",
      "Epoch 184/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1940 - acc: 0.9301     \n",
      "Epoch 185/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1401 - acc: 0.9519     \n",
      "Epoch 186/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1506 - acc: 0.9478     \n",
      "Epoch 187/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1601 - acc: 0.9460     \n",
      "Epoch 188/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.2642 - acc: 0.9032     \n",
      "Epoch 189/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1348 - acc: 0.9552     \n",
      "Epoch 190/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1624 - acc: 0.9448     \n",
      "Epoch 191/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1588 - acc: 0.9443     \n",
      "Epoch 192/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1726 - acc: 0.9379     \n",
      "Epoch 193/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1606 - acc: 0.9429     \n",
      "Epoch 194/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1795 - acc: 0.9337     \n",
      "Epoch 195/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1811 - acc: 0.9323     \n",
      "Epoch 196/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1883 - acc: 0.9326     \n",
      "Epoch 197/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1310 - acc: 0.9549     \n",
      "Epoch 198/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1048 - acc: 0.9665     \n",
      "Epoch 199/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.0940 - acc: 0.9704     \n",
      "Epoch 200/200\n",
      "10314/10314 [==============================] - 0s - loss: 0.1269 - acc: 0.9575     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13dbdc650>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim = 300, init='normal', activation='relu'))\n",
    "model.add(Dense(100, init='normal', activation='relu'))\n",
    "model.add(Dense(100, init='normal', activation='relu'))\n",
    "model.add(Dense(61, init='normal', activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size = 64, nb_epoch = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10314/10314 [==============================] - 2s - loss: 3.5811 - acc: 0.2116     \n",
      "Epoch 2/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.8682 - acc: 0.2145     \n",
      "Epoch 3/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.7344 - acc: 0.2152     \n",
      "Epoch 4/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.6274 - acc: 0.2153     \n",
      "Epoch 5/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.5562 - acc: 0.2150     \n",
      "Epoch 6/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.5112 - acc: 0.2181     \n",
      "Epoch 7/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.4773 - acc: 0.2172     \n",
      "Epoch 8/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.4470 - acc: 0.2170     \n",
      "Epoch 9/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.4170 - acc: 0.2211     \n",
      "Epoch 10/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.3848 - acc: 0.2354     \n",
      "Epoch 11/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.3497 - acc: 0.2560     \n",
      "Epoch 12/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.3068 - acc: 0.2902     \n",
      "Epoch 13/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.2554 - acc: 0.3086     \n",
      "Epoch 14/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.2004 - acc: 0.3137     \n",
      "Epoch 15/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1510 - acc: 0.3163     \n",
      "Epoch 16/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.1109 - acc: 0.3256     \n",
      "Epoch 17/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.0775 - acc: 0.3269     \n",
      "Epoch 18/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.0508 - acc: 0.3347     \n",
      "Epoch 19/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.0276 - acc: 0.3427     \n",
      "Epoch 20/200\n",
      "10314/10314 [==============================] - 1s - loss: 2.0085 - acc: 0.3446     \n",
      "Epoch 21/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9904 - acc: 0.3479     \n",
      "Epoch 22/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9756 - acc: 0.3496     \n",
      "Epoch 23/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9605 - acc: 0.3535     \n",
      "Epoch 24/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9474 - acc: 0.3568     \n",
      "Epoch 25/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9355 - acc: 0.3653     \n",
      "Epoch 26/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9236 - acc: 0.3603     \n",
      "Epoch 27/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9104 - acc: 0.3688     \n",
      "Epoch 28/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.9005 - acc: 0.3737     \n",
      "Epoch 29/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8897 - acc: 0.3751     \n",
      "Epoch 30/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8791 - acc: 0.3785     \n",
      "Epoch 31/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8679 - acc: 0.3831     \n",
      "Epoch 32/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8579 - acc: 0.3856     \n",
      "Epoch 33/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8482 - acc: 0.3901     \n",
      "Epoch 34/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8409 - acc: 0.3895     \n",
      "Epoch 35/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8289 - acc: 0.3941     \n",
      "Epoch 36/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8211 - acc: 0.3951     \n",
      "Epoch 37/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8138 - acc: 0.3924     \n",
      "Epoch 38/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.8061 - acc: 0.3980     \n",
      "Epoch 39/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7981 - acc: 0.4019     \n",
      "Epoch 40/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7894 - acc: 0.4045     \n",
      "Epoch 41/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7827 - acc: 0.4059     \n",
      "Epoch 42/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7731 - acc: 0.4058     \n",
      "Epoch 43/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7679 - acc: 0.4076     \n",
      "Epoch 44/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7621 - acc: 0.4079     \n",
      "Epoch 45/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7571 - acc: 0.4075     \n",
      "Epoch 46/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7512 - acc: 0.4107     \n",
      "Epoch 47/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7420 - acc: 0.4124     \n",
      "Epoch 48/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7425 - acc: 0.4148     \n",
      "Epoch 49/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7323 - acc: 0.4172     \n",
      "Epoch 50/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7277 - acc: 0.4103     \n",
      "Epoch 51/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7201 - acc: 0.4173     \n",
      "Epoch 52/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7181 - acc: 0.4142     \n",
      "Epoch 53/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7141 - acc: 0.4161     \n",
      "Epoch 54/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7097 - acc: 0.4168     \n",
      "Epoch 55/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.7036 - acc: 0.4194     \n",
      "Epoch 56/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6982 - acc: 0.4256     \n",
      "Epoch 57/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6965 - acc: 0.4233     \n",
      "Epoch 58/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6915 - acc: 0.4237     \n",
      "Epoch 59/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6858 - acc: 0.4232     \n",
      "Epoch 60/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6831 - acc: 0.4270     \n",
      "Epoch 61/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6770 - acc: 0.4288     \n",
      "Epoch 62/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6764 - acc: 0.4227     \n",
      "Epoch 63/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6691 - acc: 0.4249     \n",
      "Epoch 64/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6685 - acc: 0.4308     \n",
      "Epoch 65/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6618 - acc: 0.4313     \n",
      "Epoch 66/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6579 - acc: 0.4335     \n",
      "Epoch 67/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6558 - acc: 0.4305     \n",
      "Epoch 68/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6517 - acc: 0.4323     \n",
      "Epoch 69/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6442 - acc: 0.4347     \n",
      "Epoch 70/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6431 - acc: 0.4380     \n",
      "Epoch 71/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6442 - acc: 0.4342     \n",
      "Epoch 72/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6371 - acc: 0.4367     \n",
      "Epoch 73/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6381 - acc: 0.4362     \n",
      "Epoch 74/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6262 - acc: 0.4398     \n",
      "Epoch 75/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6321 - acc: 0.4346     \n",
      "Epoch 76/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6260 - acc: 0.4448     \n",
      "Epoch 77/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6187 - acc: 0.4414     \n",
      "Epoch 78/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6170 - acc: 0.4412     \n",
      "Epoch 79/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6166 - acc: 0.4467     \n",
      "Epoch 80/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6066 - acc: 0.4513     \n",
      "Epoch 81/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6110 - acc: 0.4495     \n",
      "Epoch 82/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.6080 - acc: 0.4454     \n",
      "Epoch 83/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5981 - acc: 0.4519     \n",
      "Epoch 84/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5938 - acc: 0.4533     \n",
      "Epoch 85/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5985 - acc: 0.4519     \n",
      "Epoch 86/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5944 - acc: 0.4562     \n",
      "Epoch 87/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5844 - acc: 0.4606     \n",
      "Epoch 88/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5887 - acc: 0.4605     \n",
      "Epoch 89/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5879 - acc: 0.4606     \n",
      "Epoch 90/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5843 - acc: 0.4600     \n",
      "Epoch 91/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5779 - acc: 0.4592     \n",
      "Epoch 92/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5690 - acc: 0.4689     \n",
      "Epoch 93/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5696 - acc: 0.4657     \n",
      "Epoch 94/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5660 - acc: 0.4668     \n",
      "Epoch 95/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5692 - acc: 0.4649     \n",
      "Epoch 96/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5586 - acc: 0.4661     \n",
      "Epoch 97/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5599 - acc: 0.4668     \n",
      "Epoch 98/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5611 - acc: 0.4660     \n",
      "Epoch 99/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5556 - acc: 0.4676     \n",
      "Epoch 100/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5500 - acc: 0.4723     \n",
      "Epoch 101/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5505 - acc: 0.4702     \n",
      "Epoch 102/200\n",
      "10314/10314 [==============================] - 2s - loss: 1.5504 - acc: 0.4739     \n",
      "Epoch 103/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5429 - acc: 0.4732     \n",
      "Epoch 104/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5409 - acc: 0.4699     \n",
      "Epoch 105/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5380 - acc: 0.4704     \n",
      "Epoch 106/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5378 - acc: 0.4769     \n",
      "Epoch 107/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5311 - acc: 0.4767     \n",
      "Epoch 108/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5335 - acc: 0.4764     \n",
      "Epoch 109/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5245 - acc: 0.4768     \n",
      "Epoch 110/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5238 - acc: 0.4784     \n",
      "Epoch 111/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5189 - acc: 0.4789     \n",
      "Epoch 112/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5252 - acc: 0.4789     \n",
      "Epoch 113/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5118 - acc: 0.4857     \n",
      "Epoch 114/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5123 - acc: 0.4821     \n",
      "Epoch 115/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5142 - acc: 0.4806     \n",
      "Epoch 116/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5049 - acc: 0.4811     \n",
      "Epoch 117/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5040 - acc: 0.4813     \n",
      "Epoch 118/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5093 - acc: 0.4778     \n",
      "Epoch 119/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.5005 - acc: 0.4841     \n",
      "Epoch 120/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4956 - acc: 0.4835     \n",
      "Epoch 121/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4979 - acc: 0.4841     \n",
      "Epoch 122/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4943 - acc: 0.4857     \n",
      "Epoch 123/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4868 - acc: 0.4893     \n",
      "Epoch 124/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4895 - acc: 0.4849     \n",
      "Epoch 125/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4876 - acc: 0.4905     \n",
      "Epoch 126/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4846 - acc: 0.4907     \n",
      "Epoch 127/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4806 - acc: 0.4898     \n",
      "Epoch 128/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4832 - acc: 0.4848     \n",
      "Epoch 129/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4736 - acc: 0.4902     \n",
      "Epoch 130/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4695 - acc: 0.4989     \n",
      "Epoch 131/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4804 - acc: 0.4910     \n",
      "Epoch 132/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4730 - acc: 0.4949     \n",
      "Epoch 133/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4651 - acc: 0.4967     \n",
      "Epoch 134/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4687 - acc: 0.4934     \n",
      "Epoch 135/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4650 - acc: 0.4944     \n",
      "Epoch 136/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4629 - acc: 0.4945     \n",
      "Epoch 137/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4578 - acc: 0.4979     \n",
      "Epoch 138/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4567 - acc: 0.4979     \n",
      "Epoch 139/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4583 - acc: 0.5002     \n",
      "Epoch 140/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4529 - acc: 0.4978     \n",
      "Epoch 141/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4479 - acc: 0.5036     \n",
      "Epoch 142/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4454 - acc: 0.5048     \n",
      "Epoch 143/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4481 - acc: 0.5015     \n",
      "Epoch 144/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4410 - acc: 0.5056     \n",
      "Epoch 145/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4433 - acc: 0.5066     \n",
      "Epoch 146/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4378 - acc: 0.5078     \n",
      "Epoch 147/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4354 - acc: 0.5081     \n",
      "Epoch 148/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4308 - acc: 0.5096     \n",
      "Epoch 149/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4368 - acc: 0.5076     \n",
      "Epoch 150/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4250 - acc: 0.5111     \n",
      "Epoch 151/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4327 - acc: 0.5099     \n",
      "Epoch 152/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4258 - acc: 0.5093     \n",
      "Epoch 153/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4252 - acc: 0.5086     \n",
      "Epoch 154/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4304 - acc: 0.5068     \n",
      "Epoch 155/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4244 - acc: 0.5096     \n",
      "Epoch 156/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4245 - acc: 0.5083     \n",
      "Epoch 157/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4211 - acc: 0.5119     \n",
      "Epoch 158/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4115 - acc: 0.5179     \n",
      "Epoch 159/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4155 - acc: 0.5131     \n",
      "Epoch 160/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4147 - acc: 0.5133     \n",
      "Epoch 161/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4078 - acc: 0.5211     \n",
      "Epoch 162/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4060 - acc: 0.5133     \n",
      "Epoch 163/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4076 - acc: 0.5112     \n",
      "Epoch 164/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4030 - acc: 0.5163     \n",
      "Epoch 165/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4026 - acc: 0.5171     \n",
      "Epoch 166/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4051 - acc: 0.5119     \n",
      "Epoch 167/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3970 - acc: 0.5197     \n",
      "Epoch 168/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3945 - acc: 0.5210     \n",
      "Epoch 169/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3950 - acc: 0.5148     \n",
      "Epoch 170/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3901 - acc: 0.5181     \n",
      "Epoch 171/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.4013 - acc: 0.5108     \n",
      "Epoch 172/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3849 - acc: 0.5292     \n",
      "Epoch 173/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3894 - acc: 0.5219     \n",
      "Epoch 174/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3892 - acc: 0.5241     \n",
      "Epoch 175/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3894 - acc: 0.5230     \n",
      "Epoch 176/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3813 - acc: 0.5289     \n",
      "Epoch 177/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3837 - acc: 0.5215     \n",
      "Epoch 178/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3828 - acc: 0.5200     \n",
      "Epoch 179/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3822 - acc: 0.5250     \n",
      "Epoch 180/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3810 - acc: 0.5213     \n",
      "Epoch 181/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3723 - acc: 0.5277     \n",
      "Epoch 182/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3808 - acc: 0.5271     \n",
      "Epoch 183/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3695 - acc: 0.5283     \n",
      "Epoch 184/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3703 - acc: 0.5283     \n",
      "Epoch 185/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3672 - acc: 0.5284     \n",
      "Epoch 186/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3637 - acc: 0.5349     \n",
      "Epoch 187/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3698 - acc: 0.5242     \n",
      "Epoch 188/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3678 - acc: 0.5282     \n",
      "Epoch 189/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3663 - acc: 0.5295     \n",
      "Epoch 190/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3662 - acc: 0.5279     \n",
      "Epoch 191/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3592 - acc: 0.5329     \n",
      "Epoch 192/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3603 - acc: 0.5344     \n",
      "Epoch 193/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3577 - acc: 0.5384     \n",
      "Epoch 194/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3591 - acc: 0.5293     \n",
      "Epoch 195/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3532 - acc: 0.5352     \n",
      "Epoch 196/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3553 - acc: 0.5302     \n",
      "Epoch 197/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3490 - acc: 0.5397     \n",
      "Epoch 198/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3444 - acc: 0.5386     \n",
      "Epoch 199/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3517 - acc: 0.5349     \n",
      "Epoch 200/200\n",
      "10314/10314 [==============================] - 1s - loss: 1.3578 - acc: 0.5319     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13eeefdd0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=300, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(150, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(150, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "\n",
    "model.add(Dense(61, init='normal', activation='softmax'))\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size = 32, nb_epoch = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216/1286 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>20716</td>\n",
       "      <td>8</td>\n",
       "      <td>A long time ago when I was in third grade I h...</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>20717</td>\n",
       "      <td>8</td>\n",
       "      <td>Softball has to be one of the single most gre...</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>20727</td>\n",
       "      <td>8</td>\n",
       "      <td>Laugher Laughter is to express delight, fun, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>20735</td>\n",
       "      <td>8</td>\n",
       "      <td>one time when i was skateboarding with my fri...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>20800</td>\n",
       "      <td>8</td>\n",
       "      <td>This true story might sound some what cheesy,...</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>20804</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is important in my life for many reas...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>20819</td>\n",
       "      <td>8</td>\n",
       "      <td>LaughterI laugh everyday. I feel a lot of dif...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>20825</td>\n",
       "      <td>8</td>\n",
       "      <td>In this essay I will be telling you about why...</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>20832</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is something that is there when you ...</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>20841</td>\n",
       "      <td>8</td>\n",
       "      <td>As we understand the benefits of laughter, we...</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>20853</td>\n",
       "      <td>8</td>\n",
       "      <td>DAIRY @CAPS1 boyfriend and I spend a lot of ti...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>20861</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter Laughter has alw...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>20862</td>\n",
       "      <td>8</td>\n",
       "      <td>\"@CAPS1!\" @CAPS2 society today loves laughter...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>20869</td>\n",
       "      <td>8</td>\n",
       "      <td>A day ...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>20877</td>\n",
       "      <td>8</td>\n",
       "      <td>I have had many great times with my grandpa. ...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>20881</td>\n",
       "      <td>8</td>\n",
       "      <td>Once upon a time, on a late rainy night my fri...</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>20919</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is a sign of good relationships. To ...</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>20948</td>\n",
       "      <td>8</td>\n",
       "      <td>During the @CAPS1 break my family went to @LO...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>20987</td>\n",
       "      <td>8</td>\n",
       "      <td>While you being to make any kinda of relatio...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>20993</td>\n",
       "      <td>8</td>\n",
       "      <td>Many have heard that laughing makes you live ...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>21004</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter can sometimes be something that every...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>21053</td>\n",
       "      <td>8</td>\n",
       "      <td>I live in a life full of laughter, I can not t...</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>21055</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is a huge part oh building friendshi...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>21060</td>\n",
       "      <td>8</td>\n",
       "      <td>The human brain is a piece of work. Its the k...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>21067</td>\n",
       "      <td>8</td>\n",
       "      <td>It all started with a book @DATE1 @DATE1 ago....</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>21083</td>\n",
       "      <td>8</td>\n",
       "      <td>The members of my immediate family are known ...</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>21111</td>\n",
       "      <td>8</td>\n",
       "      <td>Everyone knows that when it comes to coach @P...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>21122</td>\n",
       "      <td>8</td>\n",
       "      <td>The wind rose and fell, whipping against the ...</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>21133</td>\n",
       "      <td>8</td>\n",
       "      <td>My @CAPS1  @CAPS2 was a...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>21147</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is a huge part of life, in fact it i...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>21315</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter: A @CAPS1 @CAPS2 @CAPS3 of the variet...</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>21339</td>\n",
       "      <td>8</td>\n",
       "      <td>@PERSON1                               @CAPS1 ...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>21345</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughters importance in human life   In life t...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>21348</td>\n",
       "      <td>8</td>\n",
       "      <td>In all of our lives there is that one person...</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>21352</td>\n",
       "      <td>8</td>\n",
       "      <td>The @CAPS1 of The @CAPS2 @C...</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>21358</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is a @CAPS1 @CAPS2 do things like mus...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>21366</td>\n",
       "      <td>8</td>\n",
       "      <td>I slowly got up and watched as paint dripped ...</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>21369</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter is the key I think that being happy ...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>21370</td>\n",
       "      <td>8</td>\n",
       "      <td>My smile is a mask. It disguises all the past...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>21373</td>\n",
       "      <td>8</td>\n",
       "      <td>In the ninth grade I was required to give a s...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>21388</td>\n",
       "      <td>8</td>\n",
       "      <td>Family trip @CAPS1 the @DATE1 my famil...</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>21419</td>\n",
       "      <td>8</td>\n",
       "      <td>The @CAPS1 of Laughter   The @CAPS1 of a singl...</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>21426</td>\n",
       "      <td>8</td>\n",
       "      <td>When I was adopted, I didn't know what to exp...</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>21449</td>\n",
       "      <td>8</td>\n",
       "      <td>One day my friend and I were waking up late in...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>21480</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter in life is a good thing to have I b...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>21490</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter saved my life. Growing up, my life ...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>21495</td>\n",
       "      <td>8</td>\n",
       "      <td>Every one laughs, i love to laugh in fact...</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>21514</td>\n",
       "      <td>8</td>\n",
       "      <td>I think laughter should be a huge part in eve...</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>21522</td>\n",
       "      <td>8</td>\n",
       "      <td>It was the middle of @DATE1 and I was ten, bo...</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>21525</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter can be a good think and sometimes it...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>21530</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter, one of the most joyous things there...</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>21533</td>\n",
       "      <td>8</td>\n",
       "      <td>My dad and i went out to teach me how to driv...</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>21537</td>\n",
       "      <td>8</td>\n",
       "      <td>In the @DATE1 of @NUM1' I spent two weeks at ...</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>21548</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter, one of the wonderful things that we...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>21555</td>\n",
       "      <td>8</td>\n",
       "      <td>The elements of laughter is to show emotion t...</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>21558</td>\n",
       "      <td>8</td>\n",
       "      <td>Many believe that laughter is the key to the ...</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>21563</td>\n",
       "      <td>8</td>\n",
       "      <td>The sound of laughter could be one that break...</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>21570</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter A true story that involves @CAPS4 and...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>21609</td>\n",
       "      <td>8</td>\n",
       "      <td>Laughter, to me, is an important aspect of my...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>21615</td>\n",
       "      <td>8</td>\n",
       "      <td>@ORGANIZATION1  ...</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "1204     20716          8   A long time ago when I was in third grade I h...   \n",
       "1205     20717          8   Softball has to be one of the single most gre...   \n",
       "1206     20727          8   Laugher Laughter is to express delight, fun, ...   \n",
       "1207     20735          8   one time when i was skateboarding with my fri...   \n",
       "1208     20800          8   This true story might sound some what cheesy,...   \n",
       "1209     20804          8  Laughter is important in my life for many reas...   \n",
       "1210     20819          8   LaughterI laugh everyday. I feel a lot of dif...   \n",
       "1211     20825          8   In this essay I will be telling you about why...   \n",
       "1212     20832          8   Laughter is something that is there when you ...   \n",
       "1213     20841          8   As we understand the benefits of laughter, we...   \n",
       "1214     20853          8  DAIRY @CAPS1 boyfriend and I spend a lot of ti...   \n",
       "1215     20861          8                       Laughter Laughter has alw...   \n",
       "1216     20862          8   \"@CAPS1!\" @CAPS2 society today loves laughter...   \n",
       "1217     20869          8                                          A day ...   \n",
       "1218     20877          8   I have had many great times with my grandpa. ...   \n",
       "1219     20881          8  Once upon a time, on a late rainy night my fri...   \n",
       "1220     20919          8   Laughter is a sign of good relationships. To ...   \n",
       "1221     20948          8   During the @CAPS1 break my family went to @LO...   \n",
       "1222     20987          8    While you being to make any kinda of relatio...   \n",
       "1223     20993          8   Many have heard that laughing makes you live ...   \n",
       "1224     21004          8  Laughter can sometimes be something that every...   \n",
       "1225     21053          8  I live in a life full of laughter, I can not t...   \n",
       "1226     21055          8   Laughter is a huge part oh building friendshi...   \n",
       "1227     21060          8   The human brain is a piece of work. Its the k...   \n",
       "1228     21067          8   It all started with a book @DATE1 @DATE1 ago....   \n",
       "1229     21083          8   The members of my immediate family are known ...   \n",
       "1230     21111          8   Everyone knows that when it comes to coach @P...   \n",
       "1231     21122          8   The wind rose and fell, whipping against the ...   \n",
       "1232     21133          8                         My @CAPS1  @CAPS2 was a...   \n",
       "1233     21147          8   Laughter is a huge part of life, in fact it i...   \n",
       "...        ...        ...                                                ...   \n",
       "1256     21315          8  Laughter: A @CAPS1 @CAPS2 @CAPS3 of the variet...   \n",
       "1257     21339          8  @PERSON1                               @CAPS1 ...   \n",
       "1258     21345          8  Laughters importance in human life   In life t...   \n",
       "1259     21348          8    In all of our lives there is that one person...   \n",
       "1260     21352          8                     The @CAPS1 of The @CAPS2 @C...   \n",
       "1261     21358          8  Laughter is a @CAPS1 @CAPS2 do things like mus...   \n",
       "1262     21366          8   I slowly got up and watched as paint dripped ...   \n",
       "1263     21369          8   Laughter is the key I think that being happy ...   \n",
       "1264     21370          8   My smile is a mask. It disguises all the past...   \n",
       "1265     21373          8   In the ninth grade I was required to give a s...   \n",
       "1266     21388          8          Family trip @CAPS1 the @DATE1 my famil...   \n",
       "1267     21419          8  The @CAPS1 of Laughter   The @CAPS1 of a singl...   \n",
       "1268     21426          8   When I was adopted, I didn't know what to exp...   \n",
       "1269     21449          8  One day my friend and I were waking up late in...   \n",
       "1270     21480          8    Laughter in life is a good thing to have I b...   \n",
       "1271     21490          8    Laughter saved my life. Growing up, my life ...   \n",
       "1272     21495          8       Every one laughs, i love to laugh in fact...   \n",
       "1273     21514          8   I think laughter should be a huge part in eve...   \n",
       "1274     21522          8   It was the middle of @DATE1 and I was ten, bo...   \n",
       "1275     21525          8   Laughter can be a good think and sometimes it...   \n",
       "1276     21530          8   Laughter, one of the most joyous things there...   \n",
       "1277     21533          8   My dad and i went out to teach me how to driv...   \n",
       "1278     21537          8   In the @DATE1 of @NUM1' I spent two weeks at ...   \n",
       "1279     21548          8   Laughter, one of the wonderful things that we...   \n",
       "1280     21555          8   The elements of laughter is to show emotion t...   \n",
       "1281     21558          8   Many believe that laughter is the key to the ...   \n",
       "1282     21563          8   The sound of laughter could be one that break...   \n",
       "1283     21570          8  Laughter A true story that involves @CAPS4 and...   \n",
       "1284     21609          8   Laughter, to me, is an important aspect of my...   \n",
       "1285     21615          8                                @ORGANIZATION1  ...   \n",
       "\n",
       "      rater1_domain1  rater2_domain1  domain1_score  prediction  \n",
       "1204              18              16             34          40  \n",
       "1205              21              26             46          40  \n",
       "1206              16              15             31          40  \n",
       "1207              10              10             20          40  \n",
       "1208              18              15             33          40  \n",
       "1209              20              20             40          40  \n",
       "1210              15              15             30          40  \n",
       "1211              15              18             33           3  \n",
       "1212              20              18             36          40  \n",
       "1213              17              16             33          40  \n",
       "1214              15              17             32          40  \n",
       "1215              19              20             40          40  \n",
       "1216              20              25             45          40  \n",
       "1217              20              16             36          40  \n",
       "1218              20              20             40          40  \n",
       "1219              16              12             28          40  \n",
       "1220              15              19             34          40  \n",
       "1221              19              20             40          16  \n",
       "1222              20              15             35          40  \n",
       "1223              20              25             45          40  \n",
       "1224              14              15             29          40  \n",
       "1225              13              20             30          40  \n",
       "1226              15              20             35          40  \n",
       "1227              20              25             45          40  \n",
       "1228              20              21             41          40  \n",
       "1229              20              21             41          40  \n",
       "1230              18              18             36          40  \n",
       "1231              25              21             46           3  \n",
       "1232              20              15             35          40  \n",
       "1233              20              20             40          24  \n",
       "...              ...             ...            ...         ...  \n",
       "1256              20              15             35          40  \n",
       "1257              17              17             34          40  \n",
       "1258              15              17             32          40  \n",
       "1259              20              19             40          40  \n",
       "1260              17              20             37          40  \n",
       "1261              23              23             46          40  \n",
       "1262              20              21             41          40  \n",
       "1263              15              14             29          40  \n",
       "1264              16              15             31          40  \n",
       "1265              20              20             40          40  \n",
       "1266              20              18             40          40  \n",
       "1267              20              23             43          40  \n",
       "1268              21              20             41          40  \n",
       "1269              16              16             32          16  \n",
       "1270              15              17             32          40  \n",
       "1271              25              25             50          40  \n",
       "1272              18              18             36          40  \n",
       "1273              15              19             34          40  \n",
       "1274              20              18             40          40  \n",
       "1275              15              15             30          40  \n",
       "1276              25              21             46          40  \n",
       "1277              17              18             35          40  \n",
       "1278              16              17             33          40  \n",
       "1279              15              20             35          40  \n",
       "1280              10              15             25          40  \n",
       "1281              18              20             38          40  \n",
       "1282              21              25             46          40  \n",
       "1283              16              15             31          40  \n",
       "1284              20              20             40           3  \n",
       "1285              15              17             32          24  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = model.predict_classes(test_x)\n",
    "test[\"prediction\"] = pred_y\n",
    "test[test[\"essay_set\"] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_y = np.zeros((len(pred_y),3))\n",
    "result_y[:, 0 ] = test[\"essay_set\"].values\n",
    "result_y[:,1] = test[\"essay_id\"].values\n",
    "result_y[:,2] = pred_y\n",
    "result_y = result_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_y = np.zeros((len(pred_y),3))\n",
    "true_y[:, 0 ] = test[\"essay_set\"].values\n",
    "true_y[:,1] = test[\"essay_id\"].values\n",
    "true_y[:,2] = labels_test\n",
    "true_y = true_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.44044698  0.57673174  0.55416614  0.71316647  0.68496903  0.60792848\n",
      "  0.52000519  0.00146303]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53439040024221085"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.evaluate(result_y, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_hot_kappa(train_y, model.predict(train_x), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.47483219  0.53685594  0.72348302  0.76873897  0.77758093  0.77304073\n",
      "  0.58950121  0.30666794]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64320712745851172"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_kappa(train_y, model.predict(train_x), train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfdif regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 2500\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(nb_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train + texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28587 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[130]]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['hello world combinations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_matrix(texts_train, mode = 'tfidf')\n",
    "train_y = labels_train.astype('float32')\n",
    "test_x = tokenizer.texts_to_matrix(texts_test, mode = 'tfidf')\n",
    "test_y = labels_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8491, 2500)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8491/8491 [==============================] - 22s - loss: 63.7668 - mean_absolute_error: 2.0933    \n",
      "Epoch 2/50\n",
      "8491/8491 [==============================] - 20s - loss: 9.5773 - mean_absolute_error: 0.6979    \n",
      "Epoch 3/50\n",
      "8491/8491 [==============================] - 19s - loss: 6.2169 - mean_absolute_error: 0.4786    \n",
      "Epoch 4/50\n",
      "8491/8491 [==============================] - 19s - loss: 5.0973 - mean_absolute_error: 0.4334    \n",
      "Epoch 5/50\n",
      "8491/8491 [==============================] - 19s - loss: 4.5388 - mean_absolute_error: 0.4272    \n",
      "Epoch 6/50\n",
      "8491/8491 [==============================] - 19s - loss: 3.9764 - mean_absolute_error: 0.3657    \n",
      "Epoch 7/50\n",
      "8491/8491 [==============================] - 19s - loss: 3.5921 - mean_absolute_error: 0.3204    \n",
      "Epoch 8/50\n",
      "8491/8491 [==============================] - 18s - loss: 3.3834 - mean_absolute_error: 0.3134    \n",
      "Epoch 9/50\n",
      "8491/8491 [==============================] - 18s - loss: 3.2156 - mean_absolute_error: 0.3093    \n",
      "Epoch 10/50\n",
      "8491/8491 [==============================] - 18s - loss: 3.0814 - mean_absolute_error: 0.2948    \n",
      "Epoch 11/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.9656 - mean_absolute_error: 0.2917    \n",
      "Epoch 12/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.8658 - mean_absolute_error: 0.2779    \n",
      "Epoch 13/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.7317 - mean_absolute_error: 0.2422    \n",
      "Epoch 14/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.6603 - mean_absolute_error: 0.2350    \n",
      "Epoch 15/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.6151 - mean_absolute_error: 0.2405    \n",
      "Epoch 16/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.5783 - mean_absolute_error: 0.2469    \n",
      "Epoch 17/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.5145 - mean_absolute_error: 0.2374    \n",
      "Epoch 18/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.4552 - mean_absolute_error: 0.2244    \n",
      "Epoch 19/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.3960 - mean_absolute_error: 0.2152    \n",
      "Epoch 20/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.3518 - mean_absolute_error: 0.2110    \n",
      "Epoch 21/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.3291 - mean_absolute_error: 0.2228    \n",
      "Epoch 22/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.3149 - mean_absolute_error: 0.2316    \n",
      "Epoch 23/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.2787 - mean_absolute_error: 0.2264    \n",
      "Epoch 24/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.2108 - mean_absolute_error: 0.2062    \n",
      "Epoch 25/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.1642 - mean_absolute_error: 0.2025    \n",
      "Epoch 26/50\n",
      "8491/8491 [==============================] - 19s - loss: 2.1347 - mean_absolute_error: 0.2035    \n",
      "Epoch 27/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.1044 - mean_absolute_error: 0.2034    \n",
      "Epoch 28/50\n",
      "8491/8491 [==============================] - 18s - loss: 2.0848 - mean_absolute_error: 0.2073    \n",
      "Epoch 29/50\n",
      "8491/8491 [==============================] - 19s - loss: 2.0356 - mean_absolute_error: 0.1951    \n",
      "Epoch 30/50\n",
      "8491/8491 [==============================] - 19s - loss: 2.0075 - mean_absolute_error: 0.1983    \n",
      "Epoch 31/50\n",
      "8491/8491 [==============================] - 18s - loss: 1.9773 - mean_absolute_error: 0.1999    \n",
      "Epoch 32/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.9457 - mean_absolute_error: 0.1931    \n",
      "Epoch 33/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.9076 - mean_absolute_error: 0.1883    \n",
      "Epoch 34/50\n",
      "8491/8491 [==============================] - 18s - loss: 1.8828 - mean_absolute_error: 0.1874    \n",
      "Epoch 35/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.8508 - mean_absolute_error: 0.1860    \n",
      "Epoch 36/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.8179 - mean_absolute_error: 0.1812    \n",
      "Epoch 37/50\n",
      "8491/8491 [==============================] - 18s - loss: 1.7906 - mean_absolute_error: 0.1827    \n",
      "Epoch 38/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.7672 - mean_absolute_error: 0.1821    \n",
      "Epoch 39/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.7448 - mean_absolute_error: 0.1828    \n",
      "Epoch 40/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.7189 - mean_absolute_error: 0.1836    \n",
      "Epoch 41/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.6965 - mean_absolute_error: 0.1828    \n",
      "Epoch 42/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.6724 - mean_absolute_error: 0.1822    \n",
      "Epoch 43/50\n",
      "8491/8491 [==============================] - 18s - loss: 1.6458 - mean_absolute_error: 0.1870    \n",
      "Epoch 44/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.6211 - mean_absolute_error: 0.1839    \n",
      "Epoch 45/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.5856 - mean_absolute_error: 0.1724    \n",
      "Epoch 46/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.5656 - mean_absolute_error: 0.1748    \n",
      "Epoch 47/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.5484 - mean_absolute_error: 0.1801    \n",
      "Epoch 48/50\n",
      "8491/8491 [==============================] - 18s - loss: 1.5417 - mean_absolute_error: 0.1954    \n",
      "Epoch 49/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.5355 - mean_absolute_error: 0.1999    \n",
      "Epoch 50/50\n",
      "8491/8491 [==============================] - 19s - loss: 1.5091 - mean_absolute_error: 0.1922    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df68cf50>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2500, input_dim=MAX_NB_WORDS, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(1000, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(1000, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "sgd = SGD(lr=0.002)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', metrics = ['mean_absolute_error'], optimizer='adam')\n",
    "model.fit(train_x, train_y, batch_size = 128, nb_epoch = 50 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2979</td>\n",
       "      <td>2</td>\n",
       "      <td>Write a persuasive essay to a newspaper reflec...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.399050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2984</td>\n",
       "      <td>2</td>\n",
       "      <td>How @CAPS4 you feel if your favorite book was ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.906921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2996</td>\n",
       "      <td>2</td>\n",
       "      <td>If the people that are publishing and writing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.718492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3029</td>\n",
       "      <td>2</td>\n",
       "      <td>wow thats racist. as i said when i saw the mov...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.872141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3033</td>\n",
       "      <td>2</td>\n",
       "      <td>Why should we be more carefull of what we get ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>3045</td>\n",
       "      <td>2</td>\n",
       "      <td>Should books, magazines, music, movies, and ec...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>3099</td>\n",
       "      <td>2</td>\n",
       "      <td>Twilight, @PERSON1, or even The @CAPS1 @CAPS2 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.935044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>3113</td>\n",
       "      <td>2</td>\n",
       "      <td>I dont believe books should be takin off of th...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.765417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3123</td>\n",
       "      <td>2</td>\n",
       "      <td>I believe censorship should be used in librari...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.372568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>3126</td>\n",
       "      <td>2</td>\n",
       "      <td>Real life is rated @CAPS1 so why pretend it's ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.396649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>3155</td>\n",
       "      <td>2</td>\n",
       "      <td>The censorship in libraries should be as gog a...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.182782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3169</td>\n",
       "      <td>2</td>\n",
       "      <td>'And then we have no books left on the shelf f...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.994154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>3189</td>\n",
       "      <td>2</td>\n",
       "      <td>Books have been apart of every single person's...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.685853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3192</td>\n",
       "      <td>2</td>\n",
       "      <td>When I go to a library I @MONTH1 find some stu...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.501650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>3208</td>\n",
       "      <td>2</td>\n",
       "      <td>If I could remove anything from shelves of lib...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.390728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3219</td>\n",
       "      <td>2</td>\n",
       "      <td>I believe that libraries should provide any ki...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3226</td>\n",
       "      <td>2</td>\n",
       "      <td>Many places show and sell offensive material. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.644776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3243</td>\n",
       "      <td>2</td>\n",
       "      <td>Have you ever walked into the library hoping t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3262</td>\n",
       "      <td>2</td>\n",
       "      <td>How many of you have ever heard any offensive ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.430997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3265</td>\n",
       "      <td>2</td>\n",
       "      <td>A very wise man in @CAPS1 life once said, 'The...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3269</td>\n",
       "      <td>2</td>\n",
       "      <td>Typically when you walk in to a library there ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.035143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3285</td>\n",
       "      <td>2</td>\n",
       "      <td>I think that if certain materials are offensiv...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.196555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3293</td>\n",
       "      <td>2</td>\n",
       "      <td>Recently the growing issue of censorship in li...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.942841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3294</td>\n",
       "      <td>2</td>\n",
       "      <td>I believe that if you hear or read something o...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.698640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3297</td>\n",
       "      <td>2</td>\n",
       "      <td>There are many books that are not appropriate ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.621563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3298</td>\n",
       "      <td>2</td>\n",
       "      <td>Many people base their actions on their own vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.946259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3299</td>\n",
       "      <td>2</td>\n",
       "      <td>Many libraries contain books, movies, music, a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>3303</td>\n",
       "      <td>2</td>\n",
       "      <td>I'm writing this paper today to talk about cen...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.283906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3349</td>\n",
       "      <td>2</td>\n",
       "      <td>There are tons of books in the library that pe...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.958261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3350</td>\n",
       "      <td>2</td>\n",
       "      <td>I don't think that they should be removed from...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.888950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>4527</td>\n",
       "      <td>2</td>\n",
       "      <td>Today it seems as if anything you could imagin...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>4543</td>\n",
       "      <td>2</td>\n",
       "      <td>People @MONTH1 have a certain reason to take s...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.516143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4557</td>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in media has been around since the ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.797962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4564</td>\n",
       "      <td>2</td>\n",
       "      <td>Everyone has there own opinions and arguements...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4574</td>\n",
       "      <td>2</td>\n",
       "      <td>Where it @CAPS1 @CAPS2 @CAPS3     @CAPS4 up no...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.777409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4575</td>\n",
       "      <td>2</td>\n",
       "      <td>Censorship is a two sided question. There are ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.809463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4577</td>\n",
       "      <td>2</td>\n",
       "      <td>There are many things out in the 'material' wo...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4578</td>\n",
       "      <td>2</td>\n",
       "      <td>Controversy in the @CAPS1          @CAPS2 some...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.597684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>4583</td>\n",
       "      <td>2</td>\n",
       "      <td>Nobody should believe that we have the choice ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.623025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>4597</td>\n",
       "      <td>2</td>\n",
       "      <td>BAD @CAPS1     Do you really want your kids to...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.591640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>4602</td>\n",
       "      <td>2</td>\n",
       "      <td>How many of you out there absolutely love to r...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.596990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4607</td>\n",
       "      <td>2</td>\n",
       "      <td>Do yo think censorship is a good thing? Do you...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.063461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>4617</td>\n",
       "      <td>2</td>\n",
       "      <td>Everyone has found something offensive through...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.101567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>4626</td>\n",
       "      <td>2</td>\n",
       "      <td>Reading is something people choose to do for t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.623177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4641</td>\n",
       "      <td>2</td>\n",
       "      <td>I think if its offensive it should not be avav...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.566335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>4642</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear Newspaper,     I would like to start off ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.542599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4643</td>\n",
       "      <td>2</td>\n",
       "      <td>I am sending this letter to you about my views...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.024898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>4652</td>\n",
       "      <td>2</td>\n",
       "      <td>Censorship to most people means much more than...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>4657</td>\n",
       "      <td>2</td>\n",
       "      <td>Some children take books off the shelf that so...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.161367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>4658</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello @ORGANIZATION1, I am writing to talk abo...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.289247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>4670</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes I do believe that certain books, movies, m...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.136159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4680</td>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in Libraries     Have you ever came...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.874950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>4681</td>\n",
       "      <td>2</td>\n",
       "      <td>I personally do not think that books or magazi...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.157877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4696</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi, my name is mason and i'm writing about wet...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.702854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>4697</td>\n",
       "      <td>2</td>\n",
       "      <td>I am a student from @CAPS1. I wanted to let yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.044975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>4705</td>\n",
       "      <td>2</td>\n",
       "      <td>Certain material that are made to offend peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.427194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>4717</td>\n",
       "      <td>2</td>\n",
       "      <td>I think that no books should be taken away. I ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.478512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4722</td>\n",
       "      <td>2</td>\n",
       "      <td>In our socioty, a lot of people and places tak...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.685657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4728</td>\n",
       "      <td>2</td>\n",
       "      <td>I do not think that there is a need to remove ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.361415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>4751</td>\n",
       "      <td>2</td>\n",
       "      <td>I do not believe that certain materials, such ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.931227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essay_id  essay_set                                              essay  \\\n",
       "154      2979          2  Write a persuasive essay to a newspaper reflec...   \n",
       "155      2984          2  How @CAPS4 you feel if your favorite book was ...   \n",
       "156      2996          2  If the people that are publishing and writing ...   \n",
       "157      3029          2  wow thats racist. as i said when i saw the mov...   \n",
       "158      3033          2  Why should we be more carefull of what we get ...   \n",
       "159      3045          2  Should books, magazines, music, movies, and ec...   \n",
       "160      3099          2  Twilight, @PERSON1, or even The @CAPS1 @CAPS2 ...   \n",
       "161      3113          2  I dont believe books should be takin off of th...   \n",
       "162      3123          2  I believe censorship should be used in librari...   \n",
       "163      3126          2  Real life is rated @CAPS1 so why pretend it's ...   \n",
       "164      3155          2  The censorship in libraries should be as gog a...   \n",
       "165      3169          2  'And then we have no books left on the shelf f...   \n",
       "166      3189          2  Books have been apart of every single person's...   \n",
       "167      3192          2  When I go to a library I @MONTH1 find some stu...   \n",
       "168      3208          2  If I could remove anything from shelves of lib...   \n",
       "169      3219          2  I believe that libraries should provide any ki...   \n",
       "170      3226          2  Many places show and sell offensive material. ...   \n",
       "171      3243          2  Have you ever walked into the library hoping t...   \n",
       "172      3262          2  How many of you have ever heard any offensive ...   \n",
       "173      3265          2  A very wise man in @CAPS1 life once said, 'The...   \n",
       "174      3269          2  Typically when you walk in to a library there ...   \n",
       "175      3285          2  I think that if certain materials are offensiv...   \n",
       "176      3293          2  Recently the growing issue of censorship in li...   \n",
       "177      3294          2  I believe that if you hear or read something o...   \n",
       "178      3297          2  There are many books that are not appropriate ...   \n",
       "179      3298          2  Many people base their actions on their own vi...   \n",
       "180      3299          2  Many libraries contain books, movies, music, a...   \n",
       "181      3303          2  I'm writing this paper today to talk about cen...   \n",
       "182      3349          2  There are tons of books in the library that pe...   \n",
       "183      3350          2  I don't think that they should be removed from...   \n",
       "..        ...        ...                                                ...   \n",
       "293      4527          2  Today it seems as if anything you could imagin...   \n",
       "294      4543          2  People @MONTH1 have a certain reason to take s...   \n",
       "295      4557          2  Censorship in media has been around since the ...   \n",
       "296      4564          2  Everyone has there own opinions and arguements...   \n",
       "297      4574          2  Where it @CAPS1 @CAPS2 @CAPS3     @CAPS4 up no...   \n",
       "298      4575          2  Censorship is a two sided question. There are ...   \n",
       "299      4577          2  There are many things out in the 'material' wo...   \n",
       "300      4578          2  Controversy in the @CAPS1          @CAPS2 some...   \n",
       "301      4583          2  Nobody should believe that we have the choice ...   \n",
       "302      4597          2  BAD @CAPS1     Do you really want your kids to...   \n",
       "303      4602          2  How many of you out there absolutely love to r...   \n",
       "304      4607          2  Do yo think censorship is a good thing? Do you...   \n",
       "305      4617          2  Everyone has found something offensive through...   \n",
       "306      4626          2  Reading is something people choose to do for t...   \n",
       "307      4641          2  I think if its offensive it should not be avav...   \n",
       "308      4642          2  Dear Newspaper,     I would like to start off ...   \n",
       "309      4643          2  I am sending this letter to you about my views...   \n",
       "310      4652          2  Censorship to most people means much more than...   \n",
       "311      4657          2  Some children take books off the shelf that so...   \n",
       "312      4658          2  Hello @ORGANIZATION1, I am writing to talk abo...   \n",
       "313      4670          2  Yes I do believe that certain books, movies, m...   \n",
       "314      4680          2  Censorship in Libraries     Have you ever came...   \n",
       "315      4681          2  I personally do not think that books or magazi...   \n",
       "316      4696          2  Hi, my name is mason and i'm writing about wet...   \n",
       "317      4697          2  I am a student from @CAPS1. I wanted to let yo...   \n",
       "318      4705          2  Certain material that are made to offend peopl...   \n",
       "319      4717          2  I think that no books should be taken away. I ...   \n",
       "320      4722          2  In our socioty, a lot of people and places tak...   \n",
       "321      4728          2  I do not think that there is a need to remove ...   \n",
       "322      4751          2  I do not believe that certain materials, such ...   \n",
       "\n",
       "     rater1_domain1  rater2_domain1  domain1_score  prediction  \n",
       "154               1               2              1    2.399050  \n",
       "155               5               5              5    3.906921  \n",
       "156               1               1              1    2.718492  \n",
       "157               3               3              3    2.872141  \n",
       "158               4               4              4    3.931227  \n",
       "159               4               4              4    3.931227  \n",
       "160               4               4              4    3.935044  \n",
       "161               3               3              3    2.765417  \n",
       "162               4               4              4    2.372568  \n",
       "163               4               4              4    3.396649  \n",
       "164               3               3              3    3.182782  \n",
       "165               3               3              3    3.994154  \n",
       "166               4               4              4    3.685853  \n",
       "167               3               3              3    2.501650  \n",
       "168               4               4              4    3.390728  \n",
       "169               4               4              4    3.931227  \n",
       "170               4               4              4    3.644776  \n",
       "171               4               4              4    3.931227  \n",
       "172               4               4              4    3.430997  \n",
       "173               4               5              4    3.931227  \n",
       "174               4               4              4    4.035143  \n",
       "175               4               3              4    2.196555  \n",
       "176               4               5              4    2.942841  \n",
       "177               4               4              4    3.698640  \n",
       "178               3               3              3    2.621563  \n",
       "179               4               4              4    3.946259  \n",
       "180               4               4              4    3.931227  \n",
       "181               3               3              3    2.283906  \n",
       "182               3               4              3    3.958261  \n",
       "183               3               4              3    2.888950  \n",
       "..              ...             ...            ...         ...  \n",
       "293               4               3              4    3.931227  \n",
       "294               4               4              4    3.516143  \n",
       "295               4               4              4    2.797962  \n",
       "296               3               3              3    3.931227  \n",
       "297               4               4              4    3.777409  \n",
       "298               4               4              4    2.809463  \n",
       "299               5               5              5    3.931227  \n",
       "300               4               4              4    2.597684  \n",
       "301               3               3              3    3.623025  \n",
       "302               3               3              3    2.591640  \n",
       "303               4               4              4    3.596990  \n",
       "304               3               3              3    3.063461  \n",
       "305               4               4              4    3.101567  \n",
       "306               4               4              4    3.623177  \n",
       "307               3               3              3    2.566335  \n",
       "308               3               3              3    3.542599  \n",
       "309               3               3              3    3.024898  \n",
       "310               4               4              4    3.931227  \n",
       "311               1               1              1    1.161367  \n",
       "312               3               3              3    2.289247  \n",
       "313               3               3              3    3.136159  \n",
       "314               4               4              4    3.874950  \n",
       "315               3               3              3    3.157877  \n",
       "316               3               3              3    2.702854  \n",
       "317               4               4              4    4.044975  \n",
       "318               4               4              4    4.427194  \n",
       "319               2               2              2    1.478512  \n",
       "320               2               2              2    3.685657  \n",
       "321               4               4              4    3.361415  \n",
       "322               4               4              4    3.931227  \n",
       "\n",
       "[169 rows x 7 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = model.predict(test_x)\n",
    "test[\"prediction\"] = pred_y\n",
    "test[test[\"essay_set\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.9573843   0.91683706  0.96798999  0.98729912  0.98625968  0.98133063]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97311439697647051"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress_kappa(labels_train,model.predict(train_x),train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.48131304  0.52971314  0.47251242  0.69335093  0.70572218  0.594049  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58767347881919696"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress_kappa(labels_test,model.predict(test_x),test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfdif regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28587 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 1000\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(nb_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train + texts_test)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_matrix(texts_train, mode = 'tfidf')\n",
    "test_x = tokenizer.texts_to_matrix(texts_test, mode = 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = to_categorical(labels_train)\n",
    "test_y = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.hstack((train_x, to_categorical(train[\"essay_set\"].values)))\n",
    "test_x = np.hstack((test_x, to_categorical(test[\"essay_set\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8491/8491 [==============================] - 5s - loss: 4.0017 - acc: 0.3132     \n",
      "Epoch 2/50\n",
      "8491/8491 [==============================] - 3s - loss: 1.9974 - acc: 0.4904     \n",
      "Epoch 3/50\n",
      "8491/8491 [==============================] - 3s - loss: 1.5503 - acc: 0.7111     \n",
      "Epoch 4/50\n",
      "8491/8491 [==============================] - 3s - loss: 1.2658 - acc: 0.8072     \n",
      "Epoch 5/50\n",
      "8491/8491 [==============================] - 3s - loss: 1.0969 - acc: 0.8536     \n",
      "Epoch 6/50\n",
      "8491/8491 [==============================] - 4s - loss: 0.9802 - acc: 0.8719     \n",
      "Epoch 7/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.8922 - acc: 0.8780     \n",
      "Epoch 8/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.8249 - acc: 0.8832     \n",
      "Epoch 9/50\n",
      "8491/8491 [==============================] - 4s - loss: 0.7592 - acc: 0.8911     \n",
      "Epoch 10/50\n",
      "8491/8491 [==============================] - 4s - loss: 0.7128 - acc: 0.8961     \n",
      "Epoch 11/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.6794 - acc: 0.9025     \n",
      "Epoch 12/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.6650 - acc: 0.9019     \n",
      "Epoch 13/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.6850 - acc: 0.8919     \n",
      "Epoch 14/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.7148 - acc: 0.8812     \n",
      "Epoch 15/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.7514 - acc: 0.8722     \n",
      "Epoch 16/50\n",
      "8491/8491 [==============================] - 4s - loss: 0.6912 - acc: 0.8966     \n",
      "Epoch 17/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.6312 - acc: 0.9105     \n",
      "Epoch 18/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.5959 - acc: 0.9164     \n",
      "Epoch 19/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.5580 - acc: 0.9186     \n",
      "Epoch 20/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.5334 - acc: 0.9237     \n",
      "Epoch 21/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.5088 - acc: 0.9233     \n",
      "Epoch 22/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4912 - acc: 0.9275     \n",
      "Epoch 23/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4709 - acc: 0.9279     \n",
      "Epoch 24/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4533 - acc: 0.9279     \n",
      "Epoch 25/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4377 - acc: 0.9296     \n",
      "Epoch 26/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4346 - acc: 0.9276     \n",
      "Epoch 27/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4318 - acc: 0.9257     \n",
      "Epoch 28/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4157 - acc: 0.9276     \n",
      "Epoch 29/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4380 - acc: 0.9229     \n",
      "Epoch 30/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4482 - acc: 0.9191     \n",
      "Epoch 31/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4626 - acc: 0.9141     \n",
      "Epoch 32/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4936 - acc: 0.9108     \n",
      "Epoch 33/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.5315 - acc: 0.9007     \n",
      "Epoch 34/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.5208 - acc: 0.9041     \n",
      "Epoch 35/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4732 - acc: 0.9200     \n",
      "Epoch 36/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4516 - acc: 0.9255     \n",
      "Epoch 37/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4254 - acc: 0.9299     \n",
      "Epoch 38/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.4018 - acc: 0.9335     \n",
      "Epoch 39/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3943 - acc: 0.9317     \n",
      "Epoch 40/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3847 - acc: 0.9332     \n",
      "Epoch 41/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3745 - acc: 0.9323     \n",
      "Epoch 42/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3707 - acc: 0.9316     \n",
      "Epoch 43/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3588 - acc: 0.9325     \n",
      "Epoch 44/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3501 - acc: 0.9337     \n",
      "Epoch 45/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3396 - acc: 0.9340     \n",
      "Epoch 46/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3406 - acc: 0.9318     \n",
      "Epoch 47/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3428 - acc: 0.9335     \n",
      "Epoch 48/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3599 - acc: 0.9277     \n",
      "Epoch 49/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3626 - acc: 0.9253     \n",
      "Epoch 50/50\n",
      "8491/8491 [==============================] - 3s - loss: 0.3821 - acc: 0.9231     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x218d0ccd0>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=MAX_NB_WORDS, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(1000, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "model.add(Dense(1000, init='normal', activation='relu',\\\n",
    "          W_regularizer=l2(0.0001), activity_regularizer=activity_l2(0.0001)))\n",
    "\n",
    "model.add(Dense(13, init='normal', activation='softmax'))\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size = 128, nb_epoch = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I belive that computers ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, Local Newspaper @CAPS1 here to inform yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>ARE YOU @CAPS1!! Computers are great, they're ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you spend all or most of your freetime sitt...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>Some people think it is a good idea and same d...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers. One of the much enjoyed pieces of t...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>I saw in one of the news papers I got in the m...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers can affect the way people are and ho...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I agree that people are ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, everday @CAPS1 technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Newspaper: @CAPS1 you really t...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, Newspaper I would like to tell you about...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers and the @CAPS1 were a technological ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers of the @ORGANIZATION1, Computers ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>@ORGANIZATION1, @CAPS1 you @CAPS2 want your ki...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper @CAPS1, @CAPS2 people are now u...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 minute of the day ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @PERSON1, Advances in technology and comp...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local Newspaper, I believe that computers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>Have you ever thought about all the amazing th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you think computers have a negative effect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3 @CAPS4 all the talk...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear editor: More and more people use computer...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>357</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I am writing to you beca...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers of the @ORGANIZATION1, @CAPS1 you...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 you think computers have a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, The effects computers ha...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 name is @PERSON1....</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>@ORGANIZATION1, Computers are great tools and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1462</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 a world where the...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1473</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local news paper, This paper is going to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1489</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, In my opinion I feel lik...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1502</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I believe that with too ...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1508</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers. Theres fun. But there's also a down...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1511</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, The computer has been a r...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1530</td>\n",
       "      <td>1</td>\n",
       "      <td>To: @ORGANIZATION1 goes so fast, and the most ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1544</td>\n",
       "      <td>1</td>\n",
       "      <td>I People spend too much time on the computer. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1551</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper- I understand that comput...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1558</td>\n",
       "      <td>1</td>\n",
       "      <td>@PERCENT1 of all people in the @LOCATION3 have...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1562</td>\n",
       "      <td>1</td>\n",
       "      <td>The importance of computers in the modern worl...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1563</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers, one of the daily things we use and ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I am writing to you to t...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1578</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @LOCATION1 @ORGANIZATION1 I think that a...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1594</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, many people say that computers ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1596</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I agree that computers had...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1603</td>\n",
       "      <td>1</td>\n",
       "      <td>To the local Newspaper, I think using computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1605</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think the effects of c...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I strongly believe compu...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1665</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, Advances in computer technology h...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>Everyone will agree that using computers is al...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1703</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2 @CAPS3, The effects compute...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1705</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3, walking into a roo...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 name is @PERSON1 and I wan...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1719</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 about what the wo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 people are talkin...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1733</td>\n",
       "      <td>1</td>\n",
       "      <td>I think that computer are a good benefit for p...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1742</td>\n",
       "      <td>1</td>\n",
       "      <td>To whom it @MONTH1 concern; I am writing this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1763</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper: @CAPS1 you know that ove...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1785</td>\n",
       "      <td>1</td>\n",
       "      <td>My opinion is that people should have computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essay_id  essay_set                                              essay  \\\n",
       "0           4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "1          17          1  Dear Local Newspaper, I belive that computers ...   \n",
       "2          46          1  Dear, Local Newspaper @CAPS1 here to inform yo...   \n",
       "3          55          1  ARE YOU @CAPS1!! Computers are great, they're ...   \n",
       "4          61          1  Do you spend all or most of your freetime sitt...   \n",
       "5          69          1  Some people think it is a good idea and same d...   \n",
       "6          87          1  Computers. One of the much enjoyed pieces of t...   \n",
       "7         108          1  I saw in one of the news papers I got in the m...   \n",
       "8         127          1  Computers can affect the way people are and ho...   \n",
       "9         160          1  Dear local newspaper, I agree that people are ...   \n",
       "10        165          1  Dear Local Newspaper, everday @CAPS1 technolog...   \n",
       "11        168          1  Dear @LOCATION1 Newspaper: @CAPS1 you really t...   \n",
       "12        173          1  Dear, Newspaper I would like to tell you about...   \n",
       "13        176          1  Computers and the @CAPS1 were a technological ...   \n",
       "14        181          1  Dear Readers of the @ORGANIZATION1, Computers ...   \n",
       "15        218          1  @ORGANIZATION1, @CAPS1 you @CAPS2 want your ki...   \n",
       "16        247          1  Dear Newspaper @CAPS1, @CAPS2 people are now u...   \n",
       "17        263          1  Dear @ORGANIZATION1, @CAPS1 minute of the day ...   \n",
       "18        275          1  Dear @PERSON1, Advances in technology and comp...   \n",
       "19        276          1  Dear local Newspaper, I believe that computers...   \n",
       "20        291          1  Have you ever thought about all the amazing th...   \n",
       "21        299          1  Do you think computers have a negative effect ...   \n",
       "22        309          1  Dear @CAPS1 @CAPS2, @CAPS3 @CAPS4 all the talk...   \n",
       "23        342          1  Dear editor: More and more people use computer...   \n",
       "24        357          1  Dear local newspaper, I am writing to you beca...   \n",
       "25        377          1  Dear Readers of the @ORGANIZATION1, @CAPS1 you...   \n",
       "26        384          1  Dear @CAPS1, @CAPS2 you think computers have a...   \n",
       "27        404          1  Dear Local Newspaper, The effects computers ha...   \n",
       "28        409          1  Dear local newspaper, @CAPS1 name is @PERSON1....   \n",
       "29        429          1  @ORGANIZATION1, Computers are great tools and ...   \n",
       "..        ...        ...                                                ...   \n",
       "124      1462          1  Dear Local Newspaper, @CAPS1 a world where the...   \n",
       "125      1473          1  Dear local news paper, This paper is going to ...   \n",
       "126      1489          1  Dear local newspaper, In my opinion I feel lik...   \n",
       "127      1502          1  Dear local newspaper, I believe that with too ...   \n",
       "128      1508          1  Computers. Theres fun. But there's also a down...   \n",
       "129      1511          1  Dear @ORGANIZATION1, The computer has been a r...   \n",
       "130      1530          1  To: @ORGANIZATION1 goes so fast, and the most ...   \n",
       "131      1544          1  I People spend too much time on the computer. ...   \n",
       "132      1551          1  Dear local newspaper- I understand that comput...   \n",
       "133      1558          1  @PERCENT1 of all people in the @LOCATION3 have...   \n",
       "134      1562          1  The importance of computers in the modern worl...   \n",
       "135      1563          1  Computers, one of the daily things we use and ...   \n",
       "136      1575          1  Dear Local Newspaper, I am writing to you to t...   \n",
       "137      1578          1  Dear, @LOCATION1 @ORGANIZATION1 I think that a...   \n",
       "138      1594          1  Dear @CAPS1, many people say that computers ca...   \n",
       "139      1596          1  Dear @CAPS1 @CAPS2, I agree that computers had...   \n",
       "140      1603          1  To the local Newspaper, I think using computer...   \n",
       "141      1605          1  Dear local newspaper, I think the effects of c...   \n",
       "142      1644          1  Dear local newspaper, I strongly believe compu...   \n",
       "143      1665          1  Dear @CAPS1, Advances in computer technology h...   \n",
       "144      1673          1  Everyone will agree that using computers is al...   \n",
       "145      1703          1  Dear @CAPS1 @CAPS2 @CAPS3, The effects compute...   \n",
       "146      1705          1  Dear @CAPS1 @CAPS2, @CAPS3, walking into a roo...   \n",
       "147      1717          1  Dear @CAPS1, @CAPS2 name is @PERSON1 and I wan...   \n",
       "148      1719          1  Dear Local Newspaper, @CAPS1 about what the wo...   \n",
       "149      1722          1  Dear local newspaper, @CAPS1 people are talkin...   \n",
       "150      1733          1  I think that computer are a good benefit for p...   \n",
       "151      1742          1  To whom it @MONTH1 concern; I am writing this ...   \n",
       "152      1763          1  Dear Local Newspaper: @CAPS1 you know that ove...   \n",
       "153      1785          1  My opinion is that people should have computer...   \n",
       "\n",
       "     rater1_domain1  rater2_domain1  domain1_score  prediction  \n",
       "0                 5               5             10          10  \n",
       "1                 4               4              8           8  \n",
       "2                 4               4              8           2  \n",
       "3                 4               4              8           8  \n",
       "4                 4               4              8          10  \n",
       "5                 3               4              7           8  \n",
       "6                 5               5             10          10  \n",
       "7                 4               4              8          10  \n",
       "8                 4               5              9          10  \n",
       "9                 4               4              8           8  \n",
       "10                4               5              9          10  \n",
       "11                5               4              9          10  \n",
       "12                4               4              8          10  \n",
       "13                5               5             10          10  \n",
       "14                5               5             10          10  \n",
       "15                4               4              8          10  \n",
       "16                4               4              8           8  \n",
       "17                5               5             10           8  \n",
       "18                6               5             11          10  \n",
       "19                4               4              8          10  \n",
       "20                5               6             11          10  \n",
       "21                4               4              8          10  \n",
       "22                4               5              9          10  \n",
       "23                5               4              9          10  \n",
       "24                4               4              8           8  \n",
       "25                5               5             10          10  \n",
       "26                4               4              8           8  \n",
       "27                4               4              8          10  \n",
       "28                4               4              8           8  \n",
       "29                5               4              9          10  \n",
       "..              ...             ...            ...         ...  \n",
       "124               4               3              7           8  \n",
       "125               3               3              6           8  \n",
       "126               5               4              9          10  \n",
       "127               6               4             10          10  \n",
       "128               4               4              8          10  \n",
       "129               4               3              7           8  \n",
       "130               4               4              8          10  \n",
       "131               5               5             10           9  \n",
       "132               4               5              9          10  \n",
       "133               4               4              8          10  \n",
       "134               2               2              4           8  \n",
       "135               3               3              6           7  \n",
       "136               4               5              9          10  \n",
       "137               4               5              9          10  \n",
       "138               4               4              8          10  \n",
       "139               4               5              9           8  \n",
       "140               4               4              8          10  \n",
       "141               4               4              8           8  \n",
       "142               4               4              8           8  \n",
       "143               4               5              9          10  \n",
       "144               2               3              5           1  \n",
       "145               5               6             11          10  \n",
       "146               6               6             12          10  \n",
       "147               4               4              8          10  \n",
       "148               4               4              8          10  \n",
       "149               4               5              9           9  \n",
       "150               4               4              8           8  \n",
       "151               3               3              6          10  \n",
       "152               6               6             12          10  \n",
       "153               4               4              8           8  \n",
       "\n",
       "[154 rows x 7 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = model.predict_classes(test_x)\n",
    "test[\"prediction\"] = pred_y\n",
    "test[test[\"essay_set\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.8397268   0.72055908  0.98118579  0.97978893  0.88684094  0.97170524]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93702781596423268"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_kappa(train_y, model.predict(train_x), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.51761489  0.09874275  0.09022382  0.17894521  0.18033696  0.22126791]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22140911534217456"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_kappa(test_y, model.predict(test_x), test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 700\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35617 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(nb_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train + texts_test)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_sequences(texts_train)\n",
    "test_x = tokenizer.texts_to_sequences(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of data tensor:', (10314, 700))\n"
     ]
    }
   ],
   "source": [
    "train_x = pad_sequences(train_x, padding = 'post', truncating = 'post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_x = pad_sequences(test_x, padding = 'post',truncating = 'post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', train_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in word_index.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'caps',\n",
       " 2: 'people',\n",
       " 3: 'would',\n",
       " 4: 'computers',\n",
       " 5: 'time',\n",
       " 6: 'like',\n",
       " 7: 'one',\n",
       " 8: 'person',\n",
       " 9: 'computer',\n",
       " 10: 'get',\n",
       " 11: 'could',\n",
       " 12: 'also',\n",
       " 13: 'books',\n",
       " 14: 'think',\n",
       " 15: 'building',\n",
       " 16: 'num',\n",
       " 17: 'many',\n",
       " 18: 'things',\n",
       " 19: 'go',\n",
       " 20: 'family',\n",
       " 21: 'book',\n",
       " 22: 'way',\n",
       " 23: 'even',\n",
       " 24: 'author',\n",
       " 25: 'life',\n",
       " 26: 'parents',\n",
       " 27: 'know',\n",
       " 28: 'make',\n",
       " 29: 'friends',\n",
       " 30: 'good',\n",
       " 31: 'going',\n",
       " 32: 'offensive',\n",
       " 33: 'story',\n",
       " 34: 'want',\n",
       " 35: 'take',\n",
       " 36: 'us',\n",
       " 37: 'read',\n",
       " 38: 'see',\n",
       " 39: 'home',\n",
       " 40: 'day',\n",
       " 41: 'something',\n",
       " 42: 'new',\n",
       " 43: 'said',\n",
       " 44: 'mood',\n",
       " 45: 'much',\n",
       " 46: 'library',\n",
       " 47: 'got',\n",
       " 48: 'back',\n",
       " 49: 'dirigibles',\n",
       " 50: 'state',\n",
       " 51: 'use',\n",
       " 52: 'location',\n",
       " 53: 'cyclist',\n",
       " 54: 'another',\n",
       " 55: 'children',\n",
       " 56: 'organization',\n",
       " 57: 'help',\n",
       " 58: 'find',\n",
       " 59: 'music',\n",
       " 60: 'always',\n",
       " 61: 'around',\n",
       " 62: 'thing',\n",
       " 63: 'need',\n",
       " 64: 'empire',\n",
       " 65: 'really',\n",
       " 66: 'say',\n",
       " 67: 'world',\n",
       " 68: 'first',\n",
       " 69: 'kids',\n",
       " 70: 'right',\n",
       " 71: 'bad',\n",
       " 72: 'made',\n",
       " 73: 'libraries',\n",
       " 74: 'month',\n",
       " 75: 'mast',\n",
       " 76: 'movies',\n",
       " 77: 'reason',\n",
       " 78: 'patient',\n",
       " 79: 'someone',\n",
       " 80: 'paragraph',\n",
       " 81: 'everyone',\n",
       " 82: 'never',\n",
       " 83: 'school',\n",
       " 84: 'water',\n",
       " 85: 'away',\n",
       " 86: 'learn',\n",
       " 87: 'different',\n",
       " 88: 'talk',\n",
       " 89: 'went',\n",
       " 90: 'test',\n",
       " 91: 'saeng',\n",
       " 92: 'love',\n",
       " 93: 'lot',\n",
       " 94: 'example',\n",
       " 95: 'great',\n",
       " 96: 'builders',\n",
       " 97: 'believe',\n",
       " 98: 'memoir',\n",
       " 99: 'laughter',\n",
       " 100: 'happy',\n",
       " 101: 'setting',\n",
       " 102: 'still',\n",
       " 103: 'come',\n",
       " 104: 'mooring',\n",
       " 105: 'well',\n",
       " 106: 'better',\n",
       " 107: 'feel',\n",
       " 108: 'house',\n",
       " 109: 'dirigible',\n",
       " 110: 'laugh',\n",
       " 111: 'work',\n",
       " 112: 'says',\n",
       " 113: 'every',\n",
       " 114: 'able',\n",
       " 115: 'faced',\n",
       " 116: 'obstacles',\n",
       " 117: 'look',\n",
       " 118: 'little',\n",
       " 119: 'mom',\n",
       " 120: 'place',\n",
       " 121: 'dock',\n",
       " 122: 'date',\n",
       " 123: 'keep',\n",
       " 124: 'used',\n",
       " 125: 'ever',\n",
       " 126: 'came',\n",
       " 127: 'put',\n",
       " 128: 'narciso',\n",
       " 129: 'long',\n",
       " 130: 'magazines',\n",
       " 131: 'might',\n",
       " 132: 'reading',\n",
       " 133: 'hibiscus',\n",
       " 134: 'allow',\n",
       " 135: 'certain',\n",
       " 136: 'without',\n",
       " 137: 'top',\n",
       " 138: 'information',\n",
       " 139: 'give',\n",
       " 140: 'laughing',\n",
       " 141: 'everything',\n",
       " 142: 'hard',\n",
       " 143: 'important',\n",
       " 144: 'shows',\n",
       " 145: 'old',\n",
       " 146: 'online',\n",
       " 147: 'next',\n",
       " 148: 'shelves',\n",
       " 149: 'two',\n",
       " 150: 'started',\n",
       " 151: 'getting',\n",
       " 152: 'censorship',\n",
       " 153: 'fun',\n",
       " 154: 'let',\n",
       " 155: 'child',\n",
       " 156: 'last',\n",
       " 157: 'found',\n",
       " 158: 'nature',\n",
       " 159: 'society',\n",
       " 160: 'anything',\n",
       " 161: 'friend',\n",
       " 162: 'problem',\n",
       " 163: 'outside',\n",
       " 164: 'finally',\n",
       " 165: 'thought',\n",
       " 166: 'obstacle',\n",
       " 167: 'hand',\n",
       " 168: 'told',\n",
       " 169: 'others',\n",
       " 170: 'best',\n",
       " 171: 'wanted',\n",
       " 172: 'tell',\n",
       " 173: 'internet',\n",
       " 174: 'material',\n",
       " 175: 'show',\n",
       " 176: 'movie',\n",
       " 177: 'created',\n",
       " 178: 'patience',\n",
       " 179: 'end',\n",
       " 180: 'though',\n",
       " 181: 'dont',\n",
       " 182: 'makes',\n",
       " 183: 'hydrogen',\n",
       " 184: 'watch',\n",
       " 185: 'trying',\n",
       " 186: 'together',\n",
       " 187: 'wait',\n",
       " 188: 'air',\n",
       " 189: 'materials',\n",
       " 190: 'talking',\n",
       " 191: 'left',\n",
       " 192: 'play',\n",
       " 193: 'effect',\n",
       " 194: 'spend',\n",
       " 195: 'start',\n",
       " 196: 'big',\n",
       " 197: 'games',\n",
       " 198: 'nothing',\n",
       " 199: 'grateful',\n",
       " 200: 'stay',\n",
       " 201: 'took',\n",
       " 202: 'idea',\n",
       " 203: 'shelf',\n",
       " 204: 'try',\n",
       " 205: 'done',\n",
       " 206: 'enough',\n",
       " 207: 'times',\n",
       " 208: 'law',\n",
       " 209: 'dear',\n",
       " 210: 'age',\n",
       " 211: 'ways',\n",
       " 212: 'lives',\n",
       " 213: 'taken',\n",
       " 214: 'dad',\n",
       " 215: 'features',\n",
       " 216: 'saying',\n",
       " 217: 'making',\n",
       " 218: 'reasons',\n",
       " 219: 'affect',\n",
       " 220: 'using',\n",
       " 221: 'else',\n",
       " 222: 'states',\n",
       " 223: 'removed',\n",
       " 224: 'hope',\n",
       " 225: 'cause',\n",
       " 226: 'almost',\n",
       " 227: 'taking',\n",
       " 228: 'hours',\n",
       " 229: 'type',\n",
       " 230: 'rodriguez',\n",
       " 231: 'eye',\n",
       " 232: 'instead',\n",
       " 233: 'country',\n",
       " 234: 'live',\n",
       " 235: 'area',\n",
       " 236: 'face',\n",
       " 237: 'wrong',\n",
       " 238: 'winds',\n",
       " 239: 'opinion',\n",
       " 240: 'stop',\n",
       " 241: 'problems',\n",
       " 242: 'road',\n",
       " 243: 'whole',\n",
       " 244: 'today',\n",
       " 245: 'looking',\n",
       " 246: 'mean',\n",
       " 247: 'positive',\n",
       " 248: 'money',\n",
       " 249: 'due',\n",
       " 250: 'high',\n",
       " 251: 'room',\n",
       " 252: 'kind',\n",
       " 253: 'places',\n",
       " 254: 'part',\n",
       " 255: 'stuff',\n",
       " 256: 'waiting',\n",
       " 257: 'young',\n",
       " 258: 'sometimes',\n",
       " 259: 'ride',\n",
       " 260: 'year',\n",
       " 261: 'less',\n",
       " 262: 'conclusion',\n",
       " 263: 'line',\n",
       " 264: 'become',\n",
       " 265: 'percent',\n",
       " 266: 'listen',\n",
       " 267: 'spring',\n",
       " 268: 'concludes',\n",
       " 269: 'mother',\n",
       " 270: 'low',\n",
       " 271: 'since',\n",
       " 272: 'hot',\n",
       " 273: 'point',\n",
       " 274: 'sure',\n",
       " 275: 'number',\n",
       " 276: 'years',\n",
       " 277: 'second',\n",
       " 278: 'thats',\n",
       " 279: 'knew',\n",
       " 280: 'technology',\n",
       " 281: 'maybe',\n",
       " 282: 'words',\n",
       " 283: 'game',\n",
       " 284: 'enjoy',\n",
       " 285: 'geese',\n",
       " 286: 'stress',\n",
       " 287: 'matter',\n",
       " 288: 'attempting',\n",
       " 289: 'asked',\n",
       " 290: 'days',\n",
       " 291: 'close',\n",
       " 292: 'wind',\n",
       " 293: 'alot',\n",
       " 294: 'felt',\n",
       " 295: 'affected',\n",
       " 296: 'funny',\n",
       " 297: 'public',\n",
       " 298: 'agree',\n",
       " 299: 'fact',\n",
       " 300: 'anyone',\n",
       " 301: 'areas',\n",
       " 302: 'far',\n",
       " 303: 'students',\n",
       " 304: 'minutes',\n",
       " 305: 'open',\n",
       " 306: 'adults',\n",
       " 307: 'three',\n",
       " 308: 'york',\n",
       " 309: 'needed',\n",
       " 310: 'comes',\n",
       " 311: 'frame',\n",
       " 312: 'change',\n",
       " 313: 'town',\n",
       " 314: 'understand',\n",
       " 315: 'car',\n",
       " 316: 'exercise',\n",
       " 317: 'winter',\n",
       " 318: 'brother',\n",
       " 319: 'means',\n",
       " 320: 'happen',\n",
       " 321: 'playing',\n",
       " 322: 'safety',\n",
       " 323: 'hour',\n",
       " 324: 'however',\n",
       " 325: 'saw',\n",
       " 326: 'rather',\n",
       " 327: 'helps',\n",
       " 328: 'plant',\n",
       " 329: 'newspaper',\n",
       " 330: 'violent',\n",
       " 331: 'remember',\n",
       " 332: 'etc',\n",
       " 333: 'coordination',\n",
       " 334: 'highly',\n",
       " 335: 'urban',\n",
       " 336: 'called',\n",
       " 337: 'girl',\n",
       " 338: 'looked',\n",
       " 339: 'kept',\n",
       " 340: 'feeling',\n",
       " 341: 'seen',\n",
       " 342: 'hills',\n",
       " 343: 'learning',\n",
       " 344: 'flammable',\n",
       " 345: 'past',\n",
       " 346: 'flying',\n",
       " 347: 'sister',\n",
       " 348: 'kid',\n",
       " 349: 'hear',\n",
       " 350: 'mind',\n",
       " 351: 'teach',\n",
       " 352: 'airships',\n",
       " 353: 'forget',\n",
       " 354: 'real',\n",
       " 355: 'simple',\n",
       " 356: 'eyes',\n",
       " 357: 'cuban',\n",
       " 358: 'wants',\n",
       " 359: 'lastly',\n",
       " 360: 'research',\n",
       " 361: 'limit',\n",
       " 362: 'remove',\n",
       " 363: 'happened',\n",
       " 364: 'check',\n",
       " 365: 'gave',\n",
       " 366: 'currents',\n",
       " 367: 'write',\n",
       " 368: 'later',\n",
       " 369: 'gives',\n",
       " 370: 'learned',\n",
       " 371: 'realized',\n",
       " 372: 'reader',\n",
       " 373: 'ask',\n",
       " 374: 'safe',\n",
       " 375: 'turned',\n",
       " 376: 'capsnumber',\n",
       " 377: 'censored',\n",
       " 378: 'easy',\n",
       " 379: 'websites',\n",
       " 380: 'constantly',\n",
       " 381: 'sit',\n",
       " 382: 'spending',\n",
       " 383: 'magazine',\n",
       " 384: 'local',\n",
       " 385: 'section',\n",
       " 386: 'everyday',\n",
       " 387: 'strong',\n",
       " 388: 'homework',\n",
       " 389: 'rough',\n",
       " 390: 'class',\n",
       " 391: 'probably',\n",
       " 392: 'phone',\n",
       " 393: 'chat',\n",
       " 394: 'yes',\n",
       " 395: 'writing',\n",
       " 396: 'turn',\n",
       " 397: 'main',\n",
       " 398: 'side',\n",
       " 399: 'man',\n",
       " 400: 'job',\n",
       " 401: 'speed',\n",
       " 402: 'goes',\n",
       " 403: 'leave',\n",
       " 404: 'actually',\n",
       " 405: 'sitting',\n",
       " 406: 'decided',\n",
       " 407: 'parent',\n",
       " 408: 'pick',\n",
       " 409: 'city',\n",
       " 410: 'language',\n",
       " 411: 'front',\n",
       " 412: 'adult',\n",
       " 413: 'easier',\n",
       " 414: 'walk',\n",
       " 415: 'waited',\n",
       " 416: 'food',\n",
       " 417: 'soon',\n",
       " 418: 'desert',\n",
       " 419: 'ready',\n",
       " 420: 'buildings',\n",
       " 421: 'memories',\n",
       " 422: 'along',\n",
       " 423: 'loved',\n",
       " 424: 'excerpt',\n",
       " 425: 'often',\n",
       " 426: 'video',\n",
       " 427: 'nice',\n",
       " 428: 'store',\n",
       " 429: 'lack',\n",
       " 430: 'must',\n",
       " 431: 'lead',\n",
       " 432: 'inside',\n",
       " 433: 'future',\n",
       " 434: 'budding',\n",
       " 435: 'sense',\n",
       " 436: 'sad',\n",
       " 437: 'although',\n",
       " 438: 'heat',\n",
       " 439: 'heard',\n",
       " 440: 'coming',\n",
       " 441: 'true',\n",
       " 442: 'gets',\n",
       " 443: 'warm',\n",
       " 444: 'already',\n",
       " 445: 'effects',\n",
       " 446: 'door',\n",
       " 447: 'paper',\n",
       " 448: 'lost',\n",
       " 449: 'needs',\n",
       " 450: 'relationship',\n",
       " 451: 'yet',\n",
       " 452: 'knowledge',\n",
       " 453: 'simply',\n",
       " 454: 'watching',\n",
       " 455: 'dangerous',\n",
       " 456: 'move',\n",
       " 457: 'buy',\n",
       " 458: 'happiness',\n",
       " 459: 'helium',\n",
       " 460: 'freedom',\n",
       " 461: 'flower',\n",
       " 462: 'situation',\n",
       " 463: 'filled',\n",
       " 464: 'word',\n",
       " 465: 'united',\n",
       " 466: 'takes',\n",
       " 467: 'shifting',\n",
       " 468: 'care',\n",
       " 469: 'negative',\n",
       " 470: 'pass',\n",
       " 471: 'sat',\n",
       " 472: 'across',\n",
       " 473: 'talks',\n",
       " 474: 'return',\n",
       " 475: 'set',\n",
       " 476: 'add',\n",
       " 477: 'allowed',\n",
       " 478: 'thousand',\n",
       " 479: 'offended',\n",
       " 480: 'pretty',\n",
       " 481: 'seeing',\n",
       " 482: 'hurt',\n",
       " 483: 'short',\n",
       " 484: 'fire',\n",
       " 485: 'night',\n",
       " 486: 'least',\n",
       " 487: 'weather',\n",
       " 488: 'behind',\n",
       " 489: 'laughed',\n",
       " 490: 'head',\n",
       " 491: 'communicate',\n",
       " 492: 'loving',\n",
       " 493: 'thinking',\n",
       " 494: 'mad',\n",
       " 495: 'ship',\n",
       " 496: 'growing',\n",
       " 497: 'social',\n",
       " 498: 'huge',\n",
       " 499: 'topic',\n",
       " 500: 'teacher',\n",
       " 501: 'ones',\n",
       " 502: 'architects',\n",
       " 503: 'helpful',\n",
       " 504: 'bring',\n",
       " 505: 'facebook',\n",
       " 506: 'tried',\n",
       " 507: 'order',\n",
       " 508: 'ran',\n",
       " 509: 'trip',\n",
       " 510: 'choice',\n",
       " 511: 'ability',\n",
       " 512: 'name',\n",
       " 513: 'moved',\n",
       " 514: 'either',\n",
       " 515: 'fast',\n",
       " 516: 'project',\n",
       " 517: 'call',\n",
       " 518: 'older',\n",
       " 519: 'feet',\n",
       " 520: 'culture',\n",
       " 521: 'quote',\n",
       " 522: 'pictures',\n",
       " 523: 'benefit',\n",
       " 524: 'essay',\n",
       " 525: 'populated',\n",
       " 526: 'failed',\n",
       " 527: 'walked',\n",
       " 528: 'half',\n",
       " 529: 'small',\n",
       " 530: 'throughout',\n",
       " 531: 'whether',\n",
       " 532: 'land',\n",
       " 533: 'feels',\n",
       " 534: 'greatest',\n",
       " 535: 'group',\n",
       " 536: 'content',\n",
       " 537: 'history',\n",
       " 538: 'illegal',\n",
       " 539: 'experience',\n",
       " 540: 'worse',\n",
       " 541: 'began',\n",
       " 542: 'smile',\n",
       " 543: 'therefore',\n",
       " 544: 'l',\n",
       " 545: 'cool',\n",
       " 546: 'body',\n",
       " 547: 'touch',\n",
       " 548: 'self',\n",
       " 549: 'bike',\n",
       " 550: 'chance',\n",
       " 551: 'living',\n",
       " 552: 'censor',\n",
       " 553: 'flat',\n",
       " 554: 'posted',\n",
       " 555: 'sacrifice',\n",
       " 556: 'skills',\n",
       " 557: 'exceed',\n",
       " 558: 'running',\n",
       " 559: 'became',\n",
       " 560: 'tells',\n",
       " 561: 'grade',\n",
       " 562: 'neighborhood',\n",
       " 563: 'telling',\n",
       " 564: 'families',\n",
       " 565: 'helped',\n",
       " 566: 'gone',\n",
       " 567: 'ahead',\n",
       " 568: 'run',\n",
       " 569: 'everybody',\n",
       " 570: 'usually',\n",
       " 571: 'difficult',\n",
       " 572: 'terrain',\n",
       " 573: 'walking',\n",
       " 574: 'docking',\n",
       " 575: 'seem',\n",
       " 576: 'rest',\n",
       " 577: 'easily',\n",
       " 578: 'inappropriate',\n",
       " 579: 'free',\n",
       " 580: 'choose',\n",
       " 581: 'couple',\n",
       " 582: 'knowing',\n",
       " 583: 'meant',\n",
       " 584: 'jobs',\n",
       " 585: 'meet',\n",
       " 586: 'community',\n",
       " 587: 'affects',\n",
       " 588: 'communication',\n",
       " 589: 'large',\n",
       " 590: 'whatever',\n",
       " 591: 'ideas',\n",
       " 592: 'types',\n",
       " 593: 'working',\n",
       " 594: 'ended',\n",
       " 595: 'issue',\n",
       " 596: 'exercising',\n",
       " 597: 'creates',\n",
       " 598: 'snow',\n",
       " 599: 'worth',\n",
       " 600: 'drop',\n",
       " 601: 'news',\n",
       " 602: 'sun',\n",
       " 603: 'friendship',\n",
       " 604: 'realize',\n",
       " 605: 'brought',\n",
       " 606: 'deal',\n",
       " 607: 'full',\n",
       " 608: 'tired',\n",
       " 609: 'landing',\n",
       " 610: 'grow',\n",
       " 611: 'heart',\n",
       " 612: 'eat',\n",
       " 613: 'view',\n",
       " 614: 'song',\n",
       " 615: 'extremely',\n",
       " 616: 'beginning',\n",
       " 617: 'seemed',\n",
       " 618: 'amount',\n",
       " 619: 'lets',\n",
       " 620: 'lose',\n",
       " 621: 'especially',\n",
       " 622: 'favorite',\n",
       " 623: 'trouble',\n",
       " 624: 'driving',\n",
       " 625: 'kitchen',\n",
       " 626: 'cant',\n",
       " 627: 'question',\n",
       " 628: 'park',\n",
       " 629: 'five',\n",
       " 630: 'california',\n",
       " 631: 'june',\n",
       " 632: 'weight',\n",
       " 633: 'single',\n",
       " 634: 'existing',\n",
       " 635: 'cooking',\n",
       " 636: 'health',\n",
       " 637: 'knows',\n",
       " 638: 'changed',\n",
       " 639: 'boy',\n",
       " 640: 'dehydrated',\n",
       " 641: 'childhood',\n",
       " 642: 'faster',\n",
       " 643: 'hold',\n",
       " 644: 'talked',\n",
       " 645: 'riding',\n",
       " 646: 'showed',\n",
       " 647: 'student',\n",
       " 648: 'passed',\n",
       " 649: 'final',\n",
       " 650: 'men',\n",
       " 651: 'opinions',\n",
       " 652: 'upset',\n",
       " 653: 'upon',\n",
       " 654: 'bit',\n",
       " 655: 'blood',\n",
       " 656: 'considered',\n",
       " 657: 'items',\n",
       " 658: 'fly',\n",
       " 659: 'middle',\n",
       " 660: 'harder',\n",
       " 661: 'article',\n",
       " 662: 'die',\n",
       " 663: 'enjoying',\n",
       " 664: 'search',\n",
       " 665: 'younger',\n",
       " 666: 'personal',\n",
       " 667: 'team',\n",
       " 668: 'teens',\n",
       " 669: 'email',\n",
       " 670: 'drugs',\n",
       " 671: 'third',\n",
       " 672: 'leaving',\n",
       " 673: 'media',\n",
       " 674: 'education',\n",
       " 675: 'seems',\n",
       " 676: 'pressure',\n",
       " 677: 'several',\n",
       " 678: 'four',\n",
       " 679: 'cuba',\n",
       " 680: 'likely',\n",
       " 681: 'week',\n",
       " 682: 'towards',\n",
       " 683: 'text',\n",
       " 684: 'directions',\n",
       " 685: 'authors',\n",
       " 686: 'finds',\n",
       " 687: 'course',\n",
       " 688: 'hands',\n",
       " 689: 'appropriate',\n",
       " 690: 'girls',\n",
       " 691: 'listening',\n",
       " 692: 'blimps',\n",
       " 693: 'rolling',\n",
       " 694: 'amazing',\n",
       " 695: 'uses',\n",
       " 696: 'hit',\n",
       " 697: 'blimp',\n",
       " 698: 'okay',\n",
       " 699: 'pedestrians',\n",
       " 700: 'longer',\n",
       " 701: 'based',\n",
       " 702: 'father',\n",
       " 703: 'spent',\n",
       " 704: 'foot',\n",
       " 705: 'thankful',\n",
       " 706: 'form',\n",
       " 707: 'completely',\n",
       " 708: 'describes',\n",
       " 709: 'support',\n",
       " 710: 'environment',\n",
       " 711: 'major',\n",
       " 712: 'ago',\n",
       " 713: 'beautiful',\n",
       " 714: 'cold',\n",
       " 715: 'picture',\n",
       " 716: 'readers',\n",
       " 717: 'eventually',\n",
       " 718: 'plan',\n",
       " 719: 'website',\n",
       " 720: 'lots',\n",
       " 721: 'caused',\n",
       " 722: 'accident',\n",
       " 723: 'tie',\n",
       " 724: 'stated',\n",
       " 725: 'healthy',\n",
       " 726: 'given',\n",
       " 727: 'entertainment',\n",
       " 728: 'swivel',\n",
       " 729: 'possible',\n",
       " 730: 'smith',\n",
       " 731: 'answer',\n",
       " 732: 'mail',\n",
       " 733: 'pay',\n",
       " 734: 'giving',\n",
       " 735: 'banned',\n",
       " 736: 'held',\n",
       " 737: 'fine',\n",
       " 738: 'lived',\n",
       " 739: 'create',\n",
       " 740: 'cannot',\n",
       " 741: 'speech',\n",
       " 742: 'miles',\n",
       " 743: 'thinks',\n",
       " 744: 'hindenburg',\n",
       " 745: 'melt',\n",
       " 746: 'moving',\n",
       " 747: 'express',\n",
       " 748: 'allows',\n",
       " 749: 'offend',\n",
       " 750: 'screen',\n",
       " 751: 'played',\n",
       " 752: 'thank',\n",
       " 753: 'anymore',\n",
       " 754: 'moment',\n",
       " 755: 'sports',\n",
       " 756: 'journey',\n",
       " 757: 'starting',\n",
       " 758: 'starts',\n",
       " 759: 'dollars',\n",
       " 760: 'sex',\n",
       " 761: 'ten',\n",
       " 762: 'overcome',\n",
       " 763: 'weights',\n",
       " 764: 'purpose',\n",
       " 765: 'al',\n",
       " 766: 'quite',\n",
       " 767: 'schools',\n",
       " 768: 'cousin',\n",
       " 769: 'interesting',\n",
       " 770: 'foundation',\n",
       " 771: 'message',\n",
       " 772: 'interact',\n",
       " 773: 'explains',\n",
       " 774: 'allowing',\n",
       " 775: 'excited',\n",
       " 776: 'mostly',\n",
       " 777: 'jokes',\n",
       " 778: 'sites',\n",
       " 779: 'please',\n",
       " 780: 'ground',\n",
       " 781: 'dinner',\n",
       " 782: 'meaning',\n",
       " 783: 'sign',\n",
       " 784: 'subject',\n",
       " 785: 'greatly',\n",
       " 786: 'written',\n",
       " 787: 'stories',\n",
       " 788: 'overall',\n",
       " 789: 'energy',\n",
       " 790: 'fell',\n",
       " 791: 'quickly',\n",
       " 792: 'loves',\n",
       " 793: 'densely',\n",
       " 794: 'practical',\n",
       " 795: 'save',\n",
       " 796: 'censoring',\n",
       " 797: 'personally',\n",
       " 798: 'violence',\n",
       " 799: 'u',\n",
       " 800: 'alone',\n",
       " 801: 'sentence',\n",
       " 802: 'wont',\n",
       " 803: 'kinds',\n",
       " 804: 'helping',\n",
       " 805: 'closer',\n",
       " 806: 'send',\n",
       " 807: 'stopped',\n",
       " 808: 'steel',\n",
       " 809: 'hill',\n",
       " 810: 'teenagers',\n",
       " 811: 'noticed',\n",
       " 812: 'proud',\n",
       " 813: 'attention',\n",
       " 814: 'perfect',\n",
       " 815: 'becoming',\n",
       " 816: 'changes',\n",
       " 817: 'cultures',\n",
       " 818: 'street',\n",
       " 819: 'members',\n",
       " 820: 'control',\n",
       " 821: 'drive',\n",
       " 822: 'piece',\n",
       " 823: 'useful',\n",
       " 824: 'build',\n",
       " 825: 'e',\n",
       " 826: 'typing',\n",
       " 827: 'rid',\n",
       " 828: 'ends',\n",
       " 829: 'stand',\n",
       " 830: 'worry',\n",
       " 831: 'access',\n",
       " 832: 'showing',\n",
       " 833: 'happens',\n",
       " 834: 'brings',\n",
       " 835: 'birthday',\n",
       " 836: 'entire',\n",
       " 837: 'months',\n",
       " 838: 'known',\n",
       " 839: 'peoples',\n",
       " 840: 'letter',\n",
       " 841: 'im',\n",
       " 842: 'sted',\n",
       " 843: 'guy',\n",
       " 844: 'late',\n",
       " 845: 'moored',\n",
       " 846: 'bed',\n",
       " 847: 'ok',\n",
       " 848: 'race',\n",
       " 849: 'greatful',\n",
       " 850: 'catch',\n",
       " 851: 'fit',\n",
       " 852: 'caring',\n",
       " 853: 'sees',\n",
       " 854: 'case',\n",
       " 855: 'mature',\n",
       " 856: 'teachers',\n",
       " 857: 'decide',\n",
       " 858: 'immigrants',\n",
       " 859: 'likes',\n",
       " 860: 'forever',\n",
       " 861: 'finding',\n",
       " 862: 'joke',\n",
       " 863: 'benefits',\n",
       " 864: 'caught',\n",
       " 865: 'fall',\n",
       " 866: 'feelings',\n",
       " 867: 'onto',\n",
       " 868: 'morning',\n",
       " 869: 'thier',\n",
       " 870: 'countries',\n",
       " 871: 'human',\n",
       " 872: 'study',\n",
       " 873: 'thoughts',\n",
       " 874: 'within',\n",
       " 875: 'vowed',\n",
       " 876: 'doctor',\n",
       " 877: 'met',\n",
       " 878: 'imagine',\n",
       " 879: 'cut',\n",
       " 880: 'issues',\n",
       " 881: 'early',\n",
       " 882: 'sixty',\n",
       " 883: 'exactly',\n",
       " 884: 'arms',\n",
       " 885: 'snake',\n",
       " 886: 'till',\n",
       " 887: 'putting',\n",
       " 888: 'distance',\n",
       " 889: 'kurmaskie',\n",
       " 890: 'strength',\n",
       " 891: 'secondly',\n",
       " 892: 'sight',\n",
       " 893: 'cable',\n",
       " 894: 'business',\n",
       " 895: 'roof',\n",
       " 896: 'disagree',\n",
       " 897: 'impossible',\n",
       " 898: 'yosemite',\n",
       " 899: 'faraway',\n",
       " 900: 'snows',\n",
       " 901: 'travel',\n",
       " 902: 'marcia',\n",
       " 903: 'determined',\n",
       " 904: 'flowers',\n",
       " 905: 'act',\n",
       " 906: 'clearly',\n",
       " 907: 'moods',\n",
       " 908: 'reality',\n",
       " 909: 'begin',\n",
       " 910: 'shop',\n",
       " 911: 'nobody',\n",
       " 912: 'hang',\n",
       " 913: 'bored',\n",
       " 914: 'changing',\n",
       " 915: 'literature',\n",
       " 916: 'views',\n",
       " 917: 'stores',\n",
       " 918: 'somewhere',\n",
       " 919: 'load',\n",
       " 920: 'jersey',\n",
       " 921: 'amidon',\n",
       " 922: 'workers',\n",
       " 923: 'calm',\n",
       " 924: 'modifications',\n",
       " 925: 'lunch',\n",
       " 926: 'whats',\n",
       " 927: 'taught',\n",
       " 928: 'contact',\n",
       " 929: 'silently',\n",
       " 930: 'biggest',\n",
       " 931: 'determination',\n",
       " 932: 'eating',\n",
       " 933: 'table',\n",
       " 934: 'web',\n",
       " 935: 'songs',\n",
       " 936: 'interacting',\n",
       " 937: 'daily',\n",
       " 938: 'didnt',\n",
       " 939: 'addicted',\n",
       " 940: 'reach',\n",
       " 941: 'grew',\n",
       " 942: 'passengers',\n",
       " 943: 'drink',\n",
       " 944: 'break',\n",
       " 945: 'boring',\n",
       " 946: 'guess',\n",
       " 947: 'fresh',\n",
       " 948: 'light',\n",
       " 949: 'serious',\n",
       " 950: 'risk',\n",
       " 951: 'videos',\n",
       " 952: 'character',\n",
       " 953: 'myspace',\n",
       " 954: 'educational',\n",
       " 955: 'hundred',\n",
       " 956: 'tether',\n",
       " 957: 'explain',\n",
       " 958: 'fair',\n",
       " 959: 'fight',\n",
       " 960: 'share',\n",
       " 961: 'wrote',\n",
       " 962: 'wonderful',\n",
       " 963: 'near',\n",
       " 964: 'deserts',\n",
       " 965: 'happening',\n",
       " 966: 'crazy',\n",
       " 967: 'continue',\n",
       " 968: 'removing',\n",
       " 969: 'projects',\n",
       " 970: 'waste',\n",
       " 971: 'somebody',\n",
       " 972: 'ball',\n",
       " 973: 'bus',\n",
       " 974: 'rated',\n",
       " 975: 'looks',\n",
       " 976: 'gas',\n",
       " 977: 'provide',\n",
       " 978: 'gratitude',\n",
       " 979: 'sound',\n",
       " 980: 'office',\n",
       " 981: 'works',\n",
       " 982: 'gotten',\n",
       " 983: 'baby',\n",
       " 984: 'katherine',\n",
       " 985: 'dry',\n",
       " 986: 'weeks',\n",
       " 987: 'party',\n",
       " 988: 'sleep',\n",
       " 989: 'shown',\n",
       " 990: 'laws',\n",
       " 991: 'downtown',\n",
       " 992: 'comfort',\n",
       " 993: 'bought',\n",
       " 994: 'facts',\n",
       " 995: 'ending',\n",
       " 996: 'none',\n",
       " 997: 'dog',\n",
       " 998: 'statement',\n",
       " 999: 'six',\n",
       " 1000: 'paterson',\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = to_categorical(np.hstack((labels_train, labels_test)))[0:len(labels_train),:]\n",
    "test_y = to_categorical(np.hstack((labels_train, labels_test)))[len(labels_train):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = w2v[word]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((5000 + 1, EMBEDDING_DIM))\n",
    "for i in range(1,5001):\n",
    "    word = inv_map[i]\n",
    "    embedding_vector = w2v[word]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "sequential_3 (Sequential)        (None, 700, 128)      1084680                                      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 64)            49408                                        \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 64)            49408                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 61)            7869        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 106685\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-13124a76d7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1093\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'variables_initializer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zelongqiu/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = EMBEDDING_DIM\n",
    "\n",
    "def fork (model, n=2):\n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "    return forks\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model_left = Sequential()\n",
    "model_left.add(Embedding(5000 + 1, embedding_vecor_length, \\\n",
    "                    weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True))\n",
    "model_left.add(LSTM(64, return_sequences=True))\n",
    "\n",
    "model_right = Sequential()\n",
    "model_right.add(Embedding(5000 + 1, embedding_vecor_length, \\\n",
    "                    weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True))\n",
    "model_right.add(LSTM(64, go_backwards=True, return_sequences=True))\n",
    "model.add( Merge([model_left, model_right], mode='concat'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "left, right = fork(model)\n",
    "\n",
    "left.add(LSTM(64))\n",
    "right.add(LSTM(64,  go_backwards=True))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([left, right], mode='concat'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(61, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit([train_x, train_x], train_y, batch_size = 128, nb_epoch= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_18 (Embedding)         (None, 500, 300)      10730100    embedding_input_18[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                   (None, 100)           160400      embedding_18[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 100)           0           lstm_19[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 61)            6161        dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 10896661\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "10314/10314 [==============================] - 242s - loss: 2.7694 - acc: 0.2224   \n",
      "Epoch 2/3\n",
      "10314/10314 [==============================] - 248s - loss: 2.1013 - acc: 0.3419   \n",
      "Epoch 3/3\n",
      "10314/10314 [==============================] - 243s - loss: 1.7694 - acc: 0.4171   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cb3066d0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vecor_length = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, embedding_vecor_length, \\\n",
    "                    weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(61, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_x, train_y, batch_size = 128, nb_epoch= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286/1286 [==============================] - 28s    \n"
     ]
    }
   ],
   "source": [
    "pred_y = model.predict_classes([test_x, test_x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I belive that computers ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, Local Newspaper @CAPS1 here to inform yo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>ARE YOU @CAPS1!! Computers are great, they're ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you spend all or most of your freetime sitt...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>Some people think it is a good idea and same d...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers. One of the much enjoyed pieces of t...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>I saw in one of the news papers I got in the m...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers can affect the way people are and ho...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I agree that people are ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, everday @CAPS1 technolog...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Newspaper: @CAPS1 you really t...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, Newspaper I would like to tell you about...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers and the @CAPS1 were a technological ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers of the @ORGANIZATION1, Computers ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>@ORGANIZATION1, @CAPS1 you @CAPS2 want your ki...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Newspaper @CAPS1, @CAPS2 people are now u...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 minute of the day ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @PERSON1, Advances in technology and comp...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local Newspaper, I believe that computers...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>Have you ever thought about all the amazing th...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you think computers have a negative effect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3 @CAPS4 all the talk...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear editor: More and more people use computer...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>357</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I am writing to you beca...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers of the @ORGANIZATION1, @CAPS1 you...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 you think computers have a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, The effects computers ha...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>409</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 name is @PERSON1....</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>@ORGANIZATION1, Computers are great tools and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1462</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 a world where the...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1473</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local news paper, This paper is going to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1489</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, In my opinion I feel lik...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1502</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I believe that with too ...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1508</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers. Theres fun. But there's also a down...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1511</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, The computer has been a r...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1530</td>\n",
       "      <td>1</td>\n",
       "      <td>To: @ORGANIZATION1 goes so fast, and the most ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1544</td>\n",
       "      <td>1</td>\n",
       "      <td>I People spend too much time on the computer. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1551</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper- I understand that comput...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1558</td>\n",
       "      <td>1</td>\n",
       "      <td>@PERCENT1 of all people in the @LOCATION3 have...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1562</td>\n",
       "      <td>1</td>\n",
       "      <td>The importance of computers in the modern worl...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1563</td>\n",
       "      <td>1</td>\n",
       "      <td>Computers, one of the daily things we use and ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1575</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, I am writing to you to t...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1578</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @LOCATION1 @ORGANIZATION1 I think that a...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1594</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, many people say that computers ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1596</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I agree that computers had...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1603</td>\n",
       "      <td>1</td>\n",
       "      <td>To the local Newspaper, I think using computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1605</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think the effects of c...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1644</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I strongly believe compu...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1665</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, Advances in computer technology h...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>Everyone will agree that using computers is al...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1703</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2 @CAPS3, The effects compute...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1705</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3, walking into a roo...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, @CAPS2 name is @PERSON1 and I wan...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1719</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 about what the wo...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1722</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, @CAPS1 people are talkin...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1733</td>\n",
       "      <td>1</td>\n",
       "      <td>I think that computer are a good benefit for p...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1742</td>\n",
       "      <td>1</td>\n",
       "      <td>To whom it @MONTH1 concern; I am writing this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1763</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper: @CAPS1 you know that ove...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1785</td>\n",
       "      <td>1</td>\n",
       "      <td>My opinion is that people should have computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essay_id  essay_set                                              essay  \\\n",
       "0           4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "1          17          1  Dear Local Newspaper, I belive that computers ...   \n",
       "2          46          1  Dear, Local Newspaper @CAPS1 here to inform yo...   \n",
       "3          55          1  ARE YOU @CAPS1!! Computers are great, they're ...   \n",
       "4          61          1  Do you spend all or most of your freetime sitt...   \n",
       "5          69          1  Some people think it is a good idea and same d...   \n",
       "6          87          1  Computers. One of the much enjoyed pieces of t...   \n",
       "7         108          1  I saw in one of the news papers I got in the m...   \n",
       "8         127          1  Computers can affect the way people are and ho...   \n",
       "9         160          1  Dear local newspaper, I agree that people are ...   \n",
       "10        165          1  Dear Local Newspaper, everday @CAPS1 technolog...   \n",
       "11        168          1  Dear @LOCATION1 Newspaper: @CAPS1 you really t...   \n",
       "12        173          1  Dear, Newspaper I would like to tell you about...   \n",
       "13        176          1  Computers and the @CAPS1 were a technological ...   \n",
       "14        181          1  Dear Readers of the @ORGANIZATION1, Computers ...   \n",
       "15        218          1  @ORGANIZATION1, @CAPS1 you @CAPS2 want your ki...   \n",
       "16        247          1  Dear Newspaper @CAPS1, @CAPS2 people are now u...   \n",
       "17        263          1  Dear @ORGANIZATION1, @CAPS1 minute of the day ...   \n",
       "18        275          1  Dear @PERSON1, Advances in technology and comp...   \n",
       "19        276          1  Dear local Newspaper, I believe that computers...   \n",
       "20        291          1  Have you ever thought about all the amazing th...   \n",
       "21        299          1  Do you think computers have a negative effect ...   \n",
       "22        309          1  Dear @CAPS1 @CAPS2, @CAPS3 @CAPS4 all the talk...   \n",
       "23        342          1  Dear editor: More and more people use computer...   \n",
       "24        357          1  Dear local newspaper, I am writing to you beca...   \n",
       "25        377          1  Dear Readers of the @ORGANIZATION1, @CAPS1 you...   \n",
       "26        384          1  Dear @CAPS1, @CAPS2 you think computers have a...   \n",
       "27        404          1  Dear Local Newspaper, The effects computers ha...   \n",
       "28        409          1  Dear local newspaper, @CAPS1 name is @PERSON1....   \n",
       "29        429          1  @ORGANIZATION1, Computers are great tools and ...   \n",
       "..        ...        ...                                                ...   \n",
       "124      1462          1  Dear Local Newspaper, @CAPS1 a world where the...   \n",
       "125      1473          1  Dear local news paper, This paper is going to ...   \n",
       "126      1489          1  Dear local newspaper, In my opinion I feel lik...   \n",
       "127      1502          1  Dear local newspaper, I believe that with too ...   \n",
       "128      1508          1  Computers. Theres fun. But there's also a down...   \n",
       "129      1511          1  Dear @ORGANIZATION1, The computer has been a r...   \n",
       "130      1530          1  To: @ORGANIZATION1 goes so fast, and the most ...   \n",
       "131      1544          1  I People spend too much time on the computer. ...   \n",
       "132      1551          1  Dear local newspaper- I understand that comput...   \n",
       "133      1558          1  @PERCENT1 of all people in the @LOCATION3 have...   \n",
       "134      1562          1  The importance of computers in the modern worl...   \n",
       "135      1563          1  Computers, one of the daily things we use and ...   \n",
       "136      1575          1  Dear Local Newspaper, I am writing to you to t...   \n",
       "137      1578          1  Dear, @LOCATION1 @ORGANIZATION1 I think that a...   \n",
       "138      1594          1  Dear @CAPS1, many people say that computers ca...   \n",
       "139      1596          1  Dear @CAPS1 @CAPS2, I agree that computers had...   \n",
       "140      1603          1  To the local Newspaper, I think using computer...   \n",
       "141      1605          1  Dear local newspaper, I think the effects of c...   \n",
       "142      1644          1  Dear local newspaper, I strongly believe compu...   \n",
       "143      1665          1  Dear @CAPS1, Advances in computer technology h...   \n",
       "144      1673          1  Everyone will agree that using computers is al...   \n",
       "145      1703          1  Dear @CAPS1 @CAPS2 @CAPS3, The effects compute...   \n",
       "146      1705          1  Dear @CAPS1 @CAPS2, @CAPS3, walking into a roo...   \n",
       "147      1717          1  Dear @CAPS1, @CAPS2 name is @PERSON1 and I wan...   \n",
       "148      1719          1  Dear Local Newspaper, @CAPS1 about what the wo...   \n",
       "149      1722          1  Dear local newspaper, @CAPS1 people are talkin...   \n",
       "150      1733          1  I think that computer are a good benefit for p...   \n",
       "151      1742          1  To whom it @MONTH1 concern; I am writing this ...   \n",
       "152      1763          1  Dear Local Newspaper: @CAPS1 you know that ove...   \n",
       "153      1785          1  My opinion is that people should have computer...   \n",
       "\n",
       "     rater1_domain1  rater2_domain1  domain1_score  prediction  \n",
       "0                 5               5             10          12  \n",
       "1                 4               4              8           8  \n",
       "2                 4               4              8           7  \n",
       "3                 4               4              8           8  \n",
       "4                 4               4              8           8  \n",
       "5                 3               4              7           8  \n",
       "6                 5               5             10           9  \n",
       "7                 4               4              8           8  \n",
       "8                 4               5              9           9  \n",
       "9                 4               4              8           8  \n",
       "10                4               5              9           8  \n",
       "11                5               4              9           9  \n",
       "12                4               4              8           8  \n",
       "13                5               5             10          10  \n",
       "14                5               5             10           9  \n",
       "15                4               4              8           8  \n",
       "16                4               4              8           9  \n",
       "17                5               5             10          12  \n",
       "18                6               5             11           9  \n",
       "19                4               4              8           8  \n",
       "20                5               6             11           9  \n",
       "21                4               4              8           8  \n",
       "22                4               5              9           8  \n",
       "23                5               4              9           9  \n",
       "24                4               4              8           7  \n",
       "25                5               5             10           9  \n",
       "26                4               4              8           9  \n",
       "27                4               4              8           9  \n",
       "28                4               4              8           8  \n",
       "29                5               4              9           8  \n",
       "..              ...             ...            ...         ...  \n",
       "124               4               3              7           6  \n",
       "125               3               3              6           6  \n",
       "126               5               4              9           8  \n",
       "127               6               4             10          10  \n",
       "128               4               4              8           8  \n",
       "129               4               3              7          23  \n",
       "130               4               4              8           9  \n",
       "131               5               5             10           9  \n",
       "132               4               5              9          11  \n",
       "133               4               4              8           8  \n",
       "134               2               2              4           6  \n",
       "135               3               3              6           6  \n",
       "136               4               5              9          10  \n",
       "137               4               5              9           9  \n",
       "138               4               4              8           8  \n",
       "139               4               5              9           9  \n",
       "140               4               4              8           8  \n",
       "141               4               4              8           8  \n",
       "142               4               4              8           8  \n",
       "143               4               5              9          10  \n",
       "144               2               3              5           4  \n",
       "145               5               6             11           9  \n",
       "146               6               6             12           8  \n",
       "147               4               4              8          10  \n",
       "148               4               4              8           9  \n",
       "149               4               5              9           8  \n",
       "150               4               4              8           7  \n",
       "151               3               3              6           7  \n",
       "152               6               6             12           9  \n",
       "153               4               4              8           8  \n",
       "\n",
       "[154 rows x 7 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"prediction\"] = pred_y\n",
    "test[test[\"essay_set\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.93582272  0.98486352  0.9729714   0.9837001   0.98912857  0.98136051\n",
      "  0.93398956  0.82689709]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96812604250544088"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_kappa(train_y, model.predict([train_x, train_x]), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.49066455  0.00757581  0.10762456  0.77021246  0.30211683  0.45438115\n",
      "  0.51410443  0.30636055]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39695948628924149"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_kappa(test_y, model.predict([test_x, test_x]), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(data_df, prediction, name):\n",
    "\tdata_df[\"prediction\"] = prediction\n",
    "\tdata_df = data_df[[\"essay_set\", 'essay_id', 'prediction', 'domain1_score']]\n",
    "\tdata_df.to_csv(name, index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286/1286 [==============================] - 30s    \n"
     ]
    }
   ],
   "source": [
    "generate_output(test, model.predict_classes([test_x, test_x]), 'Bidirectional_lstm_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10314/10314 [==============================] - 234s   \n"
     ]
    }
   ],
   "source": [
    "generate_output(train, model.predict_classes([train_x, train_x]), 'Bidirectional_lstm_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sequence Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 5000\n",
    "MAX_SEQUENCE_LENGTH = 400\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35617 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(nb_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts_train + texts_test)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_sequences(texts_train)\n",
    "test_x = tokenizer.texts_to_sequences(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of data tensor:', (10314, 700))\n"
     ]
    }
   ],
   "source": [
    "train_x = pad_sequences(train_x, padding = 'post',maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_x = pad_sequences(test_x, padding = 'post', maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of data tensor:', train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = labels_train.astype('float32')\n",
    "test_y = labels_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = w2v[word]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_73 (Embedding)         (None, 400, 100)      3576700                                      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_99 (LSTM)                   (None, 64)            42240                                        \n",
      "____________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)         (None, 400, 100)      3576700                                      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_100 (LSTM)                  (None, 64)            42240                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 128)           0           merge_47[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 64)            8256        dropout_54[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 64)            0           dense_59[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 1)             65          dropout_55[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7246201\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "10314/10314 [==============================] - 215s - loss: 78.5855 - mean_absolute_error: 5.4331   \n",
      "Epoch 2/30\n",
      "10314/10314 [==============================] - 198s - loss: 31.3436 - mean_absolute_error: 3.2365   \n",
      "Epoch 3/30\n",
      "10314/10314 [==============================] - 196s - loss: 13.2848 - mean_absolute_error: 2.1730   \n",
      "Epoch 4/30\n",
      "10314/10314 [==============================] - 198s - loss: 10.6152 - mean_absolute_error: 1.9672   \n",
      "Epoch 5/30\n",
      "10314/10314 [==============================] - 197s - loss: 10.3041 - mean_absolute_error: 1.9201   \n",
      "Epoch 6/30\n",
      "10314/10314 [==============================] - 198s - loss: 7.1891 - mean_absolute_error: 1.6455   \n",
      "Epoch 7/30\n",
      "10314/10314 [==============================] - 192s - loss: 6.2184 - mean_absolute_error: 1.5161   \n",
      "Epoch 8/30\n",
      "10314/10314 [==============================] - 192s - loss: 5.7971 - mean_absolute_error: 1.4273   \n",
      "Epoch 9/30\n",
      "10314/10314 [==============================] - 191s - loss: 4.8290 - mean_absolute_error: 1.3200   \n",
      "Epoch 10/30\n",
      "10314/10314 [==============================] - 192s - loss: 4.5396 - mean_absolute_error: 1.2833   \n",
      "Epoch 11/30\n",
      "10314/10314 [==============================] - 192s - loss: 4.5083 - mean_absolute_error: 1.2494   \n",
      "Epoch 12/30\n",
      "10314/10314 [==============================] - 193s - loss: 4.0557 - mean_absolute_error: 1.2139   \n",
      "Epoch 13/30\n",
      "10314/10314 [==============================] - 208s - loss: 3.9537 - mean_absolute_error: 1.2020   \n",
      "Epoch 14/30\n",
      "10314/10314 [==============================] - 200s - loss: 3.6136 - mean_absolute_error: 1.1433   \n",
      "Epoch 15/30\n",
      "10314/10314 [==============================] - 212s - loss: 3.3530 - mean_absolute_error: 1.1158   \n",
      "Epoch 16/30\n",
      "10314/10314 [==============================] - 206s - loss: 3.2584 - mean_absolute_error: 1.1092   \n",
      "Epoch 17/30\n",
      "10314/10314 [==============================] - 194s - loss: 2.9946 - mean_absolute_error: 1.0742   \n",
      "Epoch 18/30\n",
      "10314/10314 [==============================] - 192s - loss: 2.8704 - mean_absolute_error: 1.0574   \n",
      "Epoch 19/30\n",
      "10314/10314 [==============================] - 195s - loss: 2.9297 - mean_absolute_error: 1.0630   \n",
      "Epoch 20/30\n",
      "10314/10314 [==============================] - 200s - loss: 2.8772 - mean_absolute_error: 1.0469   \n",
      "Epoch 21/30\n",
      "10314/10314 [==============================] - 195s - loss: 2.8786 - mean_absolute_error: 1.0434   \n",
      "Epoch 22/30\n",
      "10314/10314 [==============================] - 197s - loss: 2.6710 - mean_absolute_error: 1.0210   \n",
      "Epoch 23/30\n",
      "10314/10314 [==============================] - 204s - loss: 2.5711 - mean_absolute_error: 0.9851   \n",
      "Epoch 24/30\n",
      "10314/10314 [==============================] - 208s - loss: 2.3691 - mean_absolute_error: 0.9628   \n",
      "Epoch 25/30\n",
      "10314/10314 [==============================] - 198s - loss: 2.2368 - mean_absolute_error: 0.9368   \n",
      "Epoch 26/30\n",
      "10314/10314 [==============================] - 200s - loss: 2.3775 - mean_absolute_error: 0.9752   \n",
      "Epoch 27/30\n",
      "10314/10314 [==============================] - 192s - loss: 2.1824 - mean_absolute_error: 0.9472   \n",
      "Epoch 28/30\n",
      "10314/10314 [==============================] - 192s - loss: 2.1288 - mean_absolute_error: 0.9253   \n",
      "Epoch 29/30\n",
      "10314/10314 [==============================] - 191s - loss: 2.1911 - mean_absolute_error: 0.9195   \n",
      "Epoch 30/30\n",
      "10314/10314 [==============================] - 192s - loss: 1.9635 - mean_absolute_error: 0.8914   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3004877d0>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vecor_length = EMBEDDING_DIM\n",
    "\n",
    "def fork (model, n=2):\n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "    return forks\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model_left = Sequential()\n",
    "model_left.add(Embedding(len(word_index) + 1, embedding_vecor_length, \\\n",
    "                    weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True))\n",
    "model_left.add(LSTM(64))\n",
    "\n",
    "model_right = Sequential()\n",
    "model_right.add(Embedding(len(word_index) + 1, embedding_vecor_length, \\\n",
    "                    weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=True))\n",
    "model_right.add(LSTM(64, go_backwards=True))\n",
    "\n",
    "model.add( Merge([model_left, model_right], mode='concat'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', metrics = ['mean_absolute_error'], optimizer='adam')\n",
    "print(model.summary())\n",
    "model.fit([train_x, train_x], train_y, batch_size = 128, nb_epoch= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_vecor_length = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, embedding_vecor_length, \\\n",
    "                    weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_x, train_y, batch_size = 128, nb_epoch= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(61, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.85608191  0.62302006  0.69364329  0.62774886  0.77346977  0.71338742\n",
      "  0.95053852  0.93725111]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81256575262230601"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress_kappa(train_y, model.predict([train_x, train_x]), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa for each set [ 0.72805651  0.14926855  0.62803101  0.63152203  0.63041704  0.65642458\n",
      "  0.62133442  0.37867837]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57262662140342091"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress_kappa(test_y, model.predict([test_x, test_x]), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
